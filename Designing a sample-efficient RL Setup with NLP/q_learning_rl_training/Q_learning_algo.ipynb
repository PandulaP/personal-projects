{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K_q2Bd3DKo4m"
   },
   "source": [
    "##### All required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T17:18:03.660848Z",
     "start_time": "2020-09-26T17:17:57.182032Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "F7tze0YMKnwT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install gym_minigrid\n",
    "#!pip install array2gif\n",
    "\n",
    "# to create gym environment (test environment for DQN)\n",
    "import gym\n",
    "from gym import wrappers\n",
    "from gym_minigrid.wrappers import *\n",
    "\n",
    "# to store and process data\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from array2gif import write_gif\n",
    "\n",
    "# to train a NN that approximates the Q function\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.models import Model, load_model, clone_model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# to pre-process the video frames (observation)\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "\n",
    "# to build the experience replay\n",
    "from collections import deque\n",
    "\n",
    "# to communicate with the system / store trained models / visualize results\n",
    "from sys import getsizeof\n",
    "from datetime import datetime\n",
    "import os.path\n",
    "import time\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T17:18:03.799758Z",
     "start_time": "2020-09-26T17:18:03.662905Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create the simple crossing environment\n",
    "env = gym.make('MiniGrid-SimpleCrossingS9N1-v0')\n",
    "env = ReseedWrapper(env,seeds=[3])\n",
    "env = RGBImgObsWrapper(env) # Get pixel observations\n",
    "env = ImgObsWrapper(env) # Get rid of the 'mission' field\n",
    "\n",
    "obs, reward, done, _ = env.step(0)\n",
    "plt.imshow(obs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T17:18:25.354125Z",
     "start_time": "2020-09-26T17:18:25.351528Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "W_y45--U1aiS"
   },
   "outputs": [],
   "source": [
    "# function to pre-process image frames\n",
    "def pre_process(observation):\n",
    "    processed_observation = np.uint8(resize(observation, (84, 84)) *255) #  gray scale image where pixel intensities are between 0-255\n",
    "    return processed_observation\n",
    "\n",
    "\n",
    "# function to generate one-hot-encoded masked action vector\n",
    "def one_hot_encode_mask(target_action_idx, number_of_actions):\n",
    "    return np.eye(number_of_actions)[np.array(target_action_idx).reshape(-1)]\n",
    "\n",
    "\n",
    "# function defining the Q-network\n",
    "def q_approx_model():\n",
    "    \n",
    "    num_of_actions = 3 # number of actions\n",
    "    input_img_size = (84, 84, 3 * 3)  # input image size to model\n",
    "\n",
    "    # inputs to model\n",
    "    obs_input = layers.Input(input_img_size, name='4_stacked_input_frames') \n",
    "    actions_input = layers.Input((num_of_actions,), name='one_hot_encoded_action_mask')\n",
    "\n",
    "    # normalize the grayscaled input frames\n",
    "    normalized_obs = layers.Lambda(lambda x: x / 255.0, name='frame_normalization')(obs_input)\n",
    "\n",
    "    # \"The first hidden layer convolves 16 8×8 filters with stride 4 with the input image and applies a rectifier nonlinearity.\"\n",
    "    convolution_1 = layers.convolutional.Conv2D( 16, (8, 8), strides=(4, 4), activation='relu')(normalized_obs)\n",
    "\n",
    "    # \"The second hidden layer convolves 32 4×4 filters with stride 2, again followed by a rectifier nonlinearity.\"\n",
    "    convolution_2 = layers.convolutional.Conv2D( 32, (4, 4), strides=(2, 2), activation='relu')(convolution_1)\n",
    "\n",
    "    # flattened second convolutional layer.\n",
    "    convolution_2_flattened = layers.core.Flatten()(convolution_2)\n",
    "\n",
    "    # \"The final hidden layer is fully-connected and consists of 256 rectifier units.\"\n",
    "    final_hidden = layers.Dense(256, activation='relu')(convolution_2_flattened)\n",
    "\n",
    "    # \"The output layer is a fully-connected linear layer with a single output for each valid action.\"\n",
    "    output_layer = layers.Dense(num_of_actions, activation='linear')(final_hidden)\n",
    "\n",
    "    # output multiplied by the mask\n",
    "    masked_output = layers.Multiply(name='q_val')([output_layer, actions_input])\n",
    "\n",
    "    # initialise the model\n",
    "    model = Model(inputs = [obs_input, actions_input], outputs = masked_output)\n",
    "\n",
    "    # model summary\n",
    "    model.summary()\n",
    "\n",
    "    # \"We used the RMSProp algorithm\"\"\n",
    "    optimizer = RMSprop(lr=0.00025, rho=0.95, epsilon=0.01)\n",
    "    \n",
    "    model.compile(optimizer, loss='mse')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# function to store the observed information in the replay memory\n",
    "def store_replay_memory(replay_memory, current_state_set, action, reward, current_states_w_nxt_state, is_next_terminate):\n",
    "    replay_memory.append((current_state_set, action, reward, current_states_w_nxt_state, is_next_terminate))\n",
    "\n",
    "    \n",
    "# function to train the Q-network using random batches drawn from Replay Memory\n",
    "def batch_train_q_network(replay_memory, model):\n",
    "\n",
    "    num_of_actions = 3 # number of agent actions\n",
    "    input_img_size = (84, 84, 3*3)  # input image size to model\n",
    "\n",
    "    # batch size\n",
    "    batch_size = 32\n",
    "\n",
    "    # discounting factor (future reward decay rate)\n",
    "    gamma = 0.99\n",
    "\n",
    "    # draw a random mini-batch from the Replay Memory\n",
    "    mini_batch = random.sample(replay_memory, batch_size)\n",
    "    \n",
    "    # create a placeholder to store `current state sets` from sampled batch\n",
    "    current_states_set_history = np.zeros((batch_size, input_img_size[0]\n",
    "                                                     , input_img_size[1]\n",
    "                                                     , input_img_size[2]))\n",
    "    \n",
    "    # create a placeholder to store `current states with next states` from sampled batch\n",
    "    current_states_set_w_nxt_history = np.zeros((batch_size, input_img_size[0]\n",
    "                                                           , input_img_size[1]\n",
    "                                                           , input_img_size[2]))\n",
    "    \n",
    "    # create a placeholder to store Q-value targets calculated during training \n",
    "    calculated_targets = np.zeros((batch_size,))\n",
    "\n",
    "    # create placeholders to store actions, rewards and termination flags\n",
    "    action, reward, is_next_terminate = [], [], []\n",
    "\n",
    "    # transfer mini-batch data from Replay Memory to placeholders\n",
    "    for idx, val in enumerate(mini_batch):\n",
    "        current_states_set_history[idx] = val[0]\n",
    "        action.append(val[1])\n",
    "        reward.append(val[2])\n",
    "        current_states_set_w_nxt_history[idx] = val[3]\n",
    "        is_next_terminate.append(val[4])\n",
    "\n",
    "\n",
    "    # generate next state Q-value estimates with current Q-network\n",
    "    all_action_mask = np.ones((batch_size, num_of_actions))\n",
    "    next_state_Q_values = model.predict([current_states_set_w_nxt_history, all_action_mask])\n",
    "\n",
    "    # calculate target Q-values for sample using: r + gamma * max[Q(s',a')]\n",
    "    # If next state is a terminal, set target to be -1 (negative reward - penalize termination)\n",
    "    for i in range(batch_size):\n",
    "        if is_next_terminate[i]:\n",
    "            calculated_targets[i] = -1\n",
    "        else:\n",
    "            calculated_targets[i] = reward[i] + gamma * np.amax(next_state_Q_values[i])\n",
    "\n",
    "    # create the mask layer for each selected action\n",
    "    one_hot_encoded_action = one_hot_encode_mask(action, num_of_actions)\n",
    "\n",
    "    # get target values only for the selected action\n",
    "    one_hot_encoded_target = one_hot_encoded_action * calculated_targets[:, None]\n",
    "\n",
    "    # train the q-network using mini-batch data\n",
    "    H = model.fit([current_states_set_history, one_hot_encoded_action]\n",
    "                  , one_hot_encoded_target\n",
    "                  , epochs=1\n",
    "                  , batch_size=batch_size\n",
    "                  , verbose=0)\n",
    "\n",
    "    # return the training loss\n",
    "    return H.history['loss'][0]\n",
    "\n",
    "\n",
    "# function to select an action from the Q-network using an epsilon-greedy policy\n",
    "def select_action(current_state_set, epsilon, step, model, obs_step_num):\n",
    "\n",
    "    # number of agent actions\n",
    "    num_of_actions = 3\n",
    "\n",
    "    if np.random.rand() <= epsilon or step <= obs_step_num:\n",
    "        action = random.randrange(num_of_actions) # get the index of a random action\n",
    "        return action + 1 # return the real action\n",
    "    else:\n",
    "        q_value = model.predict([current_state_set, np.ones(num_of_actions).reshape(1, num_of_actions)])\n",
    "        action = np.argmax(q_value[0]) # get the index of the action with highest Q-value\n",
    "        return action + 1 # return the real action\n",
    "\n",
    "# function to generate intermediate rewards\n",
    "def intermediate_rewards_function(three_frames, language_instruction):\n",
    "    \"\"\"This function takes 3 (consecutive) images/game frames and a language instruction and evaluates \n",
    "       if the agent's behaviour in the frames agrees with the given language instruction.\n",
    "       \n",
    "       It uses the the previously trained LIERN model and outputs a reward of `1' if agent's behaviour\n",
    "       aligns with the given instruction (and `0' otherwise).\"\"\"\n",
    "    \n",
    "    ### CONVERTING IMAGES TO EMBEDDING VECTOR ###\n",
    "    \n",
    "    img_model = models.resnet50(pretrained=True)\n",
    "    layer = img_model._modules.get('avgpool')\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    img_model.eval()\n",
    "\n",
    "    def get_img_embeddings(image_array):\n",
    "        \"\"\"gets 3 input frames/images and converts them to a single embedding vector\"\"\"\n",
    "\n",
    "        temp_imgs_l = []\n",
    "\n",
    "        for image in image_array:\n",
    "            temp_img = Image.fromarray(image).convert('RGB')\n",
    "            temp_img = normalize(to_tensor(scaler(temp_img)))\n",
    "            temp_imgs_l.append(temp_img)\n",
    "\n",
    "        temp_imgs_l = torch.cat(temp_imgs_l)\n",
    "        temp_imgs_l = temp_imgs_l.reshape((3,3,224,224))\n",
    "\n",
    "        # create PyTorch Var. w/ pre-processed image\n",
    "        t_img = Variable(temp_imgs_l)\n",
    "\n",
    "        # create an empty vector to hold the embeddings vector\n",
    "        img_embedding = torch.zeros(2048*3)\n",
    "\n",
    "        # function to copy the output of the layer\n",
    "        def copy_data(m, i, o):\n",
    "            img_embedding.copy_(o.data.reshape(2048*3))\n",
    "\n",
    "        # attach that function to the `avgpool` layer\n",
    "        h = layer.register_forward_hook(copy_data)\n",
    "\n",
    "        # run the model on the image\n",
    "        img_model(t_img)\n",
    "\n",
    "        # remove the copy function from the layer\n",
    "        h.remove()\n",
    "\n",
    "        # return the feature vector\n",
    "        return img_embedding\n",
    "\n",
    "    \n",
    "    ### CONVERTING LANGUAGE INSTRUCTION TO EMBEDDING VECTOR ###\n",
    "    \n",
    "    sentence_model = SentenceTransformer('roberta-large-nli-stsb-mean-tokens')\n",
    "\n",
    "    def get_sentence_embeddings(sentence_model, language_instruct):\n",
    "\n",
    "        sentc_embedding = sentence_model.encode(language_instruct)\n",
    "\n",
    "        return sentc_embedding.reshape(-1).tolist()\n",
    "    \n",
    "    \n",
    "    ### GENERATING THE COMBINED EMBEDDINGS VECTOR (INPUT TO CLASSIFICATION MODEL) ###\n",
    "    \n",
    "    def get_combined_embeddings(img_embed, sentence_embed):\n",
    "\n",
    "        return np.concatenate([img_embed, sentence_embed]).tolist()\n",
    "    \n",
    "    \n",
    "    ### GENERATE INTERMEDIATE REWARDS USING SAVED MODEL ###\n",
    "    \n",
    "    class Classification_Net(nn.Module):\n",
    "\n",
    "        def __init__(self, n_features):\n",
    "            super(Classification_Net, self).__init__()\n",
    "            self.fc1 = nn.Linear(n_features, int(7168/2))\n",
    "            self.fc2 = nn.Linear(int(7168/2), int(7168/10))\n",
    "            self.fc3 = nn.Linear(int(7168/10), int(7168/100))\n",
    "            self.fc4 = nn.Linear(int(7168/100), 1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = F.relu(self.fc3(x))\n",
    "            return torch.sigmoid(self.fc4(x))\n",
    "\n",
    "    # load the previously trained model parameters\n",
    "    classify_net = torch.load('classify_model.pth')\n",
    "\n",
    "    def get_probability(model, combined_embed):\n",
    "        \n",
    "        classify_net = model\n",
    "        embed_input = torch.from_numpy(np.array(combined_embed)).float()\n",
    "        y_pred - classify_net(embed_input)\n",
    "        return y_pred\n",
    "\n",
    "    def generate_interim_reward(predicted_prob):\n",
    "\n",
    "        if predicted_prob > .5:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    img_embeddings = get_img_embeddings(three_frames)\n",
    "    sentence_embeddings =  get_sentence_embeddings(sentence_model, language_instruction)\n",
    "    combined_embeddings = get_combined_embeddings(img_embeddings,sentence_embeddings)\n",
    "    probability = get_probability(classify_net,combined_embeddings)\n",
    "    interim_reward = generate_interim_reward(probability)\n",
    "    \n",
    "    return interim_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T16:37:47.049302Z",
     "start_time": "2020-09-26T16:37:47.046671Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "u9Cyb_kQ1HK8"
   },
   "outputs": [],
   "source": [
    "# training and testing configurations:\n",
    "\n",
    "configs = {  'train_dir'          : './train_dir/' # directory where to write event logs and checkpoint\n",
    "            ,'restore_model_path' :  './train_dir/grid_world_20200912050215.h5' # Path of the restore model file\n",
    "            ,'resume'             : False # resume training from previous a previous model\n",
    "            , 'use_iter_rewards'  : False # whether to start generating language-based intermediate rewards\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-30T12:45:40.238874Z",
     "start_time": "2020-08-30T12:45:40.226942Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "p0AmKsVO6L2d"
   },
   "outputs": [],
   "source": [
    "def dqn_algo_train():\n",
    "\n",
    "    # create the simple crossing environment \n",
    "    random_seed = 0 # np.random.randint(1000) ## uncomment this to create stochastic enviroments\n",
    "    env = gym.make('MiniGrid-SimpleCrossingS9N1-v0')\n",
    "    env = ReseedWrapper(env,seeds=[random_seed])\n",
    "    env = RGBImgObsWrapper(env) # Get pixel observations\n",
    "    env = ImgObsWrapper(env) # Get rid of the 'mission' field\n",
    "\n",
    "    # parameter initialization\n",
    "    training_epi_limit = 100000 # number of episodes to training the Q-network\n",
    "    obs_step_num = 50000 # number of steps to observe (no training)\n",
    "    replay_memory_len = 400000  # how many previous states to remember\n",
    "\n",
    "    target_model_refresh_steps = 20000 # number of steps to refresh the target model weights\n",
    "\n",
    "    inititial_epsilon = 1.0 # starting epsilon for the policy\n",
    "    resume_epsilon = 0.5 # training resume epsilon for the policy \n",
    "    final_epsilon = 0.1 # final epsilon for the policy\n",
    "    epsilon_annealed_steps = 500000 # number of steps to linearly anneal epsilon from 1.0 to 0.1\n",
    "\n",
    "    epsilon_decay = (inititial_epsilon - final_epsilon) / epsilon_annealed_steps # epsilon decay per annealed step\n",
    "\n",
    "    manual_instruction_count = 0 # number of steps to continue without asking for language instructions\n",
    "    \n",
    "    episode_num = 0 # store episode\n",
    "    global_step_num = 0 # store global step number\n",
    "    \n",
    "    # initialize the fixed length Experience Replay memory\n",
    "    memory = deque(maxlen = replay_memory_len)\n",
    "\n",
    "    # initialize epsilon\n",
    "    epsilon = inititial_epsilon\n",
    "    \n",
    "    # if DQN training is resumed from the last checkpoint\n",
    "    # set a decayed (0.5) epsilon value to restrict exploration \n",
    "    # (assuming previous training sessions have done most exploration)\n",
    "    if configs['resume']:\n",
    "        model = load_model(configs['restore_model_path'])\n",
    "        epsilon = resume_epsilon\n",
    "    else:\n",
    "        model = q_approx_model()\n",
    "\n",
    "    # clone most recent Q-network to calculate target\n",
    "    model_target = clone_model(model)\n",
    "    model_target.set_weights(model.get_weights())\n",
    "\n",
    "    # initialize the Q-learning episodes-loop\n",
    "    while episode_num < training_epi_limit:\n",
    "\n",
    "        # flags to identify if an episode/game has terminated\n",
    "        terminated = False\n",
    "        \n",
    "  \n",
    "        # variables to information per episode (a game)\n",
    "        score = 0         # store game score (per episode/game)\n",
    "        step = 0          # store steps taken (per episode/game)    \n",
    "        loss = 0.0        # store loss value per episode/game\n",
    "        \n",
    "        # reset the environment\n",
    "        env.reset()\n",
    "\n",
    "        # get the first observation and preprocess it\n",
    "        first_obs, _, _, _ = env.step(1)\n",
    "        first_state = pre_process(first_obs)\n",
    "\n",
    "        # duplicate the first observations 3 times to create history\n",
    "        history = np.stack((first_state, first_state, first_state, first_state), axis=2)\n",
    "        history = np.reshape([history], (1, 84, 84, 3*3))\n",
    "        \n",
    "        # initialize a loop within an episode/game\n",
    "        while not terminated:\n",
    "            \n",
    "            inter_reward = 0 # set any intermediate rewards to zero \n",
    "\n",
    "            # get action for the current history and go one step in environment\n",
    "            action = select_action(history, epsilon, global_step_num, model_target, obs_step_num)\n",
    "\n",
    "            # decay epsilon after observation period\n",
    "            if epsilon > final_epsilon and global_step_num > obs_step_num:\n",
    "                epsilon -= epsilon_decay\n",
    "\n",
    "            # record environment's response for the action\n",
    "            observation, reward, terminated, info = env.step(action)\n",
    "\n",
    "            # preprocess the observation and store as next state to new history\n",
    "            next_state = pre_process(observation)\n",
    "            next_state = np.reshape([next_state], (1, 84, 84, 3*1))\n",
    "            next_history = np.append(next_state, history[:, :, :, :3*2], axis=3)\n",
    "            \n",
    "            # generate intermediate rewards (only if triggered AND 1000 time-steps has passed since last instruction)\n",
    "            ## TO-DO : Implement the moving-avg-based threshold\n",
    "            if configs['use_iter_rewards'] and manual_instruction_count % 1000 == 0:\n",
    "        \n",
    "                # diplay last 3 game frames\n",
    "                for img in history[:, :, :, -3*3:]:\n",
    "                    plt.imshow(img)\n",
    "                    plt.show()\n",
    "                    \n",
    "                language_instruction = input(\"Please provide the instruction to the agent (based on last 3 frames): \")\n",
    "                inter_reward = intermediate_rewards_function(history[:, :, :, -3*3:], language_instruction)\n",
    "                manual_instruction_count -= 1\n",
    "                \n",
    "            reward = reward + inter_reward\n",
    "            \n",
    "            # store the current step data to replay memory\n",
    "            store_replay_memory(memory, history, (action-1), reward, next_history, terminated)\n",
    "\n",
    "            # initiate the Q-network training if observation period is over\n",
    "            if global_step_num > obs_step_num:\n",
    "\n",
    "                # perform batch training for 1-epoch\n",
    "                loss = loss + batch_train_q_network(memory, model)\n",
    "\n",
    "                # update the target model weights every 10,000 steps\n",
    "                if global_step_num % target_model_refresh_steps == 0:  \n",
    "                    model_target.set_weights(model.get_weights())\n",
    "\n",
    "            # update the in game/episode score\n",
    "            score += reward\n",
    "\n",
    "            # assign new state to current state\n",
    "            history = next_history\n",
    "            \n",
    "            # increment the global step number and in game/episode step number\n",
    "            global_step_num += 1\n",
    "            step += 1\n",
    "\n",
    "            # display information per episode/game at termination\n",
    "            if terminated:\n",
    "                print(f'episode: {episode_num}, score: {score}, global_step_num: {global_step_num}, avg loss: {loss/float(step)}, step: {step}, replay memory length: {len(memory)}')\n",
    "\n",
    "                # save the model weights after every 500 episodes (and at the end of the training loop)\n",
    "                if episode_num % 500 == 0 or (episode_num + 1) == training_epi_limit:\n",
    "                    now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "                    file_name = f\"grid_world_{now}.h5\"\n",
    "                    model_path = os.path.join(configs['train_dir'], file_name)\n",
    "                    model.save(model_path)\n",
    "\n",
    "                episode_num += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-30T12:45:43.034Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6ka2kYXjBN4-",
    "outputId": "c2c26be2-16c7-4de1-913c-92c9a2ddcb09",
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "4_stacked_input_frames (InputLa [(None, 84, 84, 12)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "frame_normalization (Lambda)    (None, 84, 84, 12)   0           4_stacked_input_frames[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 20, 20, 16)   12304       frame_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 9, 9, 32)     8224        conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2592)         0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          663808      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            771         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "one_hot_encoded_action_mask (In [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "q_val (Multiply)                (None, 3)            0           dense_1[0][0]                    \n",
      "                                                                 one_hot_encoded_action_mask[0][0]\n",
      "==================================================================================================\n",
      "Total params: 685,107\n",
      "Trainable params: 685,107\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "episode: 0, score: 1.0, global_step_num: 144, avg loss: 0.0, step: 144, replay memory length: 144\n",
      "episode: 1, score: 0, global_step_num: 467, avg loss: 0.0, step: 323, replay memory length: 467\n",
      "episode: 2, score: 0, global_step_num: 790, avg loss: 0.0, step: 323, replay memory length: 790\n",
      "episode: 3, score: 0, global_step_num: 1113, avg loss: 0.0, step: 323, replay memory length: 1113\n",
      "episode: 4, score: 0, global_step_num: 1436, avg loss: 0.0, step: 323, replay memory length: 1436\n",
      "episode: 5, score: 0, global_step_num: 1759, avg loss: 0.0, step: 323, replay memory length: 1759\n",
      "episode: 6, score: 0, global_step_num: 2082, avg loss: 0.0, step: 323, replay memory length: 2082\n",
      "episode: 7, score: 0, global_step_num: 2405, avg loss: 0.0, step: 323, replay memory length: 2405\n",
      "episode: 8, score: 0, global_step_num: 2728, avg loss: 0.0, step: 323, replay memory length: 2728\n",
      "episode: 9, score: 0, global_step_num: 3051, avg loss: 0.0, step: 323, replay memory length: 3051\n",
      "episode: 10, score: 0, global_step_num: 3374, avg loss: 0.0, step: 323, replay memory length: 3374\n",
      "episode: 11, score: 0, global_step_num: 3697, avg loss: 0.0, step: 323, replay memory length: 3697\n",
      "episode: 12, score: 0, global_step_num: 4020, avg loss: 0.0, step: 323, replay memory length: 4020\n",
      "episode: 13, score: 0, global_step_num: 4343, avg loss: 0.0, step: 323, replay memory length: 4343\n",
      "episode: 14, score: 0, global_step_num: 4666, avg loss: 0.0, step: 323, replay memory length: 4666\n",
      "episode: 15, score: 0, global_step_num: 4989, avg loss: 0.0, step: 323, replay memory length: 4989\n",
      "episode: 16, score: 0, global_step_num: 5312, avg loss: 0.0, step: 323, replay memory length: 5312\n",
      "episode: 17, score: 0, global_step_num: 5635, avg loss: 0.0, step: 323, replay memory length: 5635\n",
      "episode: 18, score: 0, global_step_num: 5958, avg loss: 0.0, step: 323, replay memory length: 5958\n",
      "episode: 19, score: 0, global_step_num: 6281, avg loss: 0.0, step: 323, replay memory length: 6281\n",
      "episode: 20, score: 0, global_step_num: 6604, avg loss: 0.0, step: 323, replay memory length: 6604\n",
      "episode: 21, score: 0, global_step_num: 6927, avg loss: 0.0, step: 323, replay memory length: 6927\n",
      "episode: 22, score: 0, global_step_num: 7250, avg loss: 0.0, step: 323, replay memory length: 7250\n",
      "episode: 23, score: 0, global_step_num: 7573, avg loss: 0.0, step: 323, replay memory length: 7573\n",
      "episode: 24, score: 0, global_step_num: 7896, avg loss: 0.0, step: 323, replay memory length: 7896\n",
      "episode: 25, score: 0, global_step_num: 8219, avg loss: 0.0, step: 323, replay memory length: 8219\n",
      "episode: 26, score: 0, global_step_num: 8542, avg loss: 0.0, step: 323, replay memory length: 8542\n",
      "episode: 27, score: 0, global_step_num: 8865, avg loss: 0.0, step: 323, replay memory length: 8865\n",
      "episode: 28, score: 1.0, global_step_num: 9019, avg loss: 0.0, step: 154, replay memory length: 9019\n",
      "episode: 29, score: 0, global_step_num: 9342, avg loss: 0.0, step: 323, replay memory length: 9342\n",
      "episode: 30, score: 0, global_step_num: 9665, avg loss: 0.0, step: 323, replay memory length: 9665\n",
      "episode: 31, score: 1.0, global_step_num: 9848, avg loss: 0.0, step: 183, replay memory length: 9848\n",
      "episode: 32, score: 0, global_step_num: 10171, avg loss: 0.0, step: 323, replay memory length: 10171\n",
      "episode: 33, score: 0, global_step_num: 10494, avg loss: 0.0, step: 323, replay memory length: 10494\n",
      "episode: 34, score: 0, global_step_num: 10817, avg loss: 0.0, step: 323, replay memory length: 10817\n",
      "episode: 35, score: 0, global_step_num: 11140, avg loss: 0.0, step: 323, replay memory length: 11140\n",
      "episode: 36, score: 0, global_step_num: 11463, avg loss: 0.0, step: 323, replay memory length: 11463\n",
      "episode: 37, score: 0, global_step_num: 11786, avg loss: 0.0, step: 323, replay memory length: 11786\n",
      "episode: 38, score: 0, global_step_num: 12109, avg loss: 0.0, step: 323, replay memory length: 12109\n",
      "episode: 39, score: 0, global_step_num: 12432, avg loss: 0.0, step: 323, replay memory length: 12432\n",
      "episode: 40, score: 0, global_step_num: 12755, avg loss: 0.0, step: 323, replay memory length: 12755\n",
      "episode: 41, score: 0, global_step_num: 13078, avg loss: 0.0, step: 323, replay memory length: 13078\n",
      "episode: 42, score: 0, global_step_num: 13401, avg loss: 0.0, step: 323, replay memory length: 13401\n",
      "episode: 43, score: 1.0, global_step_num: 13720, avg loss: 0.0, step: 319, replay memory length: 13720\n",
      "episode: 44, score: 1.0, global_step_num: 13888, avg loss: 0.0, step: 168, replay memory length: 13888\n",
      "episode: 45, score: 0, global_step_num: 14211, avg loss: 0.0, step: 323, replay memory length: 14211\n",
      "episode: 46, score: 0, global_step_num: 14534, avg loss: 0.0, step: 323, replay memory length: 14534\n",
      "episode: 47, score: 0, global_step_num: 14857, avg loss: 0.0, step: 323, replay memory length: 14857\n",
      "episode: 48, score: 0, global_step_num: 15180, avg loss: 0.0, step: 323, replay memory length: 15180\n",
      "episode: 49, score: 1.0, global_step_num: 15478, avg loss: 0.0, step: 298, replay memory length: 15478\n",
      "episode: 50, score: 0, global_step_num: 15801, avg loss: 0.0, step: 323, replay memory length: 15801\n",
      "episode: 51, score: 0, global_step_num: 16124, avg loss: 0.0, step: 323, replay memory length: 16124\n",
      "episode: 52, score: 0, global_step_num: 16447, avg loss: 0.0, step: 323, replay memory length: 16447\n",
      "episode: 53, score: 0, global_step_num: 16770, avg loss: 0.0, step: 323, replay memory length: 16770\n",
      "episode: 54, score: 0, global_step_num: 17093, avg loss: 0.0, step: 323, replay memory length: 17093\n",
      "episode: 55, score: 0, global_step_num: 17416, avg loss: 0.0, step: 323, replay memory length: 17416\n",
      "episode: 56, score: 0, global_step_num: 17739, avg loss: 0.0, step: 323, replay memory length: 17739\n",
      "episode: 57, score: 0, global_step_num: 18062, avg loss: 0.0, step: 323, replay memory length: 18062\n",
      "episode: 58, score: 0, global_step_num: 18385, avg loss: 0.0, step: 323, replay memory length: 18385\n",
      "episode: 59, score: 1.0, global_step_num: 18664, avg loss: 0.0, step: 279, replay memory length: 18664\n",
      "episode: 60, score: 1.0, global_step_num: 18765, avg loss: 0.0, step: 101, replay memory length: 18765\n",
      "episode: 61, score: 0, global_step_num: 19088, avg loss: 0.0, step: 323, replay memory length: 19088\n",
      "episode: 62, score: 0, global_step_num: 19411, avg loss: 0.0, step: 323, replay memory length: 19411\n",
      "episode: 63, score: 0, global_step_num: 19734, avg loss: 0.0, step: 323, replay memory length: 19734\n",
      "episode: 64, score: 0, global_step_num: 20057, avg loss: 0.0, step: 323, replay memory length: 20057\n",
      "episode: 65, score: 0, global_step_num: 20380, avg loss: 0.0, step: 323, replay memory length: 20380\n",
      "episode: 66, score: 0, global_step_num: 20703, avg loss: 0.0, step: 323, replay memory length: 20703\n",
      "episode: 67, score: 0, global_step_num: 21026, avg loss: 0.0, step: 323, replay memory length: 21026\n",
      "episode: 68, score: 0, global_step_num: 21349, avg loss: 0.0, step: 323, replay memory length: 21349\n",
      "episode: 69, score: 0, global_step_num: 21672, avg loss: 0.0, step: 323, replay memory length: 21672\n",
      "episode: 70, score: 0, global_step_num: 21995, avg loss: 0.0, step: 323, replay memory length: 21995\n",
      "episode: 71, score: 0, global_step_num: 22318, avg loss: 0.0, step: 323, replay memory length: 22318\n",
      "episode: 72, score: 1.0, global_step_num: 22595, avg loss: 0.0, step: 277, replay memory length: 22595\n",
      "episode: 73, score: 0, global_step_num: 22918, avg loss: 0.0, step: 323, replay memory length: 22918\n",
      "episode: 74, score: 0, global_step_num: 23241, avg loss: 0.0, step: 323, replay memory length: 23241\n",
      "episode: 75, score: 0, global_step_num: 23564, avg loss: 0.0, step: 323, replay memory length: 23564\n",
      "episode: 76, score: 0, global_step_num: 23887, avg loss: 0.0, step: 323, replay memory length: 23887\n",
      "episode: 77, score: 0, global_step_num: 24210, avg loss: 0.0, step: 323, replay memory length: 24210\n",
      "episode: 78, score: 0, global_step_num: 24533, avg loss: 0.0, step: 323, replay memory length: 24533\n",
      "episode: 79, score: 0, global_step_num: 24856, avg loss: 0.0, step: 323, replay memory length: 24856\n",
      "episode: 80, score: 0, global_step_num: 25179, avg loss: 0.0, step: 323, replay memory length: 25179\n",
      "episode: 81, score: 0, global_step_num: 25502, avg loss: 0.0, step: 323, replay memory length: 25502\n",
      "episode: 82, score: 0, global_step_num: 25825, avg loss: 0.0, step: 323, replay memory length: 25825\n",
      "episode: 83, score: 0, global_step_num: 26148, avg loss: 0.0, step: 323, replay memory length: 26148\n",
      "episode: 84, score: 0, global_step_num: 26471, avg loss: 0.0, step: 323, replay memory length: 26471\n",
      "episode: 85, score: 0, global_step_num: 26794, avg loss: 0.0, step: 323, replay memory length: 26794\n",
      "episode: 86, score: 0, global_step_num: 27117, avg loss: 0.0, step: 323, replay memory length: 27117\n",
      "episode: 87, score: 0, global_step_num: 27440, avg loss: 0.0, step: 323, replay memory length: 27440\n",
      "episode: 88, score: 0, global_step_num: 27763, avg loss: 0.0, step: 323, replay memory length: 27763\n",
      "episode: 89, score: 0, global_step_num: 28086, avg loss: 0.0, step: 323, replay memory length: 28086\n",
      "episode: 90, score: 0, global_step_num: 28409, avg loss: 0.0, step: 323, replay memory length: 28409\n",
      "episode: 91, score: 0, global_step_num: 28732, avg loss: 0.0, step: 323, replay memory length: 28732\n",
      "episode: 92, score: 0, global_step_num: 29055, avg loss: 0.0, step: 323, replay memory length: 29055\n",
      "episode: 93, score: 0, global_step_num: 29378, avg loss: 0.0, step: 323, replay memory length: 29378\n",
      "episode: 94, score: 0, global_step_num: 29701, avg loss: 0.0, step: 323, replay memory length: 29701\n",
      "episode: 95, score: 0, global_step_num: 30024, avg loss: 0.0, step: 323, replay memory length: 30024\n",
      "episode: 96, score: 0, global_step_num: 30347, avg loss: 0.0, step: 323, replay memory length: 30347\n",
      "episode: 97, score: 0, global_step_num: 30670, avg loss: 0.0, step: 323, replay memory length: 30670\n",
      "episode: 98, score: 1.0, global_step_num: 30802, avg loss: 0.0, step: 132, replay memory length: 30802\n",
      "episode: 99, score: 0, global_step_num: 31125, avg loss: 0.0, step: 323, replay memory length: 31125\n",
      "episode: 100, score: 0, global_step_num: 31448, avg loss: 0.0, step: 323, replay memory length: 31448\n",
      "episode: 101, score: 0, global_step_num: 31771, avg loss: 0.0, step: 323, replay memory length: 31771\n",
      "episode: 102, score: 0, global_step_num: 32094, avg loss: 0.0, step: 323, replay memory length: 32094\n",
      "episode: 103, score: 0, global_step_num: 32417, avg loss: 0.0, step: 323, replay memory length: 32417\n",
      "episode: 104, score: 0, global_step_num: 32740, avg loss: 0.0, step: 323, replay memory length: 32740\n",
      "episode: 105, score: 0, global_step_num: 33063, avg loss: 0.0, step: 323, replay memory length: 33063\n",
      "episode: 106, score: 0, global_step_num: 33386, avg loss: 0.0, step: 323, replay memory length: 33386\n",
      "episode: 107, score: 0, global_step_num: 33709, avg loss: 0.0, step: 323, replay memory length: 33709\n",
      "episode: 108, score: 0, global_step_num: 34032, avg loss: 0.0, step: 323, replay memory length: 34032\n",
      "episode: 109, score: 0, global_step_num: 34355, avg loss: 0.0, step: 323, replay memory length: 34355\n",
      "episode: 110, score: 0, global_step_num: 34678, avg loss: 0.0, step: 323, replay memory length: 34678\n",
      "episode: 111, score: 1.0, global_step_num: 34815, avg loss: 0.0, step: 137, replay memory length: 34815\n",
      "episode: 112, score: 0, global_step_num: 35138, avg loss: 0.0, step: 323, replay memory length: 35138\n",
      "episode: 113, score: 0, global_step_num: 35461, avg loss: 0.0, step: 323, replay memory length: 35461\n",
      "episode: 114, score: 1.0, global_step_num: 35556, avg loss: 0.0, step: 95, replay memory length: 35556\n",
      "episode: 115, score: 0, global_step_num: 35879, avg loss: 0.0, step: 323, replay memory length: 35879\n",
      "episode: 116, score: 0, global_step_num: 36202, avg loss: 0.0, step: 323, replay memory length: 36202\n",
      "episode: 117, score: 0, global_step_num: 36525, avg loss: 0.0, step: 323, replay memory length: 36525\n",
      "episode: 118, score: 0, global_step_num: 36848, avg loss: 0.0, step: 323, replay memory length: 36848\n",
      "episode: 119, score: 0, global_step_num: 37171, avg loss: 0.0, step: 323, replay memory length: 37171\n",
      "episode: 120, score: 0, global_step_num: 37494, avg loss: 0.0, step: 323, replay memory length: 37494\n",
      "episode: 121, score: 1.0, global_step_num: 37570, avg loss: 0.0, step: 76, replay memory length: 37570\n",
      "episode: 122, score: 0, global_step_num: 37893, avg loss: 0.0, step: 323, replay memory length: 37893\n",
      "episode: 123, score: 0, global_step_num: 38216, avg loss: 0.0, step: 323, replay memory length: 38216\n",
      "episode: 124, score: 0, global_step_num: 38539, avg loss: 0.0, step: 323, replay memory length: 38539\n",
      "episode: 125, score: 0, global_step_num: 38862, avg loss: 0.0, step: 323, replay memory length: 38862\n",
      "episode: 126, score: 0, global_step_num: 39185, avg loss: 0.0, step: 323, replay memory length: 39185\n",
      "episode: 127, score: 1.0, global_step_num: 39490, avg loss: 0.0, step: 305, replay memory length: 39490\n",
      "episode: 128, score: 1.0, global_step_num: 39717, avg loss: 0.0, step: 227, replay memory length: 39717\n",
      "episode: 129, score: 0, global_step_num: 40040, avg loss: 0.0, step: 323, replay memory length: 40040\n",
      "episode: 130, score: 0, global_step_num: 40363, avg loss: 0.0, step: 323, replay memory length: 40363\n",
      "episode: 131, score: 0, global_step_num: 40686, avg loss: 0.0, step: 323, replay memory length: 40686\n",
      "episode: 132, score: 0, global_step_num: 41009, avg loss: 0.0, step: 323, replay memory length: 41009\n",
      "episode: 133, score: 0, global_step_num: 41332, avg loss: 0.0, step: 323, replay memory length: 41332\n",
      "episode: 134, score: 0, global_step_num: 41655, avg loss: 0.0, step: 323, replay memory length: 41655\n",
      "episode: 135, score: 0, global_step_num: 41978, avg loss: 0.0, step: 323, replay memory length: 41978\n",
      "episode: 136, score: 0, global_step_num: 42301, avg loss: 0.0, step: 323, replay memory length: 42301\n",
      "episode: 137, score: 1.0, global_step_num: 42486, avg loss: 0.0, step: 185, replay memory length: 42486\n",
      "episode: 138, score: 1.0, global_step_num: 42784, avg loss: 0.0, step: 298, replay memory length: 42784\n",
      "episode: 139, score: 0, global_step_num: 43107, avg loss: 0.0, step: 323, replay memory length: 43107\n",
      "episode: 140, score: 0, global_step_num: 43430, avg loss: 0.0, step: 323, replay memory length: 43430\n",
      "episode: 141, score: 0, global_step_num: 43753, avg loss: 0.0, step: 323, replay memory length: 43753\n",
      "episode: 142, score: 0, global_step_num: 44076, avg loss: 0.0, step: 323, replay memory length: 44076\n",
      "episode: 143, score: 0, global_step_num: 44399, avg loss: 0.0, step: 323, replay memory length: 44399\n",
      "episode: 144, score: 0, global_step_num: 44722, avg loss: 0.0, step: 323, replay memory length: 44722\n",
      "episode: 145, score: 0, global_step_num: 45045, avg loss: 0.0, step: 323, replay memory length: 45045\n",
      "episode: 146, score: 0, global_step_num: 45368, avg loss: 0.0, step: 323, replay memory length: 45368\n",
      "episode: 147, score: 0, global_step_num: 45691, avg loss: 0.0, step: 323, replay memory length: 45691\n",
      "episode: 148, score: 0, global_step_num: 46014, avg loss: 0.0, step: 323, replay memory length: 46014\n",
      "episode: 149, score: 0, global_step_num: 46337, avg loss: 0.0, step: 323, replay memory length: 46337\n",
      "episode: 150, score: 1.0, global_step_num: 46444, avg loss: 0.0, step: 107, replay memory length: 46444\n",
      "episode: 151, score: 0, global_step_num: 46767, avg loss: 0.0, step: 323, replay memory length: 46767\n",
      "episode: 152, score: 0, global_step_num: 47090, avg loss: 0.0, step: 323, replay memory length: 47090\n",
      "episode: 153, score: 0, global_step_num: 47413, avg loss: 0.0, step: 323, replay memory length: 47413\n",
      "episode: 154, score: 0, global_step_num: 47736, avg loss: 0.0, step: 323, replay memory length: 47736\n",
      "episode: 155, score: 0, global_step_num: 48059, avg loss: 0.0, step: 323, replay memory length: 48059\n",
      "episode: 156, score: 0, global_step_num: 48382, avg loss: 0.0, step: 323, replay memory length: 48382\n",
      "episode: 157, score: 0, global_step_num: 48705, avg loss: 0.0, step: 323, replay memory length: 48705\n",
      "episode: 158, score: 1.0, global_step_num: 48805, avg loss: 0.0, step: 100, replay memory length: 48805\n",
      "episode: 159, score: 0, global_step_num: 49128, avg loss: 0.0, step: 323, replay memory length: 49128\n",
      "episode: 160, score: 0, global_step_num: 49451, avg loss: 0.0, step: 323, replay memory length: 49451\n",
      "episode: 161, score: 0, global_step_num: 49774, avg loss: 0.0, step: 323, replay memory length: 49774\n",
      "episode: 162, score: 0, global_step_num: 50097, avg loss: 0.0004855279232749799, step: 323, replay memory length: 50097\n",
      "episode: 163, score: 0, global_step_num: 50420, avg loss: 0.004584416409042749, step: 323, replay memory length: 50420\n",
      "episode: 164, score: 1.0, global_step_num: 50631, avg loss: 0.005421369668273962, step: 211, replay memory length: 50631\n",
      "episode: 165, score: 0, global_step_num: 50954, avg loss: 0.004891626011907219, step: 323, replay memory length: 50954\n",
      "episode: 166, score: 1.0, global_step_num: 51238, avg loss: 0.003074355562321344, step: 284, replay memory length: 51238\n",
      "episode: 167, score: 0, global_step_num: 51561, avg loss: 0.003184329869828692, step: 323, replay memory length: 51561\n",
      "episode: 168, score: 1.0, global_step_num: 51794, avg loss: 0.004985413481929173, step: 233, replay memory length: 51794\n",
      "episode: 169, score: 0, global_step_num: 52117, avg loss: 0.0032679333593754025, step: 323, replay memory length: 52117\n",
      "episode: 170, score: 0, global_step_num: 52440, avg loss: 0.003682541350452298, step: 323, replay memory length: 52440\n",
      "episode: 171, score: 1.0, global_step_num: 52693, avg loss: 0.002845935182877252, step: 253, replay memory length: 52693\n",
      "episode: 172, score: 0, global_step_num: 53016, avg loss: 0.0035514955614264925, step: 323, replay memory length: 53016\n",
      "episode: 173, score: 0, global_step_num: 53339, avg loss: 0.0022332807087703304, step: 323, replay memory length: 53339\n",
      "episode: 174, score: 1.0, global_step_num: 53526, avg loss: 0.0027220653505269986, step: 187, replay memory length: 53526\n",
      "episode: 175, score: 0, global_step_num: 53849, avg loss: 0.003518904270725669, step: 323, replay memory length: 53849\n",
      "episode: 176, score: 1.0, global_step_num: 53961, avg loss: 0.0027902739136119897, step: 112, replay memory length: 53961\n",
      "episode: 177, score: 0, global_step_num: 54284, avg loss: 0.0032895094851770217, step: 323, replay memory length: 54284\n",
      "episode: 178, score: 0, global_step_num: 54607, avg loss: 0.0031017695842544156, step: 323, replay memory length: 54607\n",
      "episode: 179, score: 0, global_step_num: 54930, avg loss: 0.0024760488008653374, step: 323, replay memory length: 54930\n",
      "episode: 180, score: 0, global_step_num: 55253, avg loss: 0.00238009667623303, step: 323, replay memory length: 55253\n",
      "episode: 181, score: 0, global_step_num: 55576, avg loss: 0.0030559651208721156, step: 323, replay memory length: 55576\n",
      "episode: 182, score: 0, global_step_num: 55899, avg loss: 0.0031224347588449577, step: 323, replay memory length: 55899\n",
      "episode: 183, score: 0, global_step_num: 56222, avg loss: 0.002294801054076827, step: 323, replay memory length: 56222\n",
      "episode: 184, score: 0, global_step_num: 56545, avg loss: 0.003012498145599182, step: 323, replay memory length: 56545\n",
      "episode: 185, score: 0, global_step_num: 56868, avg loss: 0.0025410788100255254, step: 323, replay memory length: 56868\n",
      "episode: 186, score: 0, global_step_num: 57191, avg loss: 0.0019724955300543657, step: 323, replay memory length: 57191\n",
      "episode: 187, score: 0, global_step_num: 57514, avg loss: 0.0024025512803146336, step: 323, replay memory length: 57514\n",
      "episode: 188, score: 0, global_step_num: 57837, avg loss: 0.002676367624834691, step: 323, replay memory length: 57837\n",
      "episode: 189, score: 0, global_step_num: 58160, avg loss: 0.002328822645238226, step: 323, replay memory length: 58160\n",
      "episode: 190, score: 0, global_step_num: 58483, avg loss: 0.0017267366857586887, step: 323, replay memory length: 58483\n",
      "episode: 191, score: 0, global_step_num: 58806, avg loss: 0.0023039855831521205, step: 323, replay memory length: 58806\n",
      "episode: 192, score: 0, global_step_num: 59129, avg loss: 0.0021919318027324016, step: 323, replay memory length: 59129\n",
      "episode: 193, score: 0, global_step_num: 59452, avg loss: 0.0027823079162884678, step: 323, replay memory length: 59452\n",
      "episode: 194, score: 0, global_step_num: 59775, avg loss: 0.002434007486531849, step: 323, replay memory length: 59775\n",
      "episode: 195, score: 0, global_step_num: 60098, avg loss: 0.002210755795843203, step: 323, replay memory length: 60098\n",
      "episode: 196, score: 0, global_step_num: 60421, avg loss: 0.002337177186912106, step: 323, replay memory length: 60421\n",
      "episode: 197, score: 0, global_step_num: 60744, avg loss: 0.002124006298752073, step: 323, replay memory length: 60744\n",
      "episode: 198, score: 0, global_step_num: 61067, avg loss: 0.0026214343714075234, step: 323, replay memory length: 61067\n",
      "episode: 199, score: 0, global_step_num: 61390, avg loss: 0.0018212705587698096, step: 323, replay memory length: 61390\n",
      "episode: 200, score: 1.0, global_step_num: 61435, avg loss: 0.0026457462641701567, step: 45, replay memory length: 61435\n",
      "episode: 201, score: 0, global_step_num: 61758, avg loss: 0.0023475761750527194, step: 323, replay memory length: 61758\n",
      "episode: 202, score: 0, global_step_num: 62081, avg loss: 0.0019875993882909624, step: 323, replay memory length: 62081\n",
      "episode: 203, score: 0, global_step_num: 62404, avg loss: 0.0015210214420987636, step: 323, replay memory length: 62404\n",
      "episode: 204, score: 0, global_step_num: 62727, avg loss: 0.0026070706139889187, step: 323, replay memory length: 62727\n",
      "episode: 205, score: 0, global_step_num: 63050, avg loss: 0.0024432982989946767, step: 323, replay memory length: 63050\n",
      "episode: 206, score: 0, global_step_num: 63373, avg loss: 0.002377897240375129, step: 323, replay memory length: 63373\n",
      "episode: 207, score: 1.0, global_step_num: 63570, avg loss: 0.0019740148181142847, step: 197, replay memory length: 63570\n",
      "episode: 208, score: 0, global_step_num: 63893, avg loss: 0.0018713105892820524, step: 323, replay memory length: 63893\n",
      "episode: 209, score: 0, global_step_num: 64216, avg loss: 0.0021782573616680786, step: 323, replay memory length: 64216\n",
      "episode: 210, score: 0, global_step_num: 64539, avg loss: 0.002028925690631726, step: 323, replay memory length: 64539\n",
      "episode: 212, score: 0, global_step_num: 65185, avg loss: 0.0020960581913086656, step: 323, replay memory length: 65185\n",
      "episode: 213, score: 0, global_step_num: 65508, avg loss: 0.002156256919031301, step: 323, replay memory length: 65508\n",
      "episode: 214, score: 0, global_step_num: 65831, avg loss: 0.0023283612325357473, step: 323, replay memory length: 65831\n",
      "episode: 215, score: 0, global_step_num: 66154, avg loss: 0.002152263263683479, step: 323, replay memory length: 66154\n",
      "episode: 216, score: 0, global_step_num: 66477, avg loss: 0.0018996288945007547, step: 323, replay memory length: 66477\n",
      "episode: 217, score: 0, global_step_num: 66800, avg loss: 0.002336828283426288, step: 323, replay memory length: 66800\n",
      "episode: 218, score: 0, global_step_num: 67123, avg loss: 0.0022042091680110733, step: 323, replay memory length: 67123\n",
      "episode: 219, score: 1.0, global_step_num: 67231, avg loss: 0.002287938630329504, step: 108, replay memory length: 67231\n",
      "episode: 220, score: 1.0, global_step_num: 67432, avg loss: 0.001954297309865395, step: 201, replay memory length: 67432\n",
      "episode: 221, score: 0, global_step_num: 67755, avg loss: 0.0019134515332440206, step: 323, replay memory length: 67755\n",
      "episode: 222, score: 1.0, global_step_num: 67891, avg loss: 0.002056448827033819, step: 136, replay memory length: 67891\n",
      "episode: 223, score: 0, global_step_num: 68214, avg loss: 0.0026158185159563985, step: 323, replay memory length: 68214\n",
      "episode: 224, score: 0, global_step_num: 68537, avg loss: 0.0018892848445227592, step: 323, replay memory length: 68537\n",
      "episode: 225, score: 0, global_step_num: 68860, avg loss: 0.0021148264278608537, step: 323, replay memory length: 68860\n",
      "episode: 226, score: 0, global_step_num: 69183, avg loss: 0.0025375086319028317, step: 323, replay memory length: 69183\n",
      "episode: 227, score: 0, global_step_num: 69506, avg loss: 0.0019039081742634456, step: 323, replay memory length: 69506\n",
      "episode: 228, score: 0, global_step_num: 69829, avg loss: 0.002176969211709674, step: 323, replay memory length: 69829\n",
      "episode: 229, score: 0, global_step_num: 70152, avg loss: 0.001927211045626974, step: 323, replay memory length: 70152\n",
      "episode: 230, score: 0, global_step_num: 70475, avg loss: 0.002441824060287536, step: 323, replay memory length: 70475\n",
      "episode: 231, score: 1.0, global_step_num: 70721, avg loss: 0.0021756304809873025, step: 246, replay memory length: 70721\n",
      "episode: 232, score: 0, global_step_num: 71044, avg loss: 0.0023119924512839387, step: 323, replay memory length: 71044\n",
      "episode: 233, score: 0, global_step_num: 71367, avg loss: 0.0016847868891803302, step: 323, replay memory length: 71367\n",
      "episode: 234, score: 0, global_step_num: 71690, avg loss: 0.0021186586542881, step: 323, replay memory length: 71690\n",
      "episode: 235, score: 0, global_step_num: 72013, avg loss: 0.0021322049526905445, step: 323, replay memory length: 72013\n",
      "episode: 236, score: 0, global_step_num: 72336, avg loss: 0.0014836386180888366, step: 323, replay memory length: 72336\n",
      "episode: 237, score: 0, global_step_num: 72659, avg loss: 0.0023518107502055194, step: 323, replay memory length: 72659\n",
      "episode: 238, score: 0, global_step_num: 72982, avg loss: 0.0016518340722209064, step: 323, replay memory length: 72982\n",
      "episode: 239, score: 0, global_step_num: 73305, avg loss: 0.0017014807519343362, step: 323, replay memory length: 73305\n",
      "episode: 240, score: 0, global_step_num: 73628, avg loss: 0.001843304891516267, step: 323, replay memory length: 73628\n",
      "episode: 241, score: 0, global_step_num: 73951, avg loss: 0.0016508099392767437, step: 323, replay memory length: 73951\n",
      "episode: 242, score: 0, global_step_num: 74274, avg loss: 0.0017529991474495247, step: 323, replay memory length: 74274\n",
      "episode: 243, score: 0, global_step_num: 74597, avg loss: 0.001637555408686538, step: 323, replay memory length: 74597\n",
      "episode: 244, score: 0, global_step_num: 74920, avg loss: 0.002305996051364214, step: 323, replay memory length: 74920\n",
      "episode: 245, score: 0, global_step_num: 75243, avg loss: 0.0017747457495546988, step: 323, replay memory length: 75243\n",
      "episode: 246, score: 0, global_step_num: 75566, avg loss: 0.001460890708816687, step: 323, replay memory length: 75566\n",
      "episode: 247, score: 0, global_step_num: 75889, avg loss: 0.002123911664837201, step: 323, replay memory length: 75889\n",
      "episode: 248, score: 0, global_step_num: 76212, avg loss: 0.002210131637660397, step: 323, replay memory length: 76212\n",
      "episode: 249, score: 0, global_step_num: 76535, avg loss: 0.0012054829568275156, step: 323, replay memory length: 76535\n",
      "episode: 250, score: 0, global_step_num: 76858, avg loss: 0.0018542992498178897, step: 323, replay memory length: 76858\n",
      "episode: 251, score: 0, global_step_num: 77181, avg loss: 0.0019081260255657225, step: 323, replay memory length: 77181\n",
      "episode: 252, score: 0, global_step_num: 77504, avg loss: 0.0022230217065373134, step: 323, replay memory length: 77504\n",
      "episode: 253, score: 0, global_step_num: 77827, avg loss: 0.0015560918830800487, step: 323, replay memory length: 77827\n",
      "episode: 254, score: 0, global_step_num: 78150, avg loss: 0.0018088504215140612, step: 323, replay memory length: 78150\n",
      "episode: 255, score: 0, global_step_num: 78473, avg loss: 0.0019268329180152422, step: 323, replay memory length: 78473\n",
      "episode: 256, score: 0, global_step_num: 78796, avg loss: 0.0017589872941666178, step: 323, replay memory length: 78796\n",
      "episode: 257, score: 0, global_step_num: 79119, avg loss: 0.0021794542329642767, step: 323, replay memory length: 79119\n",
      "episode: 258, score: 0, global_step_num: 79442, avg loss: 0.001213857321369234, step: 323, replay memory length: 79442\n",
      "episode: 259, score: 0, global_step_num: 79765, avg loss: 0.0020130681051755443, step: 323, replay memory length: 79765\n",
      "episode: 260, score: 0, global_step_num: 80088, avg loss: 0.0014143854703957779, step: 323, replay memory length: 80088\n",
      "episode: 261, score: 0, global_step_num: 80411, avg loss: 0.0022295349103208907, step: 323, replay memory length: 80411\n",
      "episode: 262, score: 0, global_step_num: 80734, avg loss: 0.0021387523670638293, step: 323, replay memory length: 80734\n",
      "episode: 263, score: 0, global_step_num: 81057, avg loss: 0.001670909220052247, step: 323, replay memory length: 81057\n",
      "episode: 264, score: 0, global_step_num: 81380, avg loss: 0.002142653968679749, step: 323, replay memory length: 81380\n",
      "episode: 265, score: 0, global_step_num: 81703, avg loss: 0.0019669223749514916, step: 323, replay memory length: 81703\n",
      "episode: 266, score: 0, global_step_num: 82026, avg loss: 0.001541499223497089, step: 323, replay memory length: 82026\n",
      "episode: 267, score: 0, global_step_num: 82349, avg loss: 0.0016123351559921948, step: 323, replay memory length: 82349\n",
      "episode: 268, score: 0, global_step_num: 82672, avg loss: 0.00206586617313076, step: 323, replay memory length: 82672\n",
      "episode: 269, score: 0, global_step_num: 82995, avg loss: 0.0017926845127530053, step: 323, replay memory length: 82995\n",
      "episode: 270, score: 1.0, global_step_num: 83291, avg loss: 0.0016113319834679765, step: 296, replay memory length: 83291\n",
      "episode: 271, score: 1.0, global_step_num: 83386, avg loss: 0.0016186209456990534, step: 95, replay memory length: 83386\n",
      "episode: 272, score: 0, global_step_num: 83709, avg loss: 0.0023656192616718463, step: 323, replay memory length: 83709\n",
      "episode: 273, score: 0, global_step_num: 84032, avg loss: 0.002016524254054064, step: 323, replay memory length: 84032\n",
      "episode: 274, score: 0, global_step_num: 84355, avg loss: 0.0016108093778872418, step: 323, replay memory length: 84355\n",
      "episode: 275, score: 0, global_step_num: 84678, avg loss: 0.0011289915546006091, step: 323, replay memory length: 84678\n",
      "episode: 276, score: 0, global_step_num: 85001, avg loss: 0.0019539226440916176, step: 323, replay memory length: 85001\n",
      "episode: 277, score: 0, global_step_num: 85324, avg loss: 0.0020220101160328555, step: 323, replay memory length: 85324\n",
      "episode: 278, score: 0, global_step_num: 85647, avg loss: 0.0017922679613581888, step: 323, replay memory length: 85647\n",
      "episode: 279, score: 0, global_step_num: 85970, avg loss: 0.001254572213066879, step: 323, replay memory length: 85970\n",
      "episode: 280, score: 0, global_step_num: 86293, avg loss: 0.0013593041841250223, step: 323, replay memory length: 86293\n",
      "episode: 281, score: 0, global_step_num: 86616, avg loss: 0.0019590091695490712, step: 323, replay memory length: 86616\n",
      "episode: 282, score: 0, global_step_num: 86939, avg loss: 0.002014732877602344, step: 323, replay memory length: 86939\n",
      "episode: 283, score: 0, global_step_num: 87262, avg loss: 0.001812307628230655, step: 323, replay memory length: 87262\n",
      "episode: 284, score: 0, global_step_num: 87585, avg loss: 0.0014450474371795945, step: 323, replay memory length: 87585\n",
      "episode: 285, score: 0, global_step_num: 87908, avg loss: 0.0022813793488712804, step: 323, replay memory length: 87908\n",
      "episode: 286, score: 0, global_step_num: 88231, avg loss: 0.001540649794038619, step: 323, replay memory length: 88231\n",
      "episode: 287, score: 0, global_step_num: 88554, avg loss: 0.0019237032540314817, step: 323, replay memory length: 88554\n",
      "episode: 288, score: 0, global_step_num: 88877, avg loss: 0.0019132320960389753, step: 323, replay memory length: 88877\n",
      "episode: 289, score: 0, global_step_num: 89200, avg loss: 0.0013814570052442829, step: 323, replay memory length: 89200\n",
      "episode: 290, score: 0, global_step_num: 89523, avg loss: 0.002051079672057859, step: 323, replay memory length: 89523\n",
      "episode: 291, score: 0, global_step_num: 89846, avg loss: 0.0024026889076659433, step: 323, replay memory length: 89846\n",
      "episode: 292, score: 0, global_step_num: 90169, avg loss: 0.0012951192484364437, step: 323, replay memory length: 90169\n",
      "episode: 293, score: 0, global_step_num: 90492, avg loss: 0.0013344230550157855, step: 323, replay memory length: 90492\n",
      "episode: 294, score: 0, global_step_num: 90815, avg loss: 0.0017839886202484939, step: 323, replay memory length: 90815\n",
      "episode: 295, score: 0, global_step_num: 91138, avg loss: 0.002170613377918239, step: 323, replay memory length: 91138\n",
      "episode: 296, score: 0, global_step_num: 91461, avg loss: 0.0019873389331423654, step: 323, replay memory length: 91461\n",
      "episode: 297, score: 0, global_step_num: 91784, avg loss: 0.00146411405621733, step: 323, replay memory length: 91784\n",
      "episode: 298, score: 0, global_step_num: 92107, avg loss: 0.0021767465019821926, step: 323, replay memory length: 92107\n",
      "episode: 299, score: 0, global_step_num: 92430, avg loss: 0.001687005795534596, step: 323, replay memory length: 92430\n",
      "episode: 300, score: 0, global_step_num: 92753, avg loss: 0.002202185628214496, step: 323, replay memory length: 92753\n",
      "episode: 301, score: 0, global_step_num: 93076, avg loss: 0.001599944131155011, step: 323, replay memory length: 93076\n",
      "episode: 302, score: 0, global_step_num: 93399, avg loss: 0.0019707556205280905, step: 323, replay memory length: 93399\n",
      "episode: 303, score: 0, global_step_num: 93722, avg loss: 0.0016000857342117654, step: 323, replay memory length: 93722\n",
      "episode: 304, score: 0, global_step_num: 94045, avg loss: 0.0014938830942892113, step: 323, replay memory length: 94045\n",
      "episode: 305, score: 0, global_step_num: 94368, avg loss: 0.002054900233604532, step: 323, replay memory length: 94368\n",
      "episode: 306, score: 0, global_step_num: 94691, avg loss: 0.001745736059785131, step: 323, replay memory length: 94691\n",
      "episode: 307, score: 0, global_step_num: 95014, avg loss: 0.0016573432065669416, step: 323, replay memory length: 95014\n",
      "episode: 308, score: 0, global_step_num: 95337, avg loss: 0.0014792570250350364, step: 323, replay memory length: 95337\n",
      "episode: 309, score: 0, global_step_num: 95660, avg loss: 0.0014432375019563038, step: 323, replay memory length: 95660\n",
      "episode: 310, score: 0, global_step_num: 95983, avg loss: 0.0017399264013018931, step: 323, replay memory length: 95983\n",
      "episode: 311, score: 0, global_step_num: 96306, avg loss: 0.0018121020331632886, step: 323, replay memory length: 96306\n",
      "episode: 312, score: 0, global_step_num: 96629, avg loss: 0.002003685895388201, step: 323, replay memory length: 96629\n",
      "episode: 313, score: 0, global_step_num: 96952, avg loss: 0.0015022786223868791, step: 323, replay memory length: 96952\n",
      "episode: 314, score: 0, global_step_num: 97275, avg loss: 0.0015303043170634362, step: 323, replay memory length: 97275\n",
      "episode: 315, score: 0, global_step_num: 97598, avg loss: 0.0012606992821797111, step: 323, replay memory length: 97598\n",
      "episode: 316, score: 0, global_step_num: 97921, avg loss: 0.0016485502423554176, step: 323, replay memory length: 97921\n",
      "episode: 317, score: 1.0, global_step_num: 98232, avg loss: 0.0016263645581699264, step: 311, replay memory length: 98232\n",
      "episode: 318, score: 0, global_step_num: 98555, avg loss: 0.0019224891555878504, step: 323, replay memory length: 98555\n",
      "episode: 319, score: 0, global_step_num: 98878, avg loss: 0.001582387149780175, step: 323, replay memory length: 98878\n",
      "episode: 320, score: 0, global_step_num: 99201, avg loss: 0.0013750903544803878, step: 323, replay memory length: 99201\n",
      "episode: 321, score: 1.0, global_step_num: 99400, avg loss: 0.0012572050096085277, step: 199, replay memory length: 99400\n",
      "episode: 322, score: 0, global_step_num: 99723, avg loss: 0.00166886252091215, step: 323, replay memory length: 99723\n",
      "episode: 323, score: 1.0, global_step_num: 99995, avg loss: 0.001326497514643212, step: 272, replay memory length: 99995\n",
      "episode: 324, score: 1.0, global_step_num: 100217, avg loss: 0.00145091960339496, step: 222, replay memory length: 100217\n",
      "episode: 325, score: 0, global_step_num: 100540, avg loss: 0.0016570328701898734, step: 323, replay memory length: 100540\n",
      "episode: 326, score: 0, global_step_num: 100863, avg loss: 0.00159731482256437, step: 323, replay memory length: 100863\n",
      "episode: 327, score: 0, global_step_num: 101186, avg loss: 0.0014576536845755076, step: 323, replay memory length: 101186\n",
      "episode: 328, score: 0, global_step_num: 101509, avg loss: 0.001219329873104248, step: 323, replay memory length: 101509\n",
      "episode: 329, score: 0, global_step_num: 101832, avg loss: 0.0015645251466985738, step: 323, replay memory length: 101832\n",
      "episode: 330, score: 0, global_step_num: 102155, avg loss: 0.0019482937097265519, step: 323, replay memory length: 102155\n",
      "episode: 331, score: 1.0, global_step_num: 102375, avg loss: 0.0020834554995748144, step: 220, replay memory length: 102375\n",
      "episode: 332, score: 0, global_step_num: 102698, avg loss: 0.0018663601734488814, step: 323, replay memory length: 102698\n",
      "episode: 333, score: 0, global_step_num: 103021, avg loss: 0.001403794731462649, step: 323, replay memory length: 103021\n",
      "episode: 334, score: 1.0, global_step_num: 103323, avg loss: 0.0014119445908971897, step: 302, replay memory length: 103323\n",
      "episode: 335, score: 0, global_step_num: 103646, avg loss: 0.001181759309798542, step: 323, replay memory length: 103646\n",
      "episode: 336, score: 0, global_step_num: 103969, avg loss: 0.001839181829674982, step: 323, replay memory length: 103969\n",
      "episode: 337, score: 0, global_step_num: 104292, avg loss: 0.0019912982412087763, step: 323, replay memory length: 104292\n",
      "episode: 338, score: 0, global_step_num: 104615, avg loss: 0.0014293877007736401, step: 323, replay memory length: 104615\n",
      "episode: 339, score: 0, global_step_num: 104938, avg loss: 0.001938692301976322, step: 323, replay memory length: 104938\n",
      "episode: 340, score: 0, global_step_num: 105261, avg loss: 0.0013642876244175737, step: 323, replay memory length: 105261\n",
      "episode: 341, score: 0, global_step_num: 105584, avg loss: 0.0008833170697116572, step: 323, replay memory length: 105584\n",
      "episode: 342, score: 0, global_step_num: 105907, avg loss: 0.0017776074566523005, step: 323, replay memory length: 105907\n",
      "episode: 343, score: 0, global_step_num: 106230, avg loss: 0.0017390095635257392, step: 323, replay memory length: 106230\n",
      "episode: 344, score: 0, global_step_num: 106553, avg loss: 0.0021079138718551878, step: 323, replay memory length: 106553\n",
      "episode: 345, score: 0, global_step_num: 106876, avg loss: 0.0015234554703591344, step: 323, replay memory length: 106876\n",
      "episode: 346, score: 1.0, global_step_num: 107139, avg loss: 0.0012571928515213247, step: 263, replay memory length: 107139\n",
      "episode: 347, score: 0, global_step_num: 107462, avg loss: 0.0013383786481314165, step: 323, replay memory length: 107462\n",
      "episode: 348, score: 0, global_step_num: 107785, avg loss: 0.0015765033306991147, step: 323, replay memory length: 107785\n",
      "episode: 349, score: 0, global_step_num: 108108, avg loss: 0.0017880591173535453, step: 323, replay memory length: 108108\n",
      "episode: 350, score: 0, global_step_num: 108431, avg loss: 0.0016111092440599353, step: 323, replay memory length: 108431\n",
      "episode: 351, score: 0, global_step_num: 108754, avg loss: 0.0016062332082605979, step: 323, replay memory length: 108754\n",
      "episode: 352, score: 0, global_step_num: 109077, avg loss: 0.0014694371184107951, step: 323, replay memory length: 109077\n",
      "episode: 353, score: 0, global_step_num: 109400, avg loss: 0.0010881622905765515, step: 323, replay memory length: 109400\n",
      "episode: 354, score: 1.0, global_step_num: 109663, avg loss: 0.001844800663743471, step: 263, replay memory length: 109663\n",
      "episode: 355, score: 1.0, global_step_num: 109984, avg loss: 0.0015359378683830623, step: 321, replay memory length: 109984\n",
      "episode: 356, score: 0, global_step_num: 110307, avg loss: 0.002056420629547918, step: 323, replay memory length: 110307\n",
      "episode: 357, score: 1.0, global_step_num: 110470, avg loss: 0.0017240336361210435, step: 163, replay memory length: 110470\n",
      "episode: 358, score: 0, global_step_num: 110793, avg loss: 0.0019694565089368845, step: 323, replay memory length: 110793\n",
      "episode: 359, score: 0, global_step_num: 111116, avg loss: 0.001672799351950355, step: 323, replay memory length: 111116\n",
      "episode: 360, score: 0, global_step_num: 111439, avg loss: 0.0013945766986749512, step: 323, replay memory length: 111439\n",
      "episode: 361, score: 0, global_step_num: 111762, avg loss: 0.0016790166557409231, step: 323, replay memory length: 111762\n",
      "episode: 362, score: 0, global_step_num: 112085, avg loss: 0.0014141997730761032, step: 323, replay memory length: 112085\n",
      "episode: 363, score: 0, global_step_num: 112408, avg loss: 0.001581755343991499, step: 323, replay memory length: 112408\n",
      "episode: 364, score: 0, global_step_num: 112731, avg loss: 0.001323509219328792, step: 323, replay memory length: 112731\n",
      "episode: 365, score: 0, global_step_num: 113054, avg loss: 0.001637161416125174, step: 323, replay memory length: 113054\n",
      "episode: 366, score: 0, global_step_num: 113377, avg loss: 0.0013896123751444569, step: 323, replay memory length: 113377\n",
      "episode: 367, score: 1.0, global_step_num: 113417, avg loss: 0.0017000444381437773, step: 40, replay memory length: 113417\n",
      "episode: 368, score: 1.0, global_step_num: 113624, avg loss: 0.0015885654573948057, step: 207, replay memory length: 113624\n",
      "episode: 369, score: 0, global_step_num: 113947, avg loss: 0.0012448299241790575, step: 323, replay memory length: 113947\n",
      "episode: 370, score: 0, global_step_num: 114270, avg loss: 0.001749569668421878, step: 323, replay memory length: 114270\n",
      "episode: 371, score: 1.0, global_step_num: 114523, avg loss: 0.0014108319351306218, step: 253, replay memory length: 114523\n",
      "episode: 372, score: 0, global_step_num: 114846, avg loss: 0.0023748540278893276, step: 323, replay memory length: 114846\n",
      "episode: 373, score: 1.0, global_step_num: 115169, avg loss: 0.0014585709870499545, step: 323, replay memory length: 115169\n",
      "episode: 374, score: 0, global_step_num: 115492, avg loss: 0.002092892771382621, step: 323, replay memory length: 115492\n",
      "episode: 375, score: 0, global_step_num: 115815, avg loss: 0.0016812082558570762, step: 323, replay memory length: 115815\n",
      "episode: 376, score: 0, global_step_num: 116138, avg loss: 0.0011980477690736316, step: 323, replay memory length: 116138\n",
      "episode: 377, score: 0, global_step_num: 116461, avg loss: 0.0016351318325532787, step: 323, replay memory length: 116461\n",
      "episode: 378, score: 0, global_step_num: 116784, avg loss: 0.0011960336838123726, step: 323, replay memory length: 116784\n",
      "episode: 379, score: 0, global_step_num: 117107, avg loss: 0.0016982248516994075, step: 323, replay memory length: 117107\n",
      "episode: 380, score: 0, global_step_num: 117430, avg loss: 0.0014464624375064583, step: 323, replay memory length: 117430\n",
      "episode: 381, score: 0, global_step_num: 117753, avg loss: 0.0014331728876168087, step: 323, replay memory length: 117753\n",
      "episode: 382, score: 0, global_step_num: 118076, avg loss: 0.0018016241613709985, step: 323, replay memory length: 118076\n",
      "episode: 383, score: 1.0, global_step_num: 118162, avg loss: 0.0018003000733970535, step: 86, replay memory length: 118162\n",
      "episode: 384, score: 0, global_step_num: 118485, avg loss: 0.0012619190143629705, step: 323, replay memory length: 118485\n",
      "episode: 385, score: 0, global_step_num: 118808, avg loss: 0.0021288564460916434, step: 323, replay memory length: 118808\n",
      "episode: 386, score: 1.0, global_step_num: 119078, avg loss: 0.0012826997159343725, step: 270, replay memory length: 119078\n",
      "episode: 387, score: 0, global_step_num: 119401, avg loss: 0.0016776397241732124, step: 323, replay memory length: 119401\n",
      "episode: 388, score: 0, global_step_num: 119724, avg loss: 0.0011881994795131551, step: 323, replay memory length: 119724\n",
      "episode: 389, score: 0, global_step_num: 120047, avg loss: 0.0016975410406488967, step: 323, replay memory length: 120047\n",
      "episode: 390, score: 0, global_step_num: 120370, avg loss: 0.001517711911920649, step: 323, replay memory length: 120370\n",
      "episode: 391, score: 0, global_step_num: 120693, avg loss: 0.0015182031314507523, step: 323, replay memory length: 120693\n",
      "episode: 392, score: 0, global_step_num: 121016, avg loss: 0.0016929819873746474, step: 323, replay memory length: 121016\n",
      "episode: 393, score: 0, global_step_num: 121339, avg loss: 0.0016595923885299958, step: 323, replay memory length: 121339\n",
      "episode: 394, score: 0, global_step_num: 121662, avg loss: 0.0020960942548994997, step: 323, replay memory length: 121662\n",
      "episode: 395, score: 0, global_step_num: 121985, avg loss: 0.0013096730118228072, step: 323, replay memory length: 121985\n",
      "episode: 396, score: 0, global_step_num: 122308, avg loss: 0.0013891404062833148, step: 323, replay memory length: 122308\n",
      "episode: 397, score: 0, global_step_num: 122631, avg loss: 0.0019497200272873823, step: 323, replay memory length: 122631\n",
      "episode: 398, score: 0, global_step_num: 122954, avg loss: 0.0013675248532443772, step: 323, replay memory length: 122954\n",
      "episode: 399, score: 0, global_step_num: 123277, avg loss: 0.0012197029595670576, step: 323, replay memory length: 123277\n",
      "episode: 400, score: 1.0, global_step_num: 123505, avg loss: 0.001793201834149378, step: 228, replay memory length: 123505\n",
      "episode: 401, score: 0, global_step_num: 123828, avg loss: 0.0015201529601116515, step: 323, replay memory length: 123828\n",
      "episode: 402, score: 1.0, global_step_num: 124105, avg loss: 0.0018546268904325249, step: 277, replay memory length: 124105\n",
      "episode: 403, score: 0, global_step_num: 124428, avg loss: 0.0015683796775823337, step: 323, replay memory length: 124428\n",
      "episode: 404, score: 0, global_step_num: 124751, avg loss: 0.0018123808930325114, step: 323, replay memory length: 124751\n",
      "episode: 405, score: 0, global_step_num: 125074, avg loss: 0.0014821224329679475, step: 323, replay memory length: 125074\n",
      "episode: 406, score: 0, global_step_num: 125397, avg loss: 0.0015057334280740651, step: 323, replay memory length: 125397\n",
      "episode: 407, score: 0, global_step_num: 125720, avg loss: 0.0014202258120061934, step: 323, replay memory length: 125720\n",
      "episode: 408, score: 0, global_step_num: 126043, avg loss: 0.0016514376213826525, step: 323, replay memory length: 126043\n",
      "episode: 409, score: 0, global_step_num: 126366, avg loss: 0.0017337465350276552, step: 323, replay memory length: 126366\n",
      "episode: 410, score: 0, global_step_num: 126689, avg loss: 0.002197104101446923, step: 323, replay memory length: 126689\n",
      "episode: 411, score: 0, global_step_num: 127012, avg loss: 0.0013972252322265453, step: 323, replay memory length: 127012\n",
      "episode: 412, score: 0, global_step_num: 127335, avg loss: 0.0016042763917069325, step: 323, replay memory length: 127335\n",
      "episode: 413, score: 0, global_step_num: 127658, avg loss: 0.001745781285349645, step: 323, replay memory length: 127658\n",
      "episode: 414, score: 0, global_step_num: 127981, avg loss: 0.0014810145911507435, step: 323, replay memory length: 127981\n",
      "episode: 415, score: 1.0, global_step_num: 128264, avg loss: 0.0016519840225263074, step: 283, replay memory length: 128264\n",
      "episode: 416, score: 0, global_step_num: 128587, avg loss: 0.0016800154714809125, step: 323, replay memory length: 128587\n",
      "episode: 417, score: 0, global_step_num: 128910, avg loss: 0.001619257663731124, step: 323, replay memory length: 128910\n",
      "episode: 418, score: 0, global_step_num: 129233, avg loss: 0.0017364888034121478, step: 323, replay memory length: 129233\n",
      "episode: 419, score: 0, global_step_num: 129556, avg loss: 0.0018662710350022857, step: 323, replay memory length: 129556\n",
      "episode: 420, score: 0, global_step_num: 129879, avg loss: 0.001905420627445996, step: 323, replay memory length: 129879\n",
      "episode: 421, score: 0, global_step_num: 130202, avg loss: 0.0016417616758026665, step: 323, replay memory length: 130202\n",
      "episode: 422, score: 0, global_step_num: 130525, avg loss: 0.0015337805774772177, step: 323, replay memory length: 130525\n",
      "episode: 423, score: 0, global_step_num: 130848, avg loss: 0.0011731490372238074, step: 323, replay memory length: 130848\n",
      "episode: 424, score: 0, global_step_num: 131171, avg loss: 0.001717784434596427, step: 323, replay memory length: 131171\n",
      "episode: 425, score: 0, global_step_num: 131494, avg loss: 0.001935351089524929, step: 323, replay memory length: 131494\n",
      "episode: 426, score: 0, global_step_num: 131817, avg loss: 0.0015336235105720734, step: 323, replay memory length: 131817\n",
      "episode: 427, score: 0, global_step_num: 132140, avg loss: 0.0019798452343843353, step: 323, replay memory length: 132140\n",
      "episode: 428, score: 0, global_step_num: 132463, avg loss: 0.001879743848330578, step: 323, replay memory length: 132463\n",
      "episode: 429, score: 1.0, global_step_num: 132756, avg loss: 0.0016925862313028647, step: 293, replay memory length: 132756\n",
      "episode: 430, score: 0, global_step_num: 133079, avg loss: 0.0013555417441357377, step: 323, replay memory length: 133079\n",
      "episode: 431, score: 0, global_step_num: 133402, avg loss: 0.0016932268605278323, step: 323, replay memory length: 133402\n",
      "episode: 432, score: 0, global_step_num: 133725, avg loss: 0.001454627634398333, step: 323, replay memory length: 133725\n",
      "episode: 433, score: 0, global_step_num: 134048, avg loss: 0.001535867724064124, step: 323, replay memory length: 134048\n",
      "episode: 434, score: 0, global_step_num: 134371, avg loss: 0.0021336260014134106, step: 323, replay memory length: 134371\n",
      "episode: 435, score: 0, global_step_num: 134694, avg loss: 0.001741798086130148, step: 323, replay memory length: 134694\n",
      "episode: 436, score: 0, global_step_num: 135017, avg loss: 0.0016727161837226379, step: 323, replay memory length: 135017\n",
      "episode: 437, score: 0, global_step_num: 135340, avg loss: 0.0020203834941549693, step: 323, replay memory length: 135340\n",
      "episode: 438, score: 1.0, global_step_num: 135576, avg loss: 0.0015362537859014622, step: 236, replay memory length: 135576\n",
      "episode: 439, score: 0, global_step_num: 135899, avg loss: 0.0011031822447000333, step: 323, replay memory length: 135899\n",
      "episode: 440, score: 0, global_step_num: 136222, avg loss: 0.0019145377450358611, step: 323, replay memory length: 136222\n",
      "episode: 441, score: 0, global_step_num: 136545, avg loss: 0.0019242332435439689, step: 323, replay memory length: 136545\n",
      "episode: 442, score: 0, global_step_num: 136868, avg loss: 0.0016060337811723002, step: 323, replay memory length: 136868\n",
      "episode: 443, score: 1.0, global_step_num: 137028, avg loss: 0.0019969503327274653, step: 160, replay memory length: 137028\n",
      "episode: 444, score: 0, global_step_num: 137351, avg loss: 0.0015707606710779196, step: 323, replay memory length: 137351\n",
      "episode: 445, score: 0, global_step_num: 137674, avg loss: 0.0011803417683462973, step: 323, replay memory length: 137674\n",
      "episode: 446, score: 0, global_step_num: 137997, avg loss: 0.0016058086282548412, step: 323, replay memory length: 137997\n",
      "episode: 447, score: 0, global_step_num: 138320, avg loss: 0.0017831366447820921, step: 323, replay memory length: 138320\n",
      "episode: 448, score: 0, global_step_num: 138643, avg loss: 0.0018298066986735591, step: 323, replay memory length: 138643\n",
      "episode: 449, score: 0, global_step_num: 138966, avg loss: 0.0015802799744248403, step: 323, replay memory length: 138966\n",
      "episode: 450, score: 1.0, global_step_num: 139236, avg loss: 0.0020019013663133793, step: 270, replay memory length: 139236\n",
      "episode: 451, score: 0, global_step_num: 139559, avg loss: 0.0012728083890576184, step: 323, replay memory length: 139559\n",
      "episode: 452, score: 0, global_step_num: 139882, avg loss: 0.0018226859699179644, step: 323, replay memory length: 139882\n",
      "episode: 453, score: 0, global_step_num: 140205, avg loss: 0.0016402450823355507, step: 323, replay memory length: 140205\n",
      "episode: 454, score: 0, global_step_num: 140528, avg loss: 0.001380796947483793, step: 323, replay memory length: 140528\n",
      "episode: 455, score: 0, global_step_num: 140851, avg loss: 0.0013020922726844856, step: 323, replay memory length: 140851\n",
      "episode: 456, score: 0, global_step_num: 141174, avg loss: 0.0014713613824596202, step: 323, replay memory length: 141174\n",
      "episode: 457, score: 0, global_step_num: 141497, avg loss: 0.0014268526920261065, step: 323, replay memory length: 141497\n",
      "episode: 458, score: 1.0, global_step_num: 141595, avg loss: 0.002130506315459533, step: 98, replay memory length: 141595\n",
      "episode: 459, score: 0, global_step_num: 141918, avg loss: 0.0015089366149365472, step: 323, replay memory length: 141918\n",
      "episode: 460, score: 1.0, global_step_num: 142204, avg loss: 0.001982847601892092, step: 286, replay memory length: 142204\n",
      "episode: 461, score: 0, global_step_num: 142527, avg loss: 0.0021043784929680094, step: 323, replay memory length: 142527\n",
      "episode: 462, score: 0, global_step_num: 142850, avg loss: 0.0015419431463095335, step: 323, replay memory length: 142850\n",
      "episode: 463, score: 0, global_step_num: 143173, avg loss: 0.0016132459027753316, step: 323, replay memory length: 143173\n",
      "episode: 464, score: 0, global_step_num: 143496, avg loss: 0.0013688921549188707, step: 323, replay memory length: 143496\n",
      "episode: 465, score: 0, global_step_num: 143819, avg loss: 0.0018329180248422775, step: 323, replay memory length: 143819\n",
      "episode: 466, score: 0, global_step_num: 144142, avg loss: 0.001549802853107687, step: 323, replay memory length: 144142\n",
      "episode: 467, score: 0, global_step_num: 144465, avg loss: 0.001961665178178488, step: 323, replay memory length: 144465\n",
      "episode: 468, score: 0, global_step_num: 144788, avg loss: 0.0015762433465308008, step: 323, replay memory length: 144788\n",
      "episode: 469, score: 0, global_step_num: 145111, avg loss: 0.0014114316678872007, step: 323, replay memory length: 145111\n",
      "episode: 470, score: 0, global_step_num: 145434, avg loss: 0.001535295636370536, step: 323, replay memory length: 145434\n",
      "episode: 471, score: 0, global_step_num: 145757, avg loss: 0.001704297570560513, step: 323, replay memory length: 145757\n",
      "episode: 472, score: 1.0, global_step_num: 145966, avg loss: 0.0014361882707703989, step: 209, replay memory length: 145966\n",
      "episode: 473, score: 0, global_step_num: 146289, avg loss: 0.002035066540622278, step: 323, replay memory length: 146289\n",
      "episode: 474, score: 1.0, global_step_num: 146427, avg loss: 0.0015032879589760842, step: 138, replay memory length: 146427\n",
      "episode: 475, score: 0, global_step_num: 146750, avg loss: 0.0016379478726885957, step: 323, replay memory length: 146750\n",
      "episode: 476, score: 0, global_step_num: 147073, avg loss: 0.0018403263291520066, step: 323, replay memory length: 147073\n",
      "episode: 477, score: 0, global_step_num: 147396, avg loss: 0.0018148987188458805, step: 323, replay memory length: 147396\n",
      "episode: 478, score: 1.0, global_step_num: 147673, avg loss: 0.0012904981178724726, step: 277, replay memory length: 147673\n",
      "episode: 479, score: 1.0, global_step_num: 147976, avg loss: 0.002065741628441306, step: 303, replay memory length: 147976\n",
      "episode: 480, score: 0, global_step_num: 148299, avg loss: 0.0014859125193970471, step: 323, replay memory length: 148299\n",
      "episode: 481, score: 0, global_step_num: 148622, avg loss: 0.001862117959875263, step: 323, replay memory length: 148622\n",
      "episode: 482, score: 0, global_step_num: 148945, avg loss: 0.0014895037269435241, step: 323, replay memory length: 148945\n",
      "episode: 483, score: 0, global_step_num: 149268, avg loss: 0.001346606832813779, step: 323, replay memory length: 149268\n",
      "episode: 484, score: 0, global_step_num: 149591, avg loss: 0.0016136860640922673, step: 323, replay memory length: 149591\n",
      "episode: 485, score: 0, global_step_num: 149914, avg loss: 0.0023555267146973613, step: 323, replay memory length: 149914\n",
      "episode: 486, score: 0, global_step_num: 150237, avg loss: 0.0017458052573351287, step: 323, replay memory length: 150237\n",
      "episode: 487, score: 0, global_step_num: 150560, avg loss: 0.0016331562846183376, step: 323, replay memory length: 150560\n",
      "episode: 488, score: 1.0, global_step_num: 150691, avg loss: 0.0011848370302492421, step: 131, replay memory length: 150691\n",
      "episode: 489, score: 0, global_step_num: 151014, avg loss: 0.0021403848936122124, step: 323, replay memory length: 151014\n",
      "episode: 490, score: 0, global_step_num: 151337, avg loss: 0.00186639043406931, step: 323, replay memory length: 151337\n",
      "episode: 491, score: 0, global_step_num: 151660, avg loss: 0.0017600603347181342, step: 323, replay memory length: 151660\n",
      "episode: 492, score: 0, global_step_num: 151983, avg loss: 0.001837733666822937, step: 323, replay memory length: 151983\n",
      "episode: 493, score: 0, global_step_num: 152306, avg loss: 0.0014388332168548269, step: 323, replay memory length: 152306\n",
      "episode: 494, score: 0, global_step_num: 152629, avg loss: 0.0010915096929151355, step: 323, replay memory length: 152629\n",
      "episode: 495, score: 0, global_step_num: 152952, avg loss: 0.0017700737410706764, step: 323, replay memory length: 152952\n",
      "episode: 496, score: 0, global_step_num: 153275, avg loss: 0.0020013234546356158, step: 323, replay memory length: 153275\n",
      "episode: 497, score: 0, global_step_num: 153598, avg loss: 0.0014725439793857095, step: 323, replay memory length: 153598\n",
      "episode: 498, score: 0, global_step_num: 153921, avg loss: 0.001794605265687679, step: 323, replay memory length: 153921\n",
      "episode: 499, score: 0, global_step_num: 154244, avg loss: 0.0013043165844783147, step: 323, replay memory length: 154244\n",
      "episode: 500, score: 0, global_step_num: 154567, avg loss: 0.0019106956698453567, step: 323, replay memory length: 154567\n",
      "episode: 501, score: 0, global_step_num: 154890, avg loss: 0.002091863411119068, step: 323, replay memory length: 154890\n",
      "episode: 502, score: 0, global_step_num: 155213, avg loss: 0.0020735490145574204, step: 323, replay memory length: 155213\n",
      "episode: 503, score: 0, global_step_num: 155536, avg loss: 0.0019678335523226464, step: 323, replay memory length: 155536\n",
      "episode: 504, score: 0, global_step_num: 155859, avg loss: 0.0013899515583028741, step: 323, replay memory length: 155859\n",
      "episode: 505, score: 0, global_step_num: 156182, avg loss: 0.0021538609763909326, step: 323, replay memory length: 156182\n",
      "episode: 506, score: 0, global_step_num: 156505, avg loss: 0.0017511980875260576, step: 323, replay memory length: 156505\n",
      "episode: 507, score: 0, global_step_num: 156828, avg loss: 0.0018728896230491875, step: 323, replay memory length: 156828\n",
      "episode: 508, score: 0, global_step_num: 157151, avg loss: 0.0015742104619126882, step: 323, replay memory length: 157151\n",
      "episode: 509, score: 0, global_step_num: 157474, avg loss: 0.0012226051607195521, step: 323, replay memory length: 157474\n",
      "episode: 510, score: 0, global_step_num: 157797, avg loss: 0.001610837827878297, step: 323, replay memory length: 157797\n",
      "episode: 511, score: 0, global_step_num: 158120, avg loss: 0.0014078443603863463, step: 323, replay memory length: 158120\n",
      "episode: 512, score: 0, global_step_num: 158443, avg loss: 0.0017171895215311232, step: 323, replay memory length: 158443\n",
      "episode: 513, score: 0, global_step_num: 158766, avg loss: 0.0018715523892554558, step: 323, replay memory length: 158766\n",
      "episode: 514, score: 0, global_step_num: 159089, avg loss: 0.0014477138395116473, step: 323, replay memory length: 159089\n",
      "episode: 515, score: 0, global_step_num: 159412, avg loss: 0.0018670266161437553, step: 323, replay memory length: 159412\n",
      "episode: 516, score: 0, global_step_num: 159735, avg loss: 0.0013207784494689992, step: 323, replay memory length: 159735\n",
      "episode: 517, score: 0, global_step_num: 160058, avg loss: 0.0018551930143526402, step: 323, replay memory length: 160058\n",
      "episode: 518, score: 0, global_step_num: 160381, avg loss: 0.001200672129317599, step: 323, replay memory length: 160381\n",
      "episode: 519, score: 0, global_step_num: 160704, avg loss: 0.0018727420006580248, step: 323, replay memory length: 160704\n",
      "episode: 520, score: 0, global_step_num: 161027, avg loss: 0.0018677460506910323, step: 323, replay memory length: 161027\n",
      "episode: 521, score: 0, global_step_num: 161350, avg loss: 0.0015976907486273215, step: 323, replay memory length: 161350\n",
      "episode: 522, score: 0, global_step_num: 161673, avg loss: 0.0013440445841029834, step: 323, replay memory length: 161673\n",
      "episode: 523, score: 0, global_step_num: 161996, avg loss: 0.0013239976305617024, step: 323, replay memory length: 161996\n",
      "episode: 524, score: 0, global_step_num: 162319, avg loss: 0.001904534478130094, step: 323, replay memory length: 162319\n",
      "episode: 525, score: 0, global_step_num: 162642, avg loss: 0.0018508865921538034, step: 323, replay memory length: 162642\n",
      "episode: 526, score: 0, global_step_num: 162965, avg loss: 0.0016030992736050843, step: 323, replay memory length: 162965\n",
      "episode: 527, score: 0, global_step_num: 163288, avg loss: 0.0013606394059728695, step: 323, replay memory length: 163288\n",
      "episode: 528, score: 0, global_step_num: 163611, avg loss: 0.0019510605796611501, step: 323, replay memory length: 163611\n",
      "episode: 529, score: 0, global_step_num: 163934, avg loss: 0.001476804761940892, step: 323, replay memory length: 163934\n",
      "episode: 530, score: 0, global_step_num: 164257, avg loss: 0.001680915488650949, step: 323, replay memory length: 164257\n",
      "episode: 531, score: 0, global_step_num: 164580, avg loss: 0.0020136358706856266, step: 323, replay memory length: 164580\n",
      "episode: 532, score: 0, global_step_num: 164903, avg loss: 0.0015008839259857882, step: 323, replay memory length: 164903\n",
      "episode: 533, score: 0, global_step_num: 165226, avg loss: 0.0015183047868280364, step: 323, replay memory length: 165226\n",
      "episode: 534, score: 0, global_step_num: 165549, avg loss: 0.0019722769243752662, step: 323, replay memory length: 165549\n",
      "episode: 535, score: 0, global_step_num: 165872, avg loss: 0.001473228548490199, step: 323, replay memory length: 165872\n",
      "episode: 536, score: 0, global_step_num: 166195, avg loss: 0.0019754185155485713, step: 323, replay memory length: 166195\n",
      "episode: 537, score: 0, global_step_num: 166518, avg loss: 0.0016059763883679557, step: 323, replay memory length: 166518\n",
      "episode: 538, score: 0, global_step_num: 166841, avg loss: 0.001469771698548948, step: 323, replay memory length: 166841\n",
      "episode: 539, score: 0, global_step_num: 167164, avg loss: 0.002058031787991333, step: 323, replay memory length: 167164\n",
      "episode: 540, score: 0, global_step_num: 167487, avg loss: 0.0012180331052949675, step: 323, replay memory length: 167487\n",
      "episode: 541, score: 0, global_step_num: 167810, avg loss: 0.002358221290815657, step: 323, replay memory length: 167810\n",
      "episode: 542, score: 0, global_step_num: 168133, avg loss: 0.002069125582818534, step: 323, replay memory length: 168133\n",
      "episode: 543, score: 1.0, global_step_num: 168378, avg loss: 0.0018178478192938349, step: 245, replay memory length: 168378\n",
      "episode: 544, score: 0, global_step_num: 168701, avg loss: 0.0015134496766039558, step: 323, replay memory length: 168701\n",
      "episode: 545, score: 0, global_step_num: 169024, avg loss: 0.0012128130131829435, step: 323, replay memory length: 169024\n",
      "episode: 546, score: 0, global_step_num: 169347, avg loss: 0.0014985703171018926, step: 323, replay memory length: 169347\n",
      "episode: 547, score: 0, global_step_num: 169670, avg loss: 0.0017831261442405784, step: 323, replay memory length: 169670\n",
      "episode: 548, score: 0, global_step_num: 169993, avg loss: 0.0017569793125411968, step: 323, replay memory length: 169993\n",
      "episode: 549, score: 0, global_step_num: 170316, avg loss: 0.0015102615977240152, step: 323, replay memory length: 170316\n",
      "episode: 550, score: 1.0, global_step_num: 170591, avg loss: 0.00134891593605227, step: 275, replay memory length: 170591\n",
      "episode: 551, score: 0, global_step_num: 170914, avg loss: 0.0018712340437497814, step: 323, replay memory length: 170914\n",
      "episode: 552, score: 0, global_step_num: 171237, avg loss: 0.0016770784150702816, step: 323, replay memory length: 171237\n",
      "episode: 553, score: 0, global_step_num: 171560, avg loss: 0.002102567298767527, step: 323, replay memory length: 171560\n",
      "episode: 554, score: 0, global_step_num: 171883, avg loss: 0.0013548499629578933, step: 323, replay memory length: 171883\n",
      "episode: 555, score: 0, global_step_num: 172206, avg loss: 0.0019145129102017724, step: 323, replay memory length: 172206\n",
      "episode: 556, score: 0, global_step_num: 172529, avg loss: 0.0016151114202608825, step: 323, replay memory length: 172529\n",
      "episode: 557, score: 0, global_step_num: 172852, avg loss: 0.0016870538705600893, step: 323, replay memory length: 172852\n",
      "episode: 558, score: 1.0, global_step_num: 172955, avg loss: 0.0009720403280597857, step: 103, replay memory length: 172955\n",
      "episode: 559, score: 0, global_step_num: 173278, avg loss: 0.001451804046873325, step: 323, replay memory length: 173278\n",
      "episode: 560, score: 0, global_step_num: 173601, avg loss: 0.0015488014048479545, step: 323, replay memory length: 173601\n",
      "episode: 561, score: 1.0, global_step_num: 173817, avg loss: 0.0017086779132021682, step: 216, replay memory length: 173817\n",
      "episode: 562, score: 0, global_step_num: 174140, avg loss: 0.0014915874692438937, step: 323, replay memory length: 174140\n",
      "episode: 563, score: 0, global_step_num: 174463, avg loss: 0.0017850663498928257, step: 323, replay memory length: 174463\n",
      "episode: 564, score: 1.0, global_step_num: 174626, avg loss: 0.0016223928861594451, step: 163, replay memory length: 174626\n",
      "episode: 565, score: 0, global_step_num: 174949, avg loss: 0.0017094302047215462, step: 323, replay memory length: 174949\n",
      "episode: 566, score: 0, global_step_num: 175272, avg loss: 0.0017699845490821557, step: 323, replay memory length: 175272\n",
      "episode: 567, score: 0, global_step_num: 175595, avg loss: 0.0014306603594918148, step: 323, replay memory length: 175595\n",
      "episode: 568, score: 0, global_step_num: 175918, avg loss: 0.0014008917762292315, step: 323, replay memory length: 175918\n",
      "episode: 569, score: 0, global_step_num: 176241, avg loss: 0.0018665093831701659, step: 323, replay memory length: 176241\n",
      "episode: 570, score: 0, global_step_num: 176564, avg loss: 0.0011798902139694418, step: 323, replay memory length: 176564\n",
      "episode: 571, score: 0, global_step_num: 176887, avg loss: 0.0019421044233820586, step: 323, replay memory length: 176887\n",
      "episode: 572, score: 0, global_step_num: 177210, avg loss: 0.0017925036743735778, step: 323, replay memory length: 177210\n",
      "episode: 573, score: 0, global_step_num: 177533, avg loss: 0.00150803703915865, step: 323, replay memory length: 177533\n",
      "episode: 574, score: 0, global_step_num: 177856, avg loss: 0.0017812141606988717, step: 323, replay memory length: 177856\n",
      "episode: 575, score: 0, global_step_num: 178179, avg loss: 0.0017284990015513845, step: 323, replay memory length: 178179\n",
      "episode: 576, score: 0, global_step_num: 178502, avg loss: 0.0016273024096957862, step: 323, replay memory length: 178502\n",
      "episode: 577, score: 0, global_step_num: 178825, avg loss: 0.0015496898476898642, step: 323, replay memory length: 178825\n",
      "episode: 578, score: 1.0, global_step_num: 179027, avg loss: 0.0017497220104733871, step: 202, replay memory length: 179027\n",
      "episode: 579, score: 0, global_step_num: 179350, avg loss: 0.0019187821207205422, step: 323, replay memory length: 179350\n",
      "episode: 580, score: 0, global_step_num: 179673, avg loss: 0.0019990946469419773, step: 323, replay memory length: 179673\n",
      "episode: 581, score: 0, global_step_num: 179996, avg loss: 0.0014894004218526662, step: 323, replay memory length: 179996\n",
      "episode: 582, score: 0, global_step_num: 180319, avg loss: 0.0019581405437942177, step: 323, replay memory length: 180319\n",
      "episode: 583, score: 0, global_step_num: 180642, avg loss: 0.0013830345217799673, step: 323, replay memory length: 180642\n",
      "episode: 584, score: 1.0, global_step_num: 180831, avg loss: 0.002479551294224317, step: 189, replay memory length: 180831\n",
      "episode: 585, score: 0, global_step_num: 181154, avg loss: 0.0011716418501591845, step: 323, replay memory length: 181154\n",
      "episode: 586, score: 0, global_step_num: 181477, avg loss: 0.0021013796328050983, step: 323, replay memory length: 181477\n",
      "episode: 587, score: 1.0, global_step_num: 181539, avg loss: 0.0014866543729259584, step: 62, replay memory length: 181539\n",
      "episode: 588, score: 0, global_step_num: 181862, avg loss: 0.0018387337650771654, step: 323, replay memory length: 181862\n",
      "episode: 589, score: 0, global_step_num: 182185, avg loss: 0.001491325696510604, step: 323, replay memory length: 182185\n",
      "episode: 590, score: 0, global_step_num: 182508, avg loss: 0.0018717439209329583, step: 323, replay memory length: 182508\n",
      "episode: 591, score: 0, global_step_num: 182831, avg loss: 0.0015007305177497515, step: 323, replay memory length: 182831\n",
      "episode: 592, score: 0, global_step_num: 183154, avg loss: 0.0016471336248512379, step: 323, replay memory length: 183154\n",
      "episode: 593, score: 0, global_step_num: 183477, avg loss: 0.001684868534164921, step: 323, replay memory length: 183477\n",
      "episode: 594, score: 1.0, global_step_num: 183656, avg loss: 0.0015688792822676693, step: 179, replay memory length: 183656\n",
      "episode: 595, score: 0, global_step_num: 183979, avg loss: 0.0022973554450377927, step: 323, replay memory length: 183979\n",
      "episode: 596, score: 0, global_step_num: 184302, avg loss: 0.001381364460816055, step: 323, replay memory length: 184302\n",
      "episode: 597, score: 0, global_step_num: 184625, avg loss: 0.0020047154388656606, step: 323, replay memory length: 184625\n",
      "episode: 598, score: 0, global_step_num: 184948, avg loss: 0.0019595482149340933, step: 323, replay memory length: 184948\n",
      "episode: 599, score: 0, global_step_num: 185271, avg loss: 0.0010623741413654682, step: 323, replay memory length: 185271\n",
      "episode: 600, score: 0, global_step_num: 185594, avg loss: 0.0014765179004330193, step: 323, replay memory length: 185594\n",
      "episode: 601, score: 0, global_step_num: 185917, avg loss: 0.0016255212135885375, step: 323, replay memory length: 185917\n",
      "episode: 602, score: 0, global_step_num: 186240, avg loss: 0.0014570309198624787, step: 323, replay memory length: 186240\n",
      "episode: 603, score: 0, global_step_num: 186563, avg loss: 0.0017163038663721318, step: 323, replay memory length: 186563\n",
      "episode: 604, score: 0, global_step_num: 186886, avg loss: 0.0010720157692240288, step: 323, replay memory length: 186886\n",
      "episode: 605, score: 0, global_step_num: 187209, avg loss: 0.001627275205991234, step: 323, replay memory length: 187209\n",
      "episode: 606, score: 0, global_step_num: 187532, avg loss: 0.0009925120590455509, step: 323, replay memory length: 187532\n",
      "episode: 607, score: 0, global_step_num: 187855, avg loss: 0.0018390272290153655, step: 323, replay memory length: 187855\n",
      "episode: 608, score: 0, global_step_num: 188178, avg loss: 0.0017243399561407203, step: 323, replay memory length: 188178\n",
      "episode: 609, score: 0, global_step_num: 188501, avg loss: 0.001287828505890547, step: 323, replay memory length: 188501\n",
      "episode: 610, score: 0, global_step_num: 188824, avg loss: 0.001537742048933052, step: 323, replay memory length: 188824\n",
      "episode: 611, score: 0, global_step_num: 189147, avg loss: 0.0015494286695155058, step: 323, replay memory length: 189147\n",
      "episode: 612, score: 0, global_step_num: 189470, avg loss: 0.001860418626289377, step: 323, replay memory length: 189470\n",
      "episode: 613, score: 0, global_step_num: 189793, avg loss: 0.0013960260643323314, step: 323, replay memory length: 189793\n",
      "episode: 614, score: 1.0, global_step_num: 189890, avg loss: 0.0016668246472204139, step: 97, replay memory length: 189890\n",
      "episode: 615, score: 0, global_step_num: 190213, avg loss: 0.0013240973902085035, step: 323, replay memory length: 190213\n",
      "episode: 616, score: 1.0, global_step_num: 190293, avg loss: 0.0019267725648774102, step: 80, replay memory length: 190293\n",
      "episode: 617, score: 0, global_step_num: 190616, avg loss: 0.001901289904038238, step: 323, replay memory length: 190616\n",
      "episode: 618, score: 0, global_step_num: 190939, avg loss: 0.002053140459038585, step: 323, replay memory length: 190939\n",
      "episode: 619, score: 0, global_step_num: 191262, avg loss: 0.0015152522247479636, step: 323, replay memory length: 191262\n",
      "episode: 620, score: 0, global_step_num: 191585, avg loss: 0.002166728049753045, step: 323, replay memory length: 191585\n",
      "episode: 621, score: 0, global_step_num: 191908, avg loss: 0.001357470171200864, step: 323, replay memory length: 191908\n",
      "episode: 622, score: 0, global_step_num: 192231, avg loss: 0.0017661939902789657, step: 323, replay memory length: 192231\n",
      "episode: 623, score: 0, global_step_num: 192554, avg loss: 0.001716816822149822, step: 323, replay memory length: 192554\n",
      "episode: 624, score: 0, global_step_num: 192877, avg loss: 0.0015461142003362683, step: 323, replay memory length: 192877\n",
      "episode: 625, score: 0, global_step_num: 193200, avg loss: 0.0013322004298306047, step: 323, replay memory length: 193200\n",
      "episode: 626, score: 0, global_step_num: 193523, avg loss: 0.001958689359038905, step: 323, replay memory length: 193523\n",
      "episode: 627, score: 0, global_step_num: 193846, avg loss: 0.0015534329172131223, step: 323, replay memory length: 193846\n",
      "episode: 628, score: 0, global_step_num: 194169, avg loss: 0.0015599108176279895, step: 323, replay memory length: 194169\n",
      "episode: 629, score: 0, global_step_num: 194492, avg loss: 0.0019261743831656174, step: 323, replay memory length: 194492\n",
      "episode: 630, score: 0, global_step_num: 194815, avg loss: 0.0015252812761973923, step: 323, replay memory length: 194815\n",
      "episode: 631, score: 0, global_step_num: 195138, avg loss: 0.001959602036834161, step: 323, replay memory length: 195138\n",
      "episode: 632, score: 1.0, global_step_num: 195256, avg loss: 0.0021266676571786327, step: 118, replay memory length: 195256\n",
      "episode: 633, score: 0, global_step_num: 195579, avg loss: 0.0016745767018509702, step: 323, replay memory length: 195579\n",
      "episode: 634, score: 0, global_step_num: 195902, avg loss: 0.001640478857631649, step: 323, replay memory length: 195902\n",
      "episode: 635, score: 0, global_step_num: 196225, avg loss: 0.0016532764791822717, step: 323, replay memory length: 196225\n",
      "episode: 636, score: 0, global_step_num: 196548, avg loss: 0.0018488352672462194, step: 323, replay memory length: 196548\n",
      "episode: 637, score: 0, global_step_num: 196871, avg loss: 0.0021469713435037286, step: 323, replay memory length: 196871\n",
      "episode: 638, score: 0, global_step_num: 197194, avg loss: 0.0016671513702151437, step: 323, replay memory length: 197194\n",
      "episode: 639, score: 0, global_step_num: 197517, avg loss: 0.001804185316382034, step: 323, replay memory length: 197517\n",
      "episode: 640, score: 0, global_step_num: 197840, avg loss: 0.0014708624751481963, step: 323, replay memory length: 197840\n",
      "episode: 641, score: 0, global_step_num: 198163, avg loss: 0.0014459122881597536, step: 323, replay memory length: 198163\n",
      "episode: 642, score: 0, global_step_num: 198486, avg loss: 0.0014797525478857814, step: 323, replay memory length: 198486\n",
      "episode: 643, score: 0, global_step_num: 198809, avg loss: 0.0009164218780467136, step: 323, replay memory length: 198809\n",
      "episode: 644, score: 0, global_step_num: 199132, avg loss: 0.0014773216605850738, step: 323, replay memory length: 199132\n",
      "episode: 645, score: 0, global_step_num: 199455, avg loss: 0.002092616244640438, step: 323, replay memory length: 199455\n",
      "episode: 646, score: 0, global_step_num: 199778, avg loss: 0.002172189246356603, step: 323, replay memory length: 199778\n",
      "episode: 647, score: 0, global_step_num: 200101, avg loss: 0.0012802300704998144, step: 323, replay memory length: 200101\n",
      "episode: 648, score: 0, global_step_num: 200424, avg loss: 0.0016058526471789368, step: 323, replay memory length: 200424\n",
      "episode: 649, score: 0, global_step_num: 200747, avg loss: 0.0015300831044430757, step: 323, replay memory length: 200747\n",
      "episode: 650, score: 0, global_step_num: 201070, avg loss: 0.001707594735775212, step: 323, replay memory length: 201070\n",
      "episode: 651, score: 0, global_step_num: 201393, avg loss: 0.002440904843383057, step: 323, replay memory length: 201393\n",
      "episode: 652, score: 0, global_step_num: 201716, avg loss: 0.0013687829185019997, step: 323, replay memory length: 201716\n",
      "episode: 653, score: 0, global_step_num: 202039, avg loss: 0.0013894745222975925, step: 323, replay memory length: 202039\n",
      "episode: 654, score: 0, global_step_num: 202362, avg loss: 0.001284068303232887, step: 323, replay memory length: 202362\n",
      "episode: 655, score: 1.0, global_step_num: 202585, avg loss: 0.0014526092690840362, step: 223, replay memory length: 202585\n",
      "episode: 656, score: 0, global_step_num: 202908, avg loss: 0.0013048715702052927, step: 323, replay memory length: 202908\n",
      "episode: 657, score: 0, global_step_num: 203231, avg loss: 0.001432679076054963, step: 323, replay memory length: 203231\n",
      "episode: 658, score: 1.0, global_step_num: 203534, avg loss: 0.0013317252478613252, step: 303, replay memory length: 203534\n",
      "episode: 659, score: 0, global_step_num: 203857, avg loss: 0.0020388582549764997, step: 323, replay memory length: 203857\n",
      "episode: 660, score: 0, global_step_num: 204180, avg loss: 0.0020658968890898514, step: 323, replay memory length: 204180\n",
      "episode: 661, score: 0, global_step_num: 204503, avg loss: 0.0017397982557820053, step: 323, replay memory length: 204503\n",
      "episode: 662, score: 0, global_step_num: 204826, avg loss: 0.0018959715071245953, step: 323, replay memory length: 204826\n",
      "episode: 663, score: 0, global_step_num: 205149, avg loss: 0.0019428735830316374, step: 323, replay memory length: 205149\n",
      "episode: 664, score: 0, global_step_num: 205472, avg loss: 0.0013475967752756698, step: 323, replay memory length: 205472\n",
      "episode: 665, score: 0, global_step_num: 205795, avg loss: 0.001784853149222476, step: 323, replay memory length: 205795\n",
      "episode: 666, score: 0, global_step_num: 206118, avg loss: 0.001799636573500143, step: 323, replay memory length: 206118\n",
      "episode: 667, score: 0, global_step_num: 206441, avg loss: 0.00176123719158382, step: 323, replay memory length: 206441\n",
      "episode: 668, score: 0, global_step_num: 206764, avg loss: 0.0016533603330394684, step: 323, replay memory length: 206764\n",
      "episode: 669, score: 0, global_step_num: 207087, avg loss: 0.0013727194989504804, step: 323, replay memory length: 207087\n",
      "episode: 670, score: 0, global_step_num: 207410, avg loss: 0.0011141363816769112, step: 323, replay memory length: 207410\n",
      "episode: 671, score: 0, global_step_num: 207733, avg loss: 0.0013867048868345783, step: 323, replay memory length: 207733\n",
      "episode: 672, score: 0, global_step_num: 208056, avg loss: 0.0022644575270060045, step: 323, replay memory length: 208056\n",
      "episode: 673, score: 1.0, global_step_num: 208170, avg loss: 0.0021589430109583063, step: 114, replay memory length: 208170\n",
      "episode: 674, score: 1.0, global_step_num: 208437, avg loss: 0.001838636672225258, step: 267, replay memory length: 208437\n",
      "episode: 675, score: 0, global_step_num: 208760, avg loss: 0.0017259195432692109, step: 323, replay memory length: 208760\n",
      "episode: 676, score: 0, global_step_num: 209083, avg loss: 0.0017773690478664578, step: 323, replay memory length: 209083\n",
      "episode: 677, score: 0, global_step_num: 209406, avg loss: 0.0014851190695542855, step: 323, replay memory length: 209406\n",
      "episode: 678, score: 0, global_step_num: 209729, avg loss: 0.0018214081327594038, step: 323, replay memory length: 209729\n",
      "episode: 679, score: 0, global_step_num: 210052, avg loss: 0.001643571960812551, step: 323, replay memory length: 210052\n",
      "episode: 680, score: 0, global_step_num: 210375, avg loss: 0.0014616867370966385, step: 323, replay memory length: 210375\n",
      "episode: 681, score: 0, global_step_num: 210698, avg loss: 0.001551921930595002, step: 323, replay memory length: 210698\n",
      "episode: 682, score: 0, global_step_num: 211021, avg loss: 0.0017767166103594184, step: 323, replay memory length: 211021\n",
      "episode: 683, score: 0, global_step_num: 211344, avg loss: 0.0017111360785007272, step: 323, replay memory length: 211344\n",
      "episode: 684, score: 0, global_step_num: 211667, avg loss: 0.0014176698583953573, step: 323, replay memory length: 211667\n",
      "episode: 685, score: 0, global_step_num: 211990, avg loss: 0.0014101448852752386, step: 323, replay memory length: 211990\n",
      "episode: 686, score: 1.0, global_step_num: 212282, avg loss: 0.001849392524229487, step: 292, replay memory length: 212282\n",
      "episode: 687, score: 0, global_step_num: 212605, avg loss: 0.0019645080761625825, step: 323, replay memory length: 212605\n",
      "episode: 688, score: 1.0, global_step_num: 212923, avg loss: 0.0019830539049536535, step: 318, replay memory length: 212923\n",
      "episode: 689, score: 0, global_step_num: 213246, avg loss: 0.0020528461265977077, step: 323, replay memory length: 213246\n",
      "episode: 690, score: 0, global_step_num: 213569, avg loss: 0.0017275212254705139, step: 323, replay memory length: 213569\n",
      "episode: 691, score: 0, global_step_num: 213892, avg loss: 0.002043816574591759, step: 323, replay memory length: 213892\n",
      "episode: 692, score: 0, global_step_num: 214215, avg loss: 0.0018564584995960775, step: 323, replay memory length: 214215\n",
      "episode: 693, score: 0, global_step_num: 214538, avg loss: 0.0015378699003229163, step: 323, replay memory length: 214538\n",
      "episode: 694, score: 0, global_step_num: 214861, avg loss: 0.0013850870063439802, step: 323, replay memory length: 214861\n",
      "episode: 695, score: 0, global_step_num: 215184, avg loss: 0.0014475617284825538, step: 323, replay memory length: 215184\n",
      "episode: 696, score: 0, global_step_num: 215507, avg loss: 0.0011404478133022378, step: 323, replay memory length: 215507\n",
      "episode: 697, score: 0, global_step_num: 215830, avg loss: 0.002089131965273818, step: 323, replay memory length: 215830\n",
      "episode: 698, score: 0, global_step_num: 216153, avg loss: 0.0014528987739824807, step: 323, replay memory length: 216153\n",
      "episode: 699, score: 0, global_step_num: 216476, avg loss: 0.0013754875719100442, step: 323, replay memory length: 216476\n",
      "episode: 700, score: 0, global_step_num: 216799, avg loss: 0.0014273620485841059, step: 323, replay memory length: 216799\n",
      "episode: 701, score: 0, global_step_num: 217122, avg loss: 0.0015012175722193025, step: 323, replay memory length: 217122\n",
      "episode: 702, score: 0, global_step_num: 217445, avg loss: 0.0017831518931872368, step: 323, replay memory length: 217445\n",
      "episode: 703, score: 0, global_step_num: 217768, avg loss: 0.001728900124430132, step: 323, replay memory length: 217768\n",
      "episode: 704, score: 0, global_step_num: 218091, avg loss: 0.001467037498449638, step: 323, replay memory length: 218091\n",
      "episode: 705, score: 0, global_step_num: 218414, avg loss: 0.0020499815628870627, step: 323, replay memory length: 218414\n",
      "episode: 706, score: 0, global_step_num: 218737, avg loss: 0.001496282856587697, step: 323, replay memory length: 218737\n",
      "episode: 707, score: 0, global_step_num: 219060, avg loss: 0.0013241097208814348, step: 323, replay memory length: 219060\n",
      "episode: 708, score: 0, global_step_num: 219383, avg loss: 0.0017141064981026073, step: 323, replay memory length: 219383\n",
      "episode: 709, score: 0, global_step_num: 219706, avg loss: 0.0015112001505956688, step: 323, replay memory length: 219706\n",
      "episode: 710, score: 0, global_step_num: 220029, avg loss: 0.0013304519038641557, step: 323, replay memory length: 220029\n",
      "episode: 711, score: 0, global_step_num: 220352, avg loss: 0.0015234525727315406, step: 323, replay memory length: 220352\n",
      "episode: 712, score: 0, global_step_num: 220675, avg loss: 0.0025261781592440464, step: 323, replay memory length: 220675\n",
      "episode: 713, score: 0, global_step_num: 220998, avg loss: 0.001178649564235879, step: 323, replay memory length: 220998\n",
      "episode: 714, score: 1.0, global_step_num: 221154, avg loss: 0.0021703745520741135, step: 156, replay memory length: 221154\n",
      "episode: 715, score: 0, global_step_num: 221477, avg loss: 0.001268175630403132, step: 323, replay memory length: 221477\n",
      "episode: 716, score: 0, global_step_num: 221800, avg loss: 0.0017879195806856478, step: 323, replay memory length: 221800\n",
      "episode: 717, score: 0, global_step_num: 222123, avg loss: 0.0014775394078067666, step: 323, replay memory length: 222123\n",
      "episode: 718, score: 0, global_step_num: 222446, avg loss: 0.001955180623047203, step: 323, replay memory length: 222446\n",
      "episode: 719, score: 0, global_step_num: 222769, avg loss: 0.001651262590408473, step: 323, replay memory length: 222769\n",
      "episode: 720, score: 0, global_step_num: 223092, avg loss: 0.0019504740229036408, step: 323, replay memory length: 223092\n",
      "episode: 721, score: 0, global_step_num: 223415, avg loss: 0.0015189256744172108, step: 323, replay memory length: 223415\n",
      "episode: 722, score: 1.0, global_step_num: 223635, avg loss: 0.0014363886590548316, step: 220, replay memory length: 223635\n",
      "episode: 723, score: 0, global_step_num: 223958, avg loss: 0.0021676850653333554, step: 323, replay memory length: 223958\n",
      "episode: 724, score: 0, global_step_num: 224281, avg loss: 0.0012788794778310884, step: 323, replay memory length: 224281\n",
      "episode: 725, score: 0, global_step_num: 224604, avg loss: 0.001669731169639488, step: 323, replay memory length: 224604\n",
      "episode: 726, score: 0, global_step_num: 224927, avg loss: 0.0016417278132706682, step: 323, replay memory length: 224927\n",
      "episode: 727, score: 0, global_step_num: 225250, avg loss: 0.0014877847149164323, step: 323, replay memory length: 225250\n",
      "episode: 728, score: 0, global_step_num: 225573, avg loss: 0.0022567637180348275, step: 323, replay memory length: 225573\n",
      "episode: 729, score: 1.0, global_step_num: 225792, avg loss: 0.00111068863410449, step: 219, replay memory length: 225792\n",
      "episode: 730, score: 0, global_step_num: 226115, avg loss: 0.0019332836048309306, step: 323, replay memory length: 226115\n",
      "episode: 731, score: 0, global_step_num: 226438, avg loss: 0.001438853179492009, step: 323, replay memory length: 226438\n",
      "episode: 732, score: 0, global_step_num: 226761, avg loss: 0.001268700056612554, step: 323, replay memory length: 226761\n",
      "episode: 733, score: 0, global_step_num: 227084, avg loss: 0.0018679886029122903, step: 323, replay memory length: 227084\n",
      "episode: 734, score: 1.0, global_step_num: 227198, avg loss: 0.001998039264387779, step: 114, replay memory length: 227198\n",
      "episode: 735, score: 0, global_step_num: 227521, avg loss: 0.0014089545268663765, step: 323, replay memory length: 227521\n",
      "episode: 736, score: 0, global_step_num: 227844, avg loss: 0.0016894519768545643, step: 323, replay memory length: 227844\n",
      "episode: 737, score: 0, global_step_num: 228167, avg loss: 0.0016023805790373387, step: 323, replay memory length: 228167\n",
      "episode: 738, score: 0, global_step_num: 228490, avg loss: 0.001966997037111708, step: 323, replay memory length: 228490\n",
      "episode: 739, score: 0, global_step_num: 228813, avg loss: 0.0015742427267665987, step: 323, replay memory length: 228813\n",
      "episode: 740, score: 0, global_step_num: 229136, avg loss: 0.0017330859697606742, step: 323, replay memory length: 229136\n",
      "episode: 741, score: 0, global_step_num: 229459, avg loss: 0.0012774554911841004, step: 323, replay memory length: 229459\n",
      "episode: 744, score: 0, global_step_num: 230420, avg loss: 0.0018029582503404189, step: 323, replay memory length: 230420\n",
      "episode: 745, score: 0, global_step_num: 230743, avg loss: 0.0017409915330282716, step: 323, replay memory length: 230743\n",
      "episode: 746, score: 0, global_step_num: 231066, avg loss: 0.001808405814167473, step: 323, replay memory length: 231066\n",
      "episode: 747, score: 0, global_step_num: 231389, avg loss: 0.001882822212167133, step: 323, replay memory length: 231389\n",
      "episode: 748, score: 0, global_step_num: 231712, avg loss: 0.0015274060526714293, step: 323, replay memory length: 231712\n",
      "episode: 749, score: 0, global_step_num: 232035, avg loss: 0.0014332296856482234, step: 323, replay memory length: 232035\n",
      "episode: 750, score: 0, global_step_num: 232358, avg loss: 0.0017708628580553369, step: 323, replay memory length: 232358\n",
      "episode: 751, score: 0, global_step_num: 232681, avg loss: 0.0017490679181567264, step: 323, replay memory length: 232681\n",
      "episode: 752, score: 0, global_step_num: 233004, avg loss: 0.0010380465158137645, step: 323, replay memory length: 233004\n",
      "episode: 753, score: 0, global_step_num: 233327, avg loss: 0.0012664801440333343, step: 323, replay memory length: 233327\n",
      "episode: 754, score: 1.0, global_step_num: 233591, avg loss: 0.0016140022109218742, step: 264, replay memory length: 233591\n",
      "episode: 755, score: 0, global_step_num: 233914, avg loss: 0.0014864919532708138, step: 323, replay memory length: 233914\n",
      "episode: 756, score: 0, global_step_num: 234237, avg loss: 0.0018618058368563921, step: 323, replay memory length: 234237\n",
      "episode: 757, score: 0, global_step_num: 234560, avg loss: 0.0013410695442398607, step: 323, replay memory length: 234560\n",
      "episode: 758, score: 0, global_step_num: 234883, avg loss: 0.0018895371938209447, step: 323, replay memory length: 234883\n",
      "episode: 759, score: 0, global_step_num: 235206, avg loss: 0.001407272172082371, step: 323, replay memory length: 235206\n",
      "episode: 760, score: 0, global_step_num: 235529, avg loss: 0.001641655427097009, step: 323, replay memory length: 235529\n",
      "episode: 761, score: 0, global_step_num: 235852, avg loss: 0.001725515074353824, step: 323, replay memory length: 235852\n",
      "episode: 762, score: 0, global_step_num: 236175, avg loss: 0.0017326042987507622, step: 323, replay memory length: 236175\n",
      "episode: 763, score: 0, global_step_num: 236498, avg loss: 0.001143080070759095, step: 323, replay memory length: 236498\n",
      "episode: 764, score: 0, global_step_num: 236821, avg loss: 0.0010835367421398252, step: 323, replay memory length: 236821\n",
      "episode: 765, score: 0, global_step_num: 237144, avg loss: 0.002126380176324507, step: 323, replay memory length: 237144\n",
      "episode: 766, score: 0, global_step_num: 237467, avg loss: 0.0018638826935469524, step: 323, replay memory length: 237467\n",
      "episode: 767, score: 0, global_step_num: 237790, avg loss: 0.0015994561291243219, step: 323, replay memory length: 237790\n",
      "episode: 768, score: 0, global_step_num: 238113, avg loss: 0.0017643945085906731, step: 323, replay memory length: 238113\n",
      "episode: 769, score: 0, global_step_num: 238436, avg loss: 0.0011885871684202407, step: 323, replay memory length: 238436\n",
      "episode: 770, score: 0, global_step_num: 238759, avg loss: 0.0016964691931714037, step: 323, replay memory length: 238759\n",
      "episode: 771, score: 0, global_step_num: 239082, avg loss: 0.0012304611399438152, step: 323, replay memory length: 239082\n",
      "episode: 772, score: 0, global_step_num: 239405, avg loss: 0.002034912269974081, step: 323, replay memory length: 239405\n",
      "episode: 773, score: 1.0, global_step_num: 239629, avg loss: 0.0015337950360593108, step: 224, replay memory length: 239629\n",
      "episode: 774, score: 0, global_step_num: 239952, avg loss: 0.0012120778790817288, step: 323, replay memory length: 239952\n",
      "episode: 775, score: 0, global_step_num: 240275, avg loss: 0.0014158764735625214, step: 323, replay memory length: 240275\n",
      "episode: 776, score: 0, global_step_num: 240598, avg loss: 0.0020300669383864303, step: 323, replay memory length: 240598\n",
      "episode: 777, score: 0, global_step_num: 240921, avg loss: 0.0013486352284532528, step: 323, replay memory length: 240921\n",
      "episode: 778, score: 0, global_step_num: 241244, avg loss: 0.0013810838325484232, step: 323, replay memory length: 241244\n",
      "episode: 779, score: 0, global_step_num: 241567, avg loss: 0.0018738896174746, step: 323, replay memory length: 241567\n",
      "episode: 780, score: 0, global_step_num: 241890, avg loss: 0.001645273831897102, step: 323, replay memory length: 241890\n",
      "episode: 781, score: 0, global_step_num: 242213, avg loss: 0.001546286324238751, step: 323, replay memory length: 242213\n",
      "episode: 782, score: 0, global_step_num: 242536, avg loss: 0.001507094826573237, step: 323, replay memory length: 242536\n",
      "episode: 783, score: 0, global_step_num: 242859, avg loss: 0.0019351343863876671, step: 323, replay memory length: 242859\n",
      "episode: 784, score: 0, global_step_num: 243182, avg loss: 0.0016343197116431005, step: 323, replay memory length: 243182\n",
      "episode: 785, score: 1.0, global_step_num: 243384, avg loss: 0.0015623191790053728, step: 202, replay memory length: 243384\n",
      "episode: 786, score: 0, global_step_num: 243707, avg loss: 0.0019508481817310979, step: 323, replay memory length: 243707\n",
      "episode: 787, score: 0, global_step_num: 244030, avg loss: 0.001589929530500768, step: 323, replay memory length: 244030\n",
      "episode: 788, score: 0, global_step_num: 244353, avg loss: 0.00159419732693971, step: 323, replay memory length: 244353\n",
      "episode: 789, score: 0, global_step_num: 244676, avg loss: 0.0012549113055433244, step: 323, replay memory length: 244676\n",
      "episode: 790, score: 0, global_step_num: 244999, avg loss: 0.0018483522052275157, step: 323, replay memory length: 244999\n",
      "episode: 791, score: 0, global_step_num: 245322, avg loss: 0.0016438146415625866, step: 323, replay memory length: 245322\n",
      "episode: 792, score: 0, global_step_num: 245645, avg loss: 0.0015991481043533403, step: 323, replay memory length: 245645\n",
      "episode: 793, score: 0, global_step_num: 245968, avg loss: 0.0014513504573260884, step: 323, replay memory length: 245968\n",
      "episode: 794, score: 0, global_step_num: 246291, avg loss: 0.0012412578778387996, step: 323, replay memory length: 246291\n",
      "episode: 795, score: 0, global_step_num: 246614, avg loss: 0.0009844977223445696, step: 323, replay memory length: 246614\n",
      "episode: 796, score: 0, global_step_num: 246937, avg loss: 0.0021814901948563046, step: 323, replay memory length: 246937\n",
      "episode: 797, score: 0, global_step_num: 247260, avg loss: 0.0018466407614972297, step: 323, replay memory length: 247260\n",
      "episode: 798, score: 0, global_step_num: 247583, avg loss: 0.0018418687064250512, step: 323, replay memory length: 247583\n",
      "episode: 799, score: 0, global_step_num: 247906, avg loss: 0.0013312105092134815, step: 323, replay memory length: 247906\n",
      "episode: 800, score: 0, global_step_num: 248229, avg loss: 0.0017686215061377215, step: 323, replay memory length: 248229\n",
      "episode: 801, score: 0, global_step_num: 248552, avg loss: 0.0012993801741765026, step: 323, replay memory length: 248552\n",
      "episode: 802, score: 0, global_step_num: 248875, avg loss: 0.001705034467048461, step: 323, replay memory length: 248875\n",
      "episode: 803, score: 0, global_step_num: 249198, avg loss: 0.0018104579512087733, step: 323, replay memory length: 249198\n",
      "episode: 804, score: 0, global_step_num: 249521, avg loss: 0.0014767015047294392, step: 323, replay memory length: 249521\n",
      "episode: 805, score: 0, global_step_num: 249844, avg loss: 0.0014580496991181712, step: 323, replay memory length: 249844\n",
      "episode: 806, score: 0, global_step_num: 250167, avg loss: 0.0015360491733001772, step: 323, replay memory length: 250167\n",
      "episode: 807, score: 0, global_step_num: 250490, avg loss: 0.0011491335512927726, step: 323, replay memory length: 250490\n",
      "episode: 808, score: 0, global_step_num: 250813, avg loss: 0.001495433453456705, step: 323, replay memory length: 250813\n",
      "episode: 809, score: 0, global_step_num: 251136, avg loss: 0.0017370662147836965, step: 323, replay memory length: 251136\n",
      "episode: 810, score: 0, global_step_num: 251459, avg loss: 0.001592696841115115, step: 323, replay memory length: 251459\n",
      "episode: 811, score: 0, global_step_num: 251782, avg loss: 0.0019458845599672786, step: 323, replay memory length: 251782\n",
      "episode: 812, score: 0, global_step_num: 252105, avg loss: 0.0016666399902961154, step: 323, replay memory length: 252105\n",
      "episode: 813, score: 0, global_step_num: 252428, avg loss: 0.001541538595967621, step: 323, replay memory length: 252428\n",
      "episode: 814, score: 0, global_step_num: 252751, avg loss: 0.0016628508351135645, step: 323, replay memory length: 252751\n",
      "episode: 815, score: 0, global_step_num: 253074, avg loss: 0.0015865835445706565, step: 323, replay memory length: 253074\n",
      "episode: 816, score: 0, global_step_num: 253397, avg loss: 0.001567749540398253, step: 323, replay memory length: 253397\n",
      "episode: 817, score: 0, global_step_num: 253720, avg loss: 0.0014882625601805258, step: 323, replay memory length: 253720\n",
      "episode: 818, score: 0, global_step_num: 254043, avg loss: 0.0014966417268683487, step: 323, replay memory length: 254043\n",
      "episode: 819, score: 0, global_step_num: 254366, avg loss: 0.0013773207848815207, step: 323, replay memory length: 254366\n",
      "episode: 820, score: 0, global_step_num: 254689, avg loss: 0.001791425480016874, step: 323, replay memory length: 254689\n",
      "episode: 821, score: 0, global_step_num: 255012, avg loss: 0.001490761485170659, step: 323, replay memory length: 255012\n",
      "episode: 822, score: 1.0, global_step_num: 255237, avg loss: 0.0016851903966259366, step: 225, replay memory length: 255237\n",
      "episode: 823, score: 0, global_step_num: 255560, avg loss: 0.0013337252059511578, step: 323, replay memory length: 255560\n",
      "episode: 824, score: 0, global_step_num: 255883, avg loss: 0.0012110240691705799, step: 323, replay memory length: 255883\n",
      "episode: 825, score: 0, global_step_num: 256206, avg loss: 0.001839421062905101, step: 323, replay memory length: 256206\n",
      "episode: 826, score: 0, global_step_num: 256529, avg loss: 0.0011645904715839744, step: 323, replay memory length: 256529\n",
      "episode: 827, score: 0, global_step_num: 256852, avg loss: 0.0013437936145786547, step: 323, replay memory length: 256852\n",
      "episode: 828, score: 1.0, global_step_num: 257062, avg loss: 0.0018672714171641149, step: 210, replay memory length: 257062\n",
      "episode: 829, score: 0, global_step_num: 257385, avg loss: 0.0019354793619742355, step: 323, replay memory length: 257385\n",
      "episode: 830, score: 0, global_step_num: 257708, avg loss: 0.0013242973314513324, step: 323, replay memory length: 257708\n",
      "episode: 831, score: 0, global_step_num: 258031, avg loss: 0.0011092515577766106, step: 323, replay memory length: 258031\n",
      "episode: 832, score: 0, global_step_num: 258354, avg loss: 0.0015950820998001437, step: 323, replay memory length: 258354\n",
      "episode: 833, score: 0, global_step_num: 258677, avg loss: 0.0017992438199155353, step: 323, replay memory length: 258677\n",
      "episode: 834, score: 0, global_step_num: 259000, avg loss: 0.0012056419414289883, step: 323, replay memory length: 259000\n",
      "episode: 835, score: 0, global_step_num: 259323, avg loss: 0.0018690694172726259, step: 323, replay memory length: 259323\n",
      "episode: 836, score: 0, global_step_num: 259646, avg loss: 0.0010343394859106641, step: 323, replay memory length: 259646\n",
      "episode: 837, score: 0, global_step_num: 259969, avg loss: 0.001632061236542025, step: 323, replay memory length: 259969\n",
      "episode: 838, score: 0, global_step_num: 260292, avg loss: 0.00156113771723489, step: 323, replay memory length: 260292\n",
      "episode: 839, score: 0, global_step_num: 260615, avg loss: 0.0015269661694965575, step: 323, replay memory length: 260615\n",
      "episode: 840, score: 0, global_step_num: 260938, avg loss: 0.00114482506544201, step: 323, replay memory length: 260938\n",
      "episode: 841, score: 0, global_step_num: 261261, avg loss: 0.0011373839584826084, step: 323, replay memory length: 261261\n",
      "episode: 842, score: 0, global_step_num: 261584, avg loss: 0.0015942814251004177, step: 323, replay memory length: 261584\n",
      "episode: 844, score: 0, global_step_num: 262230, avg loss: 0.0016233832678973093, step: 323, replay memory length: 262230\n",
      "episode: 845, score: 1.0, global_step_num: 262389, avg loss: 0.0019506782610224265, step: 159, replay memory length: 262389\n",
      "episode: 846, score: 0, global_step_num: 262712, avg loss: 0.001606362308000927, step: 323, replay memory length: 262712\n",
      "episode: 847, score: 0, global_step_num: 263035, avg loss: 0.001574114502329039, step: 323, replay memory length: 263035\n",
      "episode: 848, score: 0, global_step_num: 263358, avg loss: 0.0017762293165885772, step: 323, replay memory length: 263358\n",
      "episode: 849, score: 0, global_step_num: 263681, avg loss: 0.00175410051972118, step: 323, replay memory length: 263681\n",
      "episode: 850, score: 1.0, global_step_num: 263964, avg loss: 0.0012074860652470376, step: 283, replay memory length: 263964\n",
      "episode: 851, score: 0, global_step_num: 264287, avg loss: 0.0015674954501526304, step: 323, replay memory length: 264287\n",
      "episode: 852, score: 0, global_step_num: 264610, avg loss: 0.0014861787097826284, step: 323, replay memory length: 264610\n",
      "episode: 853, score: 0, global_step_num: 264933, avg loss: 0.0016874682013180002, step: 323, replay memory length: 264933\n",
      "episode: 854, score: 0, global_step_num: 265256, avg loss: 0.0014596508721347824, step: 323, replay memory length: 265256\n",
      "episode: 855, score: 0, global_step_num: 265579, avg loss: 0.0017303267392014415, step: 323, replay memory length: 265579\n",
      "episode: 856, score: 0, global_step_num: 265902, avg loss: 0.0013966444101991809, step: 323, replay memory length: 265902\n",
      "episode: 857, score: 0, global_step_num: 266225, avg loss: 0.0014635198141394858, step: 323, replay memory length: 266225\n",
      "episode: 858, score: 0, global_step_num: 266548, avg loss: 0.0016056227060534502, step: 323, replay memory length: 266548\n",
      "episode: 859, score: 1.0, global_step_num: 266712, avg loss: 0.001805989692013277, step: 164, replay memory length: 266712\n",
      "episode: 860, score: 0, global_step_num: 267035, avg loss: 0.001752204798476922, step: 323, replay memory length: 267035\n",
      "episode: 861, score: 0, global_step_num: 267358, avg loss: 0.0017681787564608115, step: 323, replay memory length: 267358\n",
      "episode: 862, score: 0, global_step_num: 267681, avg loss: 0.0017836432070372906, step: 323, replay memory length: 267681\n",
      "episode: 863, score: 0, global_step_num: 268004, avg loss: 0.0011823289801256068, step: 323, replay memory length: 268004\n",
      "episode: 864, score: 0, global_step_num: 268327, avg loss: 0.0018055921161893801, step: 323, replay memory length: 268327\n",
      "episode: 865, score: 0, global_step_num: 268650, avg loss: 0.0017974829068705888, step: 323, replay memory length: 268650\n",
      "episode: 866, score: 0, global_step_num: 268973, avg loss: 0.001657154763063212, step: 323, replay memory length: 268973\n",
      "episode: 867, score: 0, global_step_num: 269296, avg loss: 0.0010702541843834958, step: 323, replay memory length: 269296\n",
      "episode: 868, score: 0, global_step_num: 269619, avg loss: 0.0016691915764007628, step: 323, replay memory length: 269619\n",
      "episode: 869, score: 0, global_step_num: 269942, avg loss: 0.0018676606618264092, step: 323, replay memory length: 269942\n",
      "episode: 871, score: 0, global_step_num: 270588, avg loss: 0.0015724291973638511, step: 323, replay memory length: 270588\n",
      "episode: 872, score: 1.0, global_step_num: 270875, avg loss: 0.0016071525976800165, step: 287, replay memory length: 270875\n",
      "episode: 873, score: 0, global_step_num: 271198, avg loss: 0.0013162013161778113, step: 323, replay memory length: 271198\n",
      "episode: 874, score: 0, global_step_num: 271521, avg loss: 0.001584078911940931, step: 323, replay memory length: 271521\n",
      "episode: 875, score: 0, global_step_num: 271844, avg loss: 0.0015993419658099288, step: 323, replay memory length: 271844\n",
      "episode: 876, score: 0, global_step_num: 272167, avg loss: 0.0018910220768232622, step: 323, replay memory length: 272167\n",
      "episode: 877, score: 0, global_step_num: 272490, avg loss: 0.0014555951661730394, step: 323, replay memory length: 272490\n",
      "episode: 878, score: 0, global_step_num: 272813, avg loss: 0.001768599257008333, step: 323, replay memory length: 272813\n",
      "episode: 879, score: 0, global_step_num: 273136, avg loss: 0.001613626572100941, step: 323, replay memory length: 273136\n",
      "episode: 880, score: 0, global_step_num: 273459, avg loss: 0.0012164360904261858, step: 323, replay memory length: 273459\n",
      "episode: 881, score: 1.0, global_step_num: 273713, avg loss: 0.0016788258444792046, step: 254, replay memory length: 273713\n",
      "episode: 882, score: 0, global_step_num: 274036, avg loss: 0.0015459502808644117, step: 323, replay memory length: 274036\n",
      "episode: 883, score: 0, global_step_num: 274359, avg loss: 0.001877323289754319, step: 323, replay memory length: 274359\n",
      "episode: 884, score: 0, global_step_num: 274682, avg loss: 0.0012062578126029908, step: 323, replay memory length: 274682\n",
      "episode: 885, score: 0, global_step_num: 275005, avg loss: 0.0017545080883465622, step: 323, replay memory length: 275005\n",
      "episode: 886, score: 0, global_step_num: 275328, avg loss: 0.0018404898082144286, step: 323, replay memory length: 275328\n",
      "episode: 887, score: 0, global_step_num: 275651, avg loss: 0.001413952035334198, step: 323, replay memory length: 275651\n",
      "episode: 888, score: 0, global_step_num: 275974, avg loss: 0.001444150838836747, step: 323, replay memory length: 275974\n",
      "episode: 889, score: 0, global_step_num: 276297, avg loss: 0.0012075247443850802, step: 323, replay memory length: 276297\n",
      "episode: 890, score: 0, global_step_num: 276620, avg loss: 0.001334649726499372, step: 323, replay memory length: 276620\n",
      "episode: 891, score: 1.0, global_step_num: 276753, avg loss: 0.0011652289916066667, step: 133, replay memory length: 276753\n",
      "episode: 892, score: 0, global_step_num: 277076, avg loss: 0.0016029457553455308, step: 323, replay memory length: 277076\n",
      "episode: 893, score: 0, global_step_num: 277399, avg loss: 0.0018152194669465325, step: 323, replay memory length: 277399\n",
      "episode: 894, score: 0, global_step_num: 277722, avg loss: 0.0016051025873362373, step: 323, replay memory length: 277722\n",
      "episode: 895, score: 0, global_step_num: 278045, avg loss: 0.0016203299824732926, step: 323, replay memory length: 278045\n",
      "episode: 896, score: 0, global_step_num: 278368, avg loss: 0.0014097657891150041, step: 323, replay memory length: 278368\n",
      "episode: 897, score: 0, global_step_num: 278691, avg loss: 0.0012066304110163013, step: 323, replay memory length: 278691\n",
      "episode: 898, score: 0, global_step_num: 279014, avg loss: 0.0015799346909081448, step: 323, replay memory length: 279014\n",
      "episode: 899, score: 0, global_step_num: 279337, avg loss: 0.00188197041407754, step: 323, replay memory length: 279337\n",
      "episode: 900, score: 0, global_step_num: 279660, avg loss: 0.0017814615225055063, step: 323, replay memory length: 279660\n",
      "episode: 901, score: 0, global_step_num: 279983, avg loss: 0.001492362850625649, step: 323, replay memory length: 279983\n",
      "episode: 902, score: 0, global_step_num: 280306, avg loss: 0.001937507789640312, step: 323, replay memory length: 280306\n",
      "episode: 903, score: 1.0, global_step_num: 280357, avg loss: 0.0009872960066536953, step: 51, replay memory length: 280357\n",
      "episode: 904, score: 1.0, global_step_num: 280593, avg loss: 0.002319935165483542, step: 236, replay memory length: 280593\n",
      "episode: 905, score: 0, global_step_num: 280916, avg loss: 0.001596432215631779, step: 323, replay memory length: 280916\n",
      "episode: 906, score: 1.0, global_step_num: 281075, avg loss: 0.0011441510895674124, step: 159, replay memory length: 281075\n",
      "episode: 907, score: 0, global_step_num: 281398, avg loss: 0.0012414049674772502, step: 323, replay memory length: 281398\n",
      "episode: 908, score: 0, global_step_num: 281721, avg loss: 0.0014655535616709663, step: 323, replay memory length: 281721\n",
      "episode: 909, score: 0, global_step_num: 282044, avg loss: 0.0014739749856620416, step: 323, replay memory length: 282044\n",
      "episode: 910, score: 1.0, global_step_num: 282154, avg loss: 0.0009126316450006429, step: 110, replay memory length: 282154\n",
      "episode: 911, score: 0, global_step_num: 282477, avg loss: 0.0018530271104662422, step: 323, replay memory length: 282477\n",
      "episode: 912, score: 1.0, global_step_num: 282795, avg loss: 0.0016171598541353338, step: 318, replay memory length: 282795\n",
      "episode: 913, score: 0, global_step_num: 283118, avg loss: 0.00190929869744363, step: 323, replay memory length: 283118\n",
      "episode: 914, score: 0, global_step_num: 283441, avg loss: 0.001360653792224905, step: 323, replay memory length: 283441\n",
      "episode: 915, score: 1.0, global_step_num: 283532, avg loss: 0.0014334394702198371, step: 91, replay memory length: 283532\n",
      "episode: 916, score: 0, global_step_num: 283855, avg loss: 0.001042457970070583, step: 323, replay memory length: 283855\n",
      "episode: 917, score: 0, global_step_num: 284178, avg loss: 0.0014336979369962322, step: 323, replay memory length: 284178\n",
      "episode: 918, score: 0, global_step_num: 284501, avg loss: 0.0015294651578162425, step: 323, replay memory length: 284501\n",
      "episode: 919, score: 0, global_step_num: 284824, avg loss: 0.0013171880267995554, step: 323, replay memory length: 284824\n",
      "episode: 920, score: 0, global_step_num: 285147, avg loss: 0.001833844122535962, step: 323, replay memory length: 285147\n",
      "episode: 921, score: 0, global_step_num: 285470, avg loss: 0.0015090080584175402, step: 323, replay memory length: 285470\n",
      "episode: 922, score: 0, global_step_num: 285793, avg loss: 0.0012436859856744227, step: 323, replay memory length: 285793\n",
      "episode: 923, score: 1.0, global_step_num: 285846, avg loss: 0.001614322421187782, step: 53, replay memory length: 285846\n",
      "episode: 924, score: 0, global_step_num: 286169, avg loss: 0.001302483579334825, step: 323, replay memory length: 286169\n",
      "episode: 925, score: 1.0, global_step_num: 286390, avg loss: 0.0011668778294725553, step: 221, replay memory length: 286390\n",
      "episode: 926, score: 0, global_step_num: 286713, avg loss: 0.0015932840160924966, step: 323, replay memory length: 286713\n",
      "episode: 927, score: 1.0, global_step_num: 286973, avg loss: 0.0018540001137423063, step: 260, replay memory length: 286973\n",
      "episode: 928, score: 0, global_step_num: 287296, avg loss: 0.0012903665383616242, step: 323, replay memory length: 287296\n",
      "episode: 929, score: 0, global_step_num: 287619, avg loss: 0.0017731388965592418, step: 323, replay memory length: 287619\n",
      "episode: 930, score: 0, global_step_num: 287942, avg loss: 0.001508105284960455, step: 323, replay memory length: 287942\n",
      "episode: 931, score: 0, global_step_num: 288265, avg loss: 0.0019671396355386114, step: 323, replay memory length: 288265\n",
      "episode: 932, score: 0, global_step_num: 288588, avg loss: 0.0012735289972247428, step: 323, replay memory length: 288588\n",
      "episode: 933, score: 0, global_step_num: 288911, avg loss: 0.001754071717671202, step: 323, replay memory length: 288911\n",
      "episode: 934, score: 0, global_step_num: 289234, avg loss: 0.0017996331955889525, step: 323, replay memory length: 289234\n",
      "episode: 935, score: 0, global_step_num: 289557, avg loss: 0.0011483135471500178, step: 323, replay memory length: 289557\n",
      "episode: 936, score: 0, global_step_num: 289880, avg loss: 0.0017199530629629011, step: 323, replay memory length: 289880\n",
      "episode: 937, score: 0, global_step_num: 290203, avg loss: 0.001434085390121744, step: 323, replay memory length: 290203\n",
      "episode: 938, score: 0, global_step_num: 290526, avg loss: 0.001533956354193408, step: 323, replay memory length: 290526\n",
      "episode: 939, score: 0, global_step_num: 290849, avg loss: 0.0011914208678115265, step: 323, replay memory length: 290849\n",
      "episode: 940, score: 0, global_step_num: 291172, avg loss: 0.0017598404920079775, step: 323, replay memory length: 291172\n",
      "episode: 941, score: 0, global_step_num: 291495, avg loss: 0.0015827539906330523, step: 323, replay memory length: 291495\n",
      "episode: 942, score: 1.0, global_step_num: 291719, avg loss: 0.001624628739266752, step: 224, replay memory length: 291719\n",
      "episode: 943, score: 1.0, global_step_num: 291973, avg loss: 0.001211207095650927, step: 254, replay memory length: 291973\n",
      "episode: 944, score: 0, global_step_num: 292296, avg loss: 0.0015463847440055683, step: 323, replay memory length: 292296\n",
      "episode: 945, score: 0, global_step_num: 292619, avg loss: 0.0015965917125152938, step: 323, replay memory length: 292619\n",
      "episode: 946, score: 0, global_step_num: 292942, avg loss: 0.0018760788366012024, step: 323, replay memory length: 292942\n",
      "episode: 947, score: 0, global_step_num: 293265, avg loss: 0.0012257620746850952, step: 323, replay memory length: 293265\n",
      "episode: 948, score: 0, global_step_num: 293588, avg loss: 0.0012525982690328838, step: 323, replay memory length: 293588\n",
      "episode: 949, score: 0, global_step_num: 293911, avg loss: 0.0018461093117135652, step: 323, replay memory length: 293911\n",
      "episode: 950, score: 0, global_step_num: 294234, avg loss: 0.0014900895140207279, step: 323, replay memory length: 294234\n",
      "episode: 951, score: 0, global_step_num: 294557, avg loss: 0.0013107860244440206, step: 323, replay memory length: 294557\n",
      "episode: 952, score: 0, global_step_num: 294880, avg loss: 0.0018501135455463152, step: 323, replay memory length: 294880\n",
      "episode: 953, score: 0, global_step_num: 295203, avg loss: 0.0015503453892797947, step: 323, replay memory length: 295203\n",
      "episode: 954, score: 0, global_step_num: 295526, avg loss: 0.0014609979910124291, step: 323, replay memory length: 295526\n",
      "episode: 955, score: 0, global_step_num: 295849, avg loss: 0.001383280644967449, step: 323, replay memory length: 295849\n",
      "episode: 956, score: 0, global_step_num: 296172, avg loss: 0.0016865558790844883, step: 323, replay memory length: 296172\n",
      "episode: 957, score: 0, global_step_num: 296495, avg loss: 0.0013819820465987532, step: 323, replay memory length: 296495\n",
      "episode: 958, score: 0, global_step_num: 296818, avg loss: 0.0015387747331744783, step: 323, replay memory length: 296818\n",
      "episode: 959, score: 0, global_step_num: 297141, avg loss: 0.0014451482716970815, step: 323, replay memory length: 297141\n",
      "episode: 960, score: 0, global_step_num: 297464, avg loss: 0.001769864200736372, step: 323, replay memory length: 297464\n",
      "episode: 961, score: 0, global_step_num: 297787, avg loss: 0.001399473093820107, step: 323, replay memory length: 297787\n",
      "episode: 962, score: 0, global_step_num: 298110, avg loss: 0.001314124111328174, step: 323, replay memory length: 298110\n",
      "episode: 963, score: 0, global_step_num: 298433, avg loss: 0.0008952521946429057, step: 323, replay memory length: 298433\n",
      "episode: 964, score: 1.0, global_step_num: 298477, avg loss: 0.0011447788844882532, step: 44, replay memory length: 298477\n",
      "episode: 965, score: 0, global_step_num: 298800, avg loss: 0.0015559567830033321, step: 323, replay memory length: 298800\n",
      "episode: 966, score: 0, global_step_num: 299123, avg loss: 0.0018358723426683, step: 323, replay memory length: 299123\n",
      "episode: 967, score: 0, global_step_num: 299446, avg loss: 0.0009741310564982297, step: 323, replay memory length: 299446\n",
      "episode: 968, score: 0, global_step_num: 299769, avg loss: 0.0020412856062673986, step: 323, replay memory length: 299769\n",
      "episode: 969, score: 1.0, global_step_num: 300003, avg loss: 0.0015932781675590563, step: 234, replay memory length: 300003\n",
      "episode: 970, score: 0, global_step_num: 300326, avg loss: 0.0012731333838368211, step: 323, replay memory length: 300326\n",
      "episode: 971, score: 0, global_step_num: 300649, avg loss: 0.0017167058384852216, step: 323, replay memory length: 300649\n",
      "episode: 972, score: 1.0, global_step_num: 300789, avg loss: 0.0012518335804608276, step: 140, replay memory length: 300789\n",
      "episode: 973, score: 0, global_step_num: 301112, avg loss: 0.0013551122547198174, step: 323, replay memory length: 301112\n",
      "episode: 974, score: 0, global_step_num: 301435, avg loss: 0.0013708043908157916, step: 323, replay memory length: 301435\n",
      "episode: 975, score: 1.0, global_step_num: 301720, avg loss: 0.001154554785352957, step: 285, replay memory length: 301720\n",
      "episode: 976, score: 0, global_step_num: 302043, avg loss: 0.0016087158849814635, step: 323, replay memory length: 302043\n",
      "episode: 977, score: 0, global_step_num: 302366, avg loss: 0.0018056029578364594, step: 323, replay memory length: 302366\n",
      "episode: 978, score: 1.0, global_step_num: 302572, avg loss: 0.0009364487754000329, step: 206, replay memory length: 302572\n",
      "episode: 979, score: 0, global_step_num: 302895, avg loss: 0.0015894754852009496, step: 323, replay memory length: 302895\n",
      "episode: 980, score: 0, global_step_num: 303218, avg loss: 0.0014414128257076496, step: 323, replay memory length: 303218\n",
      "episode: 981, score: 0, global_step_num: 303541, avg loss: 0.001709212989293795, step: 323, replay memory length: 303541\n",
      "episode: 982, score: 1.0, global_step_num: 303760, avg loss: 0.0015333433016561494, step: 219, replay memory length: 303760\n",
      "episode: 983, score: 0, global_step_num: 304083, avg loss: 0.001380991520973365, step: 323, replay memory length: 304083\n",
      "episode: 984, score: 1.0, global_step_num: 304156, avg loss: 0.0006693816026262078, step: 73, replay memory length: 304156\n",
      "episode: 985, score: 0, global_step_num: 304479, avg loss: 0.001389145210825642, step: 323, replay memory length: 304479\n",
      "episode: 986, score: 0, global_step_num: 304802, avg loss: 0.001599425142808779, step: 323, replay memory length: 304802\n",
      "episode: 987, score: 0, global_step_num: 305125, avg loss: 0.0013511575022926573, step: 323, replay memory length: 305125\n",
      "episode: 988, score: 0, global_step_num: 305448, avg loss: 0.0016434181735086963, step: 323, replay memory length: 305448\n",
      "episode: 989, score: 0, global_step_num: 305771, avg loss: 0.0011185511131754015, step: 323, replay memory length: 305771\n",
      "episode: 990, score: 0, global_step_num: 306094, avg loss: 0.0014895267380013952, step: 323, replay memory length: 306094\n",
      "episode: 991, score: 1.0, global_step_num: 306254, avg loss: 0.001578474133458485, step: 160, replay memory length: 306254\n",
      "episode: 992, score: 0, global_step_num: 306577, avg loss: 0.0017686559718984162, step: 323, replay memory length: 306577\n",
      "episode: 993, score: 0, global_step_num: 306900, avg loss: 0.0019201159589904231, step: 323, replay memory length: 306900\n",
      "episode: 994, score: 0, global_step_num: 307223, avg loss: 0.001283856055811537, step: 323, replay memory length: 307223\n",
      "episode: 995, score: 1.0, global_step_num: 307377, avg loss: 0.001618046077138305, step: 154, replay memory length: 307377\n",
      "episode: 996, score: 0, global_step_num: 307700, avg loss: 0.0015292406728423923, step: 323, replay memory length: 307700\n",
      "episode: 997, score: 0, global_step_num: 308023, avg loss: 0.0012534988341101234, step: 323, replay memory length: 308023\n",
      "episode: 998, score: 0, global_step_num: 308346, avg loss: 0.0015671639343808894, step: 323, replay memory length: 308346\n",
      "episode: 999, score: 0, global_step_num: 308669, avg loss: 0.0012739755823238754, step: 323, replay memory length: 308669\n",
      "episode: 1000, score: 1.0, global_step_num: 308730, avg loss: 0.0010793086123650013, step: 61, replay memory length: 308730\n",
      "episode: 1001, score: 0, global_step_num: 309053, avg loss: 0.0010181180262170471, step: 323, replay memory length: 309053\n",
      "episode: 1002, score: 0, global_step_num: 309376, avg loss: 0.001504061229707499, step: 323, replay memory length: 309376\n",
      "episode: 1003, score: 0, global_step_num: 309699, avg loss: 0.0012736751027026371, step: 323, replay memory length: 309699\n",
      "episode: 1004, score: 0, global_step_num: 310022, avg loss: 0.0011471064730887558, step: 323, replay memory length: 310022\n",
      "episode: 1005, score: 1.0, global_step_num: 310195, avg loss: 0.0019256929351648836, step: 173, replay memory length: 310195\n",
      "episode: 1006, score: 1.0, global_step_num: 310454, avg loss: 0.0016932529029437533, step: 259, replay memory length: 310454\n",
      "episode: 1007, score: 1.0, global_step_num: 310593, avg loss: 0.0017379587833857455, step: 139, replay memory length: 310593\n",
      "episode: 1008, score: 1.0, global_step_num: 310814, avg loss: 0.0015044235502023288, step: 221, replay memory length: 310814\n",
      "episode: 1009, score: 0, global_step_num: 311137, avg loss: 0.0013165442178827503, step: 323, replay memory length: 311137\n",
      "episode: 1010, score: 0, global_step_num: 311460, avg loss: 0.001277195068118422, step: 323, replay memory length: 311460\n",
      "episode: 1011, score: 0, global_step_num: 311783, avg loss: 0.0016168304642160253, step: 323, replay memory length: 311783\n",
      "episode: 1012, score: 0, global_step_num: 312106, avg loss: 0.0017697030441770783, step: 323, replay memory length: 312106\n",
      "episode: 1013, score: 0, global_step_num: 312429, avg loss: 0.0013776805412479445, step: 323, replay memory length: 312429\n",
      "episode: 1014, score: 1.0, global_step_num: 312610, avg loss: 0.001291227381933526, step: 181, replay memory length: 312610\n",
      "episode: 1015, score: 0, global_step_num: 312933, avg loss: 0.001691116340129826, step: 323, replay memory length: 312933\n",
      "episode: 1016, score: 0, global_step_num: 313256, avg loss: 0.0011154628453498312, step: 323, replay memory length: 313256\n",
      "episode: 1017, score: 0, global_step_num: 313579, avg loss: 0.001270247832167467, step: 323, replay memory length: 313579\n",
      "episode: 1018, score: 0, global_step_num: 313902, avg loss: 0.0017987599494292518, step: 323, replay memory length: 313902\n",
      "episode: 1019, score: 0, global_step_num: 314225, avg loss: 0.00135072447644597, step: 323, replay memory length: 314225\n",
      "episode: 1020, score: 0, global_step_num: 314548, avg loss: 0.0017785798226292798, step: 323, replay memory length: 314548\n",
      "episode: 1021, score: 1.0, global_step_num: 314755, avg loss: 0.0011181194688352236, step: 207, replay memory length: 314755\n",
      "episode: 1022, score: 0, global_step_num: 315078, avg loss: 0.0011882459261601873, step: 323, replay memory length: 315078\n",
      "episode: 1023, score: 0, global_step_num: 315401, avg loss: 0.0011913192140448647, step: 323, replay memory length: 315401\n",
      "episode: 1024, score: 0, global_step_num: 315724, avg loss: 0.0011514813961899907, step: 323, replay memory length: 315724\n",
      "episode: 1025, score: 0, global_step_num: 316047, avg loss: 0.0012605737862248488, step: 323, replay memory length: 316047\n",
      "episode: 1026, score: 0, global_step_num: 316370, avg loss: 0.0014011322438830015, step: 323, replay memory length: 316370\n",
      "episode: 1027, score: 0, global_step_num: 316693, avg loss: 0.0015486486387616377, step: 323, replay memory length: 316693\n",
      "episode: 1028, score: 0, global_step_num: 317016, avg loss: 0.0014655481155378504, step: 323, replay memory length: 317016\n",
      "episode: 1029, score: 0, global_step_num: 317339, avg loss: 0.0010013629476906382, step: 323, replay memory length: 317339\n",
      "episode: 1030, score: 0, global_step_num: 317662, avg loss: 0.0014877804499705538, step: 323, replay memory length: 317662\n",
      "episode: 1031, score: 1.0, global_step_num: 317967, avg loss: 0.0016279703202479916, step: 305, replay memory length: 317967\n",
      "episode: 1032, score: 0, global_step_num: 318290, avg loss: 0.001615785358678827, step: 323, replay memory length: 318290\n",
      "episode: 1033, score: 0, global_step_num: 318613, avg loss: 0.0014672143092852384, step: 323, replay memory length: 318613\n",
      "episode: 1034, score: 1.0, global_step_num: 318835, avg loss: 0.0013239998860839692, step: 222, replay memory length: 318835\n",
      "episode: 1035, score: 0, global_step_num: 319158, avg loss: 0.001886466283949546, step: 323, replay memory length: 319158\n",
      "episode: 1036, score: 1.0, global_step_num: 319368, avg loss: 0.0019695986394513707, step: 210, replay memory length: 319368\n",
      "episode: 1037, score: 1.0, global_step_num: 319501, avg loss: 0.0015362197447169258, step: 133, replay memory length: 319501\n",
      "episode: 1038, score: 0, global_step_num: 319824, avg loss: 0.0011496012933336036, step: 323, replay memory length: 319824\n",
      "episode: 1039, score: 1.0, global_step_num: 319856, avg loss: 0.001421874303957793, step: 32, replay memory length: 319856\n",
      "episode: 1040, score: 0, global_step_num: 320179, avg loss: 0.0016852789579898282, step: 323, replay memory length: 320179\n",
      "episode: 1041, score: 0, global_step_num: 320502, avg loss: 0.0013264561378550767, step: 323, replay memory length: 320502\n",
      "episode: 1042, score: 0, global_step_num: 320825, avg loss: 0.0015093926736717944, step: 323, replay memory length: 320825\n",
      "episode: 1043, score: 0, global_step_num: 321148, avg loss: 0.0017177919171895478, step: 323, replay memory length: 321148\n",
      "episode: 1044, score: 0, global_step_num: 321471, avg loss: 0.0012652747687758338, step: 323, replay memory length: 321471\n",
      "episode: 1045, score: 0, global_step_num: 321794, avg loss: 0.0017049321128638792, step: 323, replay memory length: 321794\n",
      "episode: 1046, score: 0, global_step_num: 322117, avg loss: 0.001302317111202579, step: 323, replay memory length: 322117\n",
      "episode: 1047, score: 0, global_step_num: 322440, avg loss: 0.001519860372543399, step: 323, replay memory length: 322440\n",
      "episode: 1048, score: 1.0, global_step_num: 322594, avg loss: 0.0008377501772978481, step: 154, replay memory length: 322594\n",
      "episode: 1049, score: 0, global_step_num: 322917, avg loss: 0.001100580609194868, step: 323, replay memory length: 322917\n",
      "episode: 1050, score: 0, global_step_num: 323240, avg loss: 0.00135140177816969, step: 323, replay memory length: 323240\n",
      "episode: 1051, score: 0, global_step_num: 323563, avg loss: 0.0013688512476760296, step: 323, replay memory length: 323563\n",
      "episode: 1052, score: 0, global_step_num: 323886, avg loss: 0.0012832593278734898, step: 323, replay memory length: 323886\n",
      "episode: 1053, score: 0, global_step_num: 324209, avg loss: 0.0010143801183296413, step: 323, replay memory length: 324209\n",
      "episode: 1054, score: 0, global_step_num: 324532, avg loss: 0.0016616092332587193, step: 323, replay memory length: 324532\n",
      "episode: 1055, score: 0, global_step_num: 324855, avg loss: 0.0015064900538870542, step: 323, replay memory length: 324855\n",
      "episode: 1056, score: 0, global_step_num: 325178, avg loss: 0.00170686889112054, step: 323, replay memory length: 325178\n",
      "episode: 1057, score: 0, global_step_num: 325501, avg loss: 0.0013791202433481328, step: 323, replay memory length: 325501\n",
      "episode: 1058, score: 0, global_step_num: 325824, avg loss: 0.0011176950756663208, step: 323, replay memory length: 325824\n",
      "episode: 1059, score: 0, global_step_num: 326147, avg loss: 0.001727464281767895, step: 323, replay memory length: 326147\n",
      "episode: 1060, score: 0, global_step_num: 326470, avg loss: 0.001611101969170907, step: 323, replay memory length: 326470\n",
      "episode: 1061, score: 0, global_step_num: 326793, avg loss: 0.001587874800923702, step: 323, replay memory length: 326793\n",
      "episode: 1062, score: 0, global_step_num: 327116, avg loss: 0.0011368067383358406, step: 323, replay memory length: 327116\n",
      "episode: 1063, score: 0, global_step_num: 327439, avg loss: 0.0012237594537115514, step: 323, replay memory length: 327439\n",
      "episode: 1064, score: 0, global_step_num: 327762, avg loss: 0.001207296917302594, step: 323, replay memory length: 327762\n",
      "episode: 1065, score: 0, global_step_num: 328085, avg loss: 0.0018193738448810711, step: 323, replay memory length: 328085\n",
      "episode: 1066, score: 1.0, global_step_num: 328316, avg loss: 0.0017186605085760566, step: 231, replay memory length: 328316\n",
      "episode: 1067, score: 0, global_step_num: 328639, avg loss: 0.001462872067718829, step: 323, replay memory length: 328639\n",
      "episode: 1068, score: 0, global_step_num: 328962, avg loss: 0.0017712893552421355, step: 323, replay memory length: 328962\n",
      "episode: 1069, score: 0, global_step_num: 329285, avg loss: 0.0010281230487404292, step: 323, replay memory length: 329285\n",
      "episode: 1070, score: 0, global_step_num: 329608, avg loss: 0.0013865256743106793, step: 323, replay memory length: 329608\n",
      "episode: 1071, score: 0, global_step_num: 329931, avg loss: 0.0015176015428323105, step: 323, replay memory length: 329931\n",
      "episode: 1072, score: 1.0, global_step_num: 330088, avg loss: 0.0016486536212147592, step: 157, replay memory length: 330088\n",
      "episode: 1073, score: 0, global_step_num: 330411, avg loss: 0.0014930110106270544, step: 323, replay memory length: 330411\n",
      "episode: 1074, score: 0, global_step_num: 330734, avg loss: 0.0013184780958283857, step: 323, replay memory length: 330734\n",
      "episode: 1075, score: 0, global_step_num: 331057, avg loss: 0.0014758328570650557, step: 323, replay memory length: 331057\n",
      "episode: 1076, score: 0, global_step_num: 331380, avg loss: 0.001134546816099169, step: 323, replay memory length: 331380\n",
      "episode: 1077, score: 0, global_step_num: 331703, avg loss: 0.0018963897992655214, step: 323, replay memory length: 331703\n",
      "episode: 1078, score: 0, global_step_num: 332026, avg loss: 0.0010062224439881153, step: 323, replay memory length: 332026\n",
      "episode: 1079, score: 0, global_step_num: 332349, avg loss: 0.0015364537580592839, step: 323, replay memory length: 332349\n",
      "episode: 1080, score: 0, global_step_num: 332672, avg loss: 0.0016756811196515155, step: 323, replay memory length: 332672\n",
      "episode: 1081, score: 0, global_step_num: 332995, avg loss: 0.0012060504750930118, step: 323, replay memory length: 332995\n",
      "episode: 1082, score: 0, global_step_num: 333318, avg loss: 0.0016647784955591302, step: 323, replay memory length: 333318\n",
      "episode: 1083, score: 0, global_step_num: 333641, avg loss: 0.0010691883545509474, step: 323, replay memory length: 333641\n",
      "episode: 1084, score: 0, global_step_num: 333964, avg loss: 0.001385071317951767, step: 323, replay memory length: 333964\n",
      "episode: 1085, score: 0, global_step_num: 334287, avg loss: 0.0012952097550404246, step: 323, replay memory length: 334287\n",
      "episode: 1086, score: 0, global_step_num: 334610, avg loss: 0.0015208147018959104, step: 323, replay memory length: 334610\n",
      "episode: 1087, score: 0, global_step_num: 334933, avg loss: 0.0017951879450834338, step: 323, replay memory length: 334933\n",
      "episode: 1088, score: 1.0, global_step_num: 335247, avg loss: 0.001320996718782892, step: 314, replay memory length: 335247\n",
      "episode: 1089, score: 0, global_step_num: 335570, avg loss: 0.0011028262770252622, step: 323, replay memory length: 335570\n",
      "episode: 1090, score: 0, global_step_num: 335893, avg loss: 0.0012306925563795234, step: 323, replay memory length: 335893\n",
      "episode: 1091, score: 0, global_step_num: 336216, avg loss: 0.0012845193050001985, step: 323, replay memory length: 336216\n",
      "episode: 1092, score: 0, global_step_num: 336539, avg loss: 0.0015981626521357785, step: 323, replay memory length: 336539\n",
      "episode: 1093, score: 0, global_step_num: 336862, avg loss: 0.0016438998195849378, step: 323, replay memory length: 336862\n",
      "episode: 1094, score: 0, global_step_num: 337185, avg loss: 0.0013597176611461696, step: 323, replay memory length: 337185\n",
      "episode: 1095, score: 0, global_step_num: 337508, avg loss: 0.0011349521446954163, step: 323, replay memory length: 337508\n",
      "episode: 1096, score: 0, global_step_num: 337831, avg loss: 0.0013795957947849312, step: 323, replay memory length: 337831\n",
      "episode: 1097, score: 1.0, global_step_num: 337954, avg loss: 0.0011263060543673256, step: 123, replay memory length: 337954\n",
      "episode: 1098, score: 0, global_step_num: 338277, avg loss: 0.0009207008858451468, step: 323, replay memory length: 338277\n",
      "episode: 1099, score: 0, global_step_num: 338600, avg loss: 0.0012871338451848984, step: 323, replay memory length: 338600\n",
      "episode: 1100, score: 0, global_step_num: 338923, avg loss: 0.001032292421970271, step: 323, replay memory length: 338923\n",
      "episode: 1101, score: 0, global_step_num: 339246, avg loss: 0.0015386584853995964, step: 323, replay memory length: 339246\n",
      "episode: 1102, score: 0, global_step_num: 339569, avg loss: 0.0013139859851584413, step: 323, replay memory length: 339569\n",
      "episode: 1103, score: 0, global_step_num: 339892, avg loss: 0.001449198877625048, step: 323, replay memory length: 339892\n",
      "episode: 1104, score: 0, global_step_num: 340215, avg loss: 0.0010844961397121014, step: 323, replay memory length: 340215\n",
      "episode: 1105, score: 0, global_step_num: 340538, avg loss: 0.001621453638722344, step: 323, replay memory length: 340538\n",
      "episode: 1106, score: 0, global_step_num: 340861, avg loss: 0.0014292581552654605, step: 323, replay memory length: 340861\n",
      "episode: 1107, score: 0, global_step_num: 341184, avg loss: 0.0014962948725163302, step: 323, replay memory length: 341184\n",
      "episode: 1108, score: 0, global_step_num: 341507, avg loss: 0.0015531225222116588, step: 323, replay memory length: 341507\n",
      "episode: 1109, score: 0, global_step_num: 341830, avg loss: 0.0014890132312501251, step: 323, replay memory length: 341830\n",
      "episode: 1110, score: 0, global_step_num: 342153, avg loss: 0.0013964791551019735, step: 323, replay memory length: 342153\n",
      "episode: 1111, score: 0, global_step_num: 342476, avg loss: 0.0016713252966767504, step: 323, replay memory length: 342476\n",
      "episode: 1112, score: 0, global_step_num: 342799, avg loss: 0.0011979989138227625, step: 323, replay memory length: 342799\n",
      "episode: 1113, score: 0, global_step_num: 343122, avg loss: 0.0012557461624244234, step: 323, replay memory length: 343122\n",
      "episode: 1114, score: 0, global_step_num: 343445, avg loss: 0.001523925807817675, step: 323, replay memory length: 343445\n",
      "episode: 1115, score: 0, global_step_num: 343768, avg loss: 0.0014778550639168975, step: 323, replay memory length: 343768\n",
      "episode: 1116, score: 0, global_step_num: 344091, avg loss: 0.001655960635138112, step: 323, replay memory length: 344091\n",
      "episode: 1117, score: 0, global_step_num: 344414, avg loss: 0.0015800864542202377, step: 323, replay memory length: 344414\n",
      "episode: 1118, score: 0, global_step_num: 344737, avg loss: 0.0010058906777392807, step: 323, replay memory length: 344737\n",
      "episode: 1119, score: 0, global_step_num: 345060, avg loss: 0.0016359792372470571, step: 323, replay memory length: 345060\n",
      "episode: 1120, score: 0, global_step_num: 345383, avg loss: 0.0013181242419037747, step: 323, replay memory length: 345383\n",
      "episode: 1121, score: 0, global_step_num: 345706, avg loss: 0.001338585420693134, step: 323, replay memory length: 345706\n",
      "episode: 1122, score: 0, global_step_num: 346029, avg loss: 0.00140093632211681, step: 323, replay memory length: 346029\n",
      "episode: 1123, score: 0, global_step_num: 346352, avg loss: 0.0018593693922516242, step: 323, replay memory length: 346352\n",
      "episode: 1124, score: 0, global_step_num: 346675, avg loss: 0.001503771335267097, step: 323, replay memory length: 346675\n",
      "episode: 1125, score: 0, global_step_num: 346998, avg loss: 0.0015790966504126444, step: 323, replay memory length: 346998\n",
      "episode: 1126, score: 0, global_step_num: 347321, avg loss: 0.0012679013630274055, step: 323, replay memory length: 347321\n",
      "episode: 1127, score: 0, global_step_num: 347644, avg loss: 0.0014030253834843118, step: 323, replay memory length: 347644\n",
      "episode: 1128, score: 1.0, global_step_num: 347786, avg loss: 0.0011822786764369853, step: 142, replay memory length: 347786\n",
      "episode: 1129, score: 0, global_step_num: 348109, avg loss: 0.0015560890334388596, step: 323, replay memory length: 348109\n",
      "episode: 1130, score: 0, global_step_num: 348432, avg loss: 0.0012732638068553362, step: 323, replay memory length: 348432\n",
      "episode: 1131, score: 0, global_step_num: 348755, avg loss: 0.0012650537257382223, step: 323, replay memory length: 348755\n",
      "episode: 1132, score: 0, global_step_num: 349078, avg loss: 0.0010269601833187893, step: 323, replay memory length: 349078\n",
      "episode: 1133, score: 0, global_step_num: 349401, avg loss: 0.001328392086285111, step: 323, replay memory length: 349401\n",
      "episode: 1134, score: 0, global_step_num: 349724, avg loss: 0.001305326330762155, step: 323, replay memory length: 349724\n",
      "episode: 1135, score: 0, global_step_num: 350047, avg loss: 0.0012969222969419184, step: 323, replay memory length: 350047\n",
      "episode: 1136, score: 0, global_step_num: 350370, avg loss: 0.001316526080623961, step: 323, replay memory length: 350370\n",
      "episode: 1137, score: 0, global_step_num: 350693, avg loss: 0.0015715218451809918, step: 323, replay memory length: 350693\n",
      "episode: 1138, score: 1.0, global_step_num: 350865, avg loss: 0.0016090766824131712, step: 172, replay memory length: 350865\n",
      "episode: 1139, score: 0, global_step_num: 351188, avg loss: 0.0012464395222364837, step: 323, replay memory length: 351188\n",
      "episode: 1140, score: 0, global_step_num: 351511, avg loss: 0.0011716379092862603, step: 323, replay memory length: 351511\n",
      "episode: 1141, score: 0, global_step_num: 351834, avg loss: 0.001824147719590281, step: 323, replay memory length: 351834\n",
      "episode: 1142, score: 0, global_step_num: 352157, avg loss: 0.0008905256272780823, step: 323, replay memory length: 352157\n",
      "episode: 1143, score: 0, global_step_num: 352480, avg loss: 0.0013186842986761458, step: 323, replay memory length: 352480\n",
      "episode: 1144, score: 0, global_step_num: 352803, avg loss: 0.0015037955943220532, step: 323, replay memory length: 352803\n",
      "episode: 1145, score: 1.0, global_step_num: 353020, avg loss: 0.000987268471855236, step: 217, replay memory length: 353020\n",
      "episode: 1146, score: 0, global_step_num: 353343, avg loss: 0.0011925882696097135, step: 323, replay memory length: 353343\n",
      "episode: 1147, score: 0, global_step_num: 353666, avg loss: 0.0016106932440469856, step: 323, replay memory length: 353666\n",
      "episode: 1148, score: 0, global_step_num: 353989, avg loss: 0.0010756261337488417, step: 323, replay memory length: 353989\n",
      "episode: 1149, score: 0, global_step_num: 354312, avg loss: 0.0016773944630656297, step: 323, replay memory length: 354312\n",
      "episode: 1150, score: 0, global_step_num: 354635, avg loss: 0.0010706583003600308, step: 323, replay memory length: 354635\n",
      "episode: 1151, score: 0, global_step_num: 354958, avg loss: 0.0009667675060082495, step: 323, replay memory length: 354958\n",
      "episode: 1152, score: 0, global_step_num: 355281, avg loss: 0.0016114141134192987, step: 323, replay memory length: 355281\n",
      "episode: 1153, score: 0, global_step_num: 355604, avg loss: 0.0015981246203266078, step: 323, replay memory length: 355604\n",
      "episode: 1154, score: 0, global_step_num: 355927, avg loss: 0.0014005253157056386, step: 323, replay memory length: 355927\n",
      "episode: 1155, score: 0, global_step_num: 356250, avg loss: 0.0014099440571497736, step: 323, replay memory length: 356250\n",
      "episode: 1156, score: 0, global_step_num: 356573, avg loss: 0.0013136784233723545, step: 323, replay memory length: 356573\n",
      "episode: 1157, score: 0, global_step_num: 356896, avg loss: 0.001545599905222038, step: 323, replay memory length: 356896\n",
      "episode: 1158, score: 0, global_step_num: 357219, avg loss: 0.00126600422385275, step: 323, replay memory length: 357219\n",
      "episode: 1159, score: 0, global_step_num: 357542, avg loss: 0.0014512307124061054, step: 323, replay memory length: 357542\n",
      "episode: 1160, score: 0, global_step_num: 357865, avg loss: 0.0015681362398764708, step: 323, replay memory length: 357865\n",
      "episode: 1161, score: 0, global_step_num: 358188, avg loss: 0.0012358107177288412, step: 323, replay memory length: 358188\n",
      "episode: 1162, score: 0, global_step_num: 358511, avg loss: 0.0008622798197292054, step: 323, replay memory length: 358511\n",
      "episode: 1163, score: 0, global_step_num: 358834, avg loss: 0.0012562953201163917, step: 323, replay memory length: 358834\n",
      "episode: 1164, score: 0, global_step_num: 359157, avg loss: 0.0009793219615948211, step: 323, replay memory length: 359157\n",
      "episode: 1165, score: 0, global_step_num: 359480, avg loss: 0.001435987753205889, step: 323, replay memory length: 359480\n",
      "episode: 1166, score: 0, global_step_num: 359803, avg loss: 0.0011097378455224175, step: 323, replay memory length: 359803\n",
      "episode: 1167, score: 0, global_step_num: 360126, avg loss: 0.0010609802531785374, step: 323, replay memory length: 360126\n",
      "episode: 1168, score: 0, global_step_num: 360449, avg loss: 0.0011305489615115333, step: 323, replay memory length: 360449\n",
      "episode: 1169, score: 0, global_step_num: 360772, avg loss: 0.0016430162369672676, step: 323, replay memory length: 360772\n",
      "episode: 1170, score: 0, global_step_num: 361095, avg loss: 0.001041269878370306, step: 323, replay memory length: 361095\n",
      "episode: 1171, score: 0, global_step_num: 361418, avg loss: 0.0013270007113431843, step: 323, replay memory length: 361418\n",
      "episode: 1172, score: 0, global_step_num: 361741, avg loss: 0.001436193657500046, step: 323, replay memory length: 361741\n",
      "episode: 1173, score: 0, global_step_num: 362064, avg loss: 0.0014180462518132838, step: 323, replay memory length: 362064\n",
      "episode: 1174, score: 0, global_step_num: 362387, avg loss: 0.0012783594880945847, step: 323, replay memory length: 362387\n",
      "episode: 1175, score: 0, global_step_num: 362710, avg loss: 0.0014290368164815719, step: 323, replay memory length: 362710\n",
      "episode: 1176, score: 1.0, global_step_num: 362963, avg loss: 0.0019137111625054301, step: 253, replay memory length: 362963\n",
      "episode: 1177, score: 0, global_step_num: 363286, avg loss: 0.0014154410106388996, step: 323, replay memory length: 363286\n",
      "episode: 1178, score: 0, global_step_num: 363609, avg loss: 0.0012543562274787, step: 323, replay memory length: 363609\n",
      "episode: 1179, score: 0, global_step_num: 363932, avg loss: 0.0013617729885414243, step: 323, replay memory length: 363932\n",
      "episode: 1180, score: 0, global_step_num: 364255, avg loss: 0.0015327134531394602, step: 323, replay memory length: 364255\n",
      "episode: 1181, score: 0, global_step_num: 364578, avg loss: 0.0010913995867383444, step: 323, replay memory length: 364578\n",
      "episode: 1182, score: 0, global_step_num: 364901, avg loss: 0.0015487355768223673, step: 323, replay memory length: 364901\n",
      "episode: 1183, score: 0, global_step_num: 365224, avg loss: 0.0009090786981501575, step: 323, replay memory length: 365224\n",
      "episode: 1184, score: 1.0, global_step_num: 365472, avg loss: 0.0010000819407896561, step: 248, replay memory length: 365472\n",
      "episode: 1185, score: 0, global_step_num: 365795, avg loss: 0.0018730942921355007, step: 323, replay memory length: 365795\n",
      "episode: 1186, score: 0, global_step_num: 366118, avg loss: 0.0012274502264038969, step: 323, replay memory length: 366118\n",
      "episode: 1187, score: 0, global_step_num: 366441, avg loss: 0.0015207448390955908, step: 323, replay memory length: 366441\n",
      "episode: 1188, score: 0, global_step_num: 366764, avg loss: 0.001153252654731538, step: 323, replay memory length: 366764\n",
      "episode: 1189, score: 0, global_step_num: 367087, avg loss: 0.0012994277787440392, step: 323, replay memory length: 367087\n",
      "episode: 1190, score: 0, global_step_num: 367410, avg loss: 0.001313869363840288, step: 323, replay memory length: 367410\n",
      "episode: 1191, score: 0, global_step_num: 367733, avg loss: 0.0013669440322644805, step: 323, replay memory length: 367733\n",
      "episode: 1192, score: 0, global_step_num: 368056, avg loss: 0.0014157512326519366, step: 323, replay memory length: 368056\n",
      "episode: 1193, score: 0, global_step_num: 368379, avg loss: 0.0014572219509715553, step: 323, replay memory length: 368379\n",
      "episode: 1194, score: 0, global_step_num: 368702, avg loss: 0.001299331603696027, step: 323, replay memory length: 368702\n",
      "episode: 1195, score: 0, global_step_num: 369025, avg loss: 0.0012439019975450274, step: 323, replay memory length: 369025\n",
      "episode: 1196, score: 0, global_step_num: 369348, avg loss: 0.0013944676247901334, step: 323, replay memory length: 369348\n",
      "episode: 1197, score: 0, global_step_num: 369671, avg loss: 0.0015093931617283327, step: 323, replay memory length: 369671\n",
      "episode: 1198, score: 0, global_step_num: 369994, avg loss: 0.0013550636836874503, step: 323, replay memory length: 369994\n",
      "episode: 1199, score: 0, global_step_num: 370317, avg loss: 0.0011590978043730237, step: 323, replay memory length: 370317\n",
      "episode: 1200, score: 0, global_step_num: 370640, avg loss: 0.0014181607871152338, step: 323, replay memory length: 370640\n",
      "episode: 1201, score: 0, global_step_num: 370963, avg loss: 0.0016634671218759619, step: 323, replay memory length: 370963\n",
      "episode: 1202, score: 0, global_step_num: 371286, avg loss: 0.0015286299255306461, step: 323, replay memory length: 371286\n",
      "episode: 1203, score: 0, global_step_num: 371609, avg loss: 0.0014188508738016729, step: 323, replay memory length: 371609\n",
      "episode: 1204, score: 0, global_step_num: 371932, avg loss: 0.001024468502849572, step: 323, replay memory length: 371932\n",
      "episode: 1205, score: 0, global_step_num: 372255, avg loss: 0.0011954592595607252, step: 323, replay memory length: 372255\n",
      "episode: 1206, score: 0, global_step_num: 372578, avg loss: 0.0012258942804075543, step: 323, replay memory length: 372578\n",
      "episode: 1207, score: 0, global_step_num: 372901, avg loss: 0.001305601109913084, step: 323, replay memory length: 372901\n",
      "episode: 1208, score: 0, global_step_num: 373224, avg loss: 0.0017014735344251315, step: 323, replay memory length: 373224\n",
      "episode: 1209, score: 0, global_step_num: 373547, avg loss: 0.0011118954882065725, step: 323, replay memory length: 373547\n",
      "episode: 1210, score: 0, global_step_num: 373870, avg loss: 0.001377633607077963, step: 323, replay memory length: 373870\n",
      "episode: 1211, score: 0, global_step_num: 374193, avg loss: 0.0014879724658174202, step: 323, replay memory length: 374193\n",
      "episode: 1212, score: 0, global_step_num: 374516, avg loss: 0.0008905679256916219, step: 323, replay memory length: 374516\n",
      "episode: 1213, score: 0, global_step_num: 374839, avg loss: 0.0015311832716159487, step: 323, replay memory length: 374839\n",
      "episode: 1214, score: 1.0, global_step_num: 375140, avg loss: 0.0015520541362842705, step: 301, replay memory length: 375140\n",
      "episode: 1215, score: 1.0, global_step_num: 375437, avg loss: 0.0011715917529901997, step: 297, replay memory length: 375437\n",
      "episode: 1216, score: 0, global_step_num: 375760, avg loss: 0.0012440071586921257, step: 323, replay memory length: 375760\n",
      "episode: 1217, score: 0, global_step_num: 376083, avg loss: 0.0013200975616259726, step: 323, replay memory length: 376083\n",
      "episode: 1218, score: 0, global_step_num: 376406, avg loss: 0.0012250561581321486, step: 323, replay memory length: 376406\n",
      "episode: 1219, score: 0, global_step_num: 376729, avg loss: 0.0011337589729026672, step: 323, replay memory length: 376729\n",
      "episode: 1220, score: 0, global_step_num: 377052, avg loss: 0.0012378242812991526, step: 323, replay memory length: 377052\n",
      "episode: 1221, score: 0, global_step_num: 377375, avg loss: 0.0012146413572759018, step: 323, replay memory length: 377375\n",
      "episode: 1222, score: 0, global_step_num: 377698, avg loss: 0.0016650805535605555, step: 323, replay memory length: 377698\n",
      "episode: 1223, score: 0, global_step_num: 378021, avg loss: 0.0012717720576495175, step: 323, replay memory length: 378021\n",
      "episode: 1224, score: 0, global_step_num: 378344, avg loss: 0.0012167540612988848, step: 323, replay memory length: 378344\n",
      "episode: 1225, score: 0, global_step_num: 378667, avg loss: 0.001330164407492376, step: 323, replay memory length: 378667\n",
      "episode: 1226, score: 0, global_step_num: 378990, avg loss: 0.001466546663144441, step: 323, replay memory length: 378990\n",
      "episode: 1227, score: 0, global_step_num: 379313, avg loss: 0.0013396231930618407, step: 323, replay memory length: 379313\n",
      "episode: 1228, score: 0, global_step_num: 379636, avg loss: 0.0013467987360297226, step: 323, replay memory length: 379636\n",
      "episode: 1229, score: 0, global_step_num: 379959, avg loss: 0.001340045732454327, step: 323, replay memory length: 379959\n",
      "episode: 1230, score: 0, global_step_num: 380282, avg loss: 0.001503860483239453, step: 323, replay memory length: 380282\n",
      "episode: 1231, score: 0, global_step_num: 380605, avg loss: 0.0015662206625072787, step: 323, replay memory length: 380605\n",
      "episode: 1232, score: 0, global_step_num: 380928, avg loss: 0.0016144551120513917, step: 323, replay memory length: 380928\n",
      "episode: 1233, score: 0, global_step_num: 381251, avg loss: 0.0012529345450407628, step: 323, replay memory length: 381251\n",
      "episode: 1234, score: 0, global_step_num: 381574, avg loss: 0.001466273018184089, step: 323, replay memory length: 381574\n",
      "episode: 1235, score: 0, global_step_num: 381897, avg loss: 0.0009196320195744317, step: 323, replay memory length: 381897\n",
      "episode: 1236, score: 1.0, global_step_num: 382208, avg loss: 0.0013999754361297182, step: 311, replay memory length: 382208\n",
      "episode: 1237, score: 0, global_step_num: 382531, avg loss: 0.001497611880099626, step: 323, replay memory length: 382531\n",
      "episode: 1238, score: 0, global_step_num: 382854, avg loss: 0.001112416644520675, step: 323, replay memory length: 382854\n",
      "episode: 1239, score: 1.0, global_step_num: 383154, avg loss: 0.0014640894809948197, step: 300, replay memory length: 383154\n",
      "episode: 1240, score: 0, global_step_num: 383477, avg loss: 0.0010633062364727673, step: 323, replay memory length: 383477\n",
      "episode: 1241, score: 1.0, global_step_num: 383595, avg loss: 0.0018396090645182994, step: 118, replay memory length: 383595\n",
      "episode: 1242, score: 0, global_step_num: 383918, avg loss: 0.001181553953558008, step: 323, replay memory length: 383918\n",
      "episode: 1243, score: 0, global_step_num: 384241, avg loss: 0.0013345723089855357, step: 323, replay memory length: 384241\n",
      "episode: 1244, score: 0, global_step_num: 384564, avg loss: 0.001665812900494138, step: 323, replay memory length: 384564\n",
      "episode: 1245, score: 0, global_step_num: 384887, avg loss: 0.0010999014880833124, step: 323, replay memory length: 384887\n",
      "episode: 1246, score: 0, global_step_num: 385210, avg loss: 0.0012738347586731067, step: 323, replay memory length: 385210\n",
      "episode: 1247, score: 0, global_step_num: 385533, avg loss: 0.0014244082951122168, step: 323, replay memory length: 385533\n",
      "episode: 1248, score: 0, global_step_num: 385856, avg loss: 0.0014421066339464486, step: 323, replay memory length: 385856\n",
      "episode: 1249, score: 0, global_step_num: 386179, avg loss: 0.0013056078711684992, step: 323, replay memory length: 386179\n",
      "episode: 1250, score: 0, global_step_num: 386502, avg loss: 0.0015281041194093942, step: 323, replay memory length: 386502\n",
      "episode: 1251, score: 1.0, global_step_num: 386820, avg loss: 0.0011068949486357927, step: 318, replay memory length: 386820\n",
      "episode: 1252, score: 0, global_step_num: 387143, avg loss: 0.0011726049745845132, step: 323, replay memory length: 387143\n",
      "episode: 1253, score: 0, global_step_num: 387466, avg loss: 0.001091857870010343, step: 323, replay memory length: 387466\n",
      "episode: 1254, score: 0, global_step_num: 387789, avg loss: 0.0008911831394600463, step: 323, replay memory length: 387789\n",
      "episode: 1255, score: 1.0, global_step_num: 387893, avg loss: 0.001042777583926671, step: 104, replay memory length: 387893\n",
      "episode: 1256, score: 0, global_step_num: 388216, avg loss: 0.0018590839089337359, step: 323, replay memory length: 388216\n",
      "episode: 1257, score: 0, global_step_num: 388539, avg loss: 0.0016887840800198588, step: 323, replay memory length: 388539\n",
      "episode: 1258, score: 0, global_step_num: 388862, avg loss: 0.001379238188749783, step: 323, replay memory length: 388862\n",
      "episode: 1259, score: 0, global_step_num: 389185, avg loss: 0.0011129529361570678, step: 323, replay memory length: 389185\n",
      "episode: 1260, score: 0, global_step_num: 389508, avg loss: 0.0012320142898127361, step: 323, replay memory length: 389508\n",
      "episode: 1261, score: 0, global_step_num: 389831, avg loss: 0.0014082613555610778, step: 323, replay memory length: 389831\n",
      "episode: 1262, score: 0, global_step_num: 390154, avg loss: 0.0011599475136686531, step: 323, replay memory length: 390154\n",
      "episode: 1263, score: 0, global_step_num: 390477, avg loss: 0.0008361490731898046, step: 323, replay memory length: 390477\n",
      "episode: 1264, score: 0, global_step_num: 390800, avg loss: 0.0012249993566781619, step: 323, replay memory length: 390800\n",
      "episode: 1265, score: 1.0, global_step_num: 390936, avg loss: 0.0008991327875144313, step: 136, replay memory length: 390936\n",
      "episode: 1266, score: 0, global_step_num: 391259, avg loss: 0.0017361129040258303, step: 323, replay memory length: 391259\n",
      "episode: 1267, score: 0, global_step_num: 391582, avg loss: 0.0012430175454757643, step: 323, replay memory length: 391582\n",
      "episode: 1268, score: 0, global_step_num: 391905, avg loss: 0.0014902654578502342, step: 323, replay memory length: 391905\n",
      "episode: 1269, score: 0, global_step_num: 392228, avg loss: 0.0013339761029848166, step: 323, replay memory length: 392228\n",
      "episode: 1270, score: 0, global_step_num: 392551, avg loss: 0.001496504447639511, step: 323, replay memory length: 392551\n",
      "episode: 1271, score: 0, global_step_num: 392874, avg loss: 0.0010885078837269168, step: 323, replay memory length: 392874\n",
      "episode: 1272, score: 0, global_step_num: 393197, avg loss: 0.0008957417119241491, step: 323, replay memory length: 393197\n",
      "episode: 1273, score: 0, global_step_num: 393520, avg loss: 0.0014068783208488812, step: 323, replay memory length: 393520\n",
      "episode: 1274, score: 0, global_step_num: 393843, avg loss: 0.0014718719794487225, step: 323, replay memory length: 393843\n",
      "episode: 1275, score: 0, global_step_num: 394166, avg loss: 0.0011070989190309368, step: 323, replay memory length: 394166\n",
      "episode: 1276, score: 0, global_step_num: 394489, avg loss: 0.0015686338206842407, step: 323, replay memory length: 394489\n",
      "episode: 1277, score: 0, global_step_num: 394812, avg loss: 0.0013546431110547303, step: 323, replay memory length: 394812\n",
      "episode: 1278, score: 0, global_step_num: 395135, avg loss: 0.001545555790426501, step: 323, replay memory length: 395135\n",
      "episode: 1279, score: 0, global_step_num: 395458, avg loss: 0.0013057493514617717, step: 323, replay memory length: 395458\n",
      "episode: 1280, score: 0, global_step_num: 395781, avg loss: 0.0011996216149886597, step: 323, replay memory length: 395781\n",
      "episode: 1281, score: 0, global_step_num: 396104, avg loss: 0.0012224024316290823, step: 323, replay memory length: 396104\n",
      "episode: 1282, score: 0, global_step_num: 396427, avg loss: 0.001368603048578154, step: 323, replay memory length: 396427\n",
      "episode: 1283, score: 0, global_step_num: 396750, avg loss: 0.0012993714767617348, step: 323, replay memory length: 396750\n",
      "episode: 1284, score: 0, global_step_num: 397073, avg loss: 0.001254647239806353, step: 323, replay memory length: 397073\n",
      "episode: 1285, score: 0, global_step_num: 397396, avg loss: 0.0014321761720056773, step: 323, replay memory length: 397396\n",
      "episode: 1286, score: 0, global_step_num: 397719, avg loss: 0.0013505218295648107, step: 323, replay memory length: 397719\n",
      "episode: 1287, score: 0, global_step_num: 398042, avg loss: 0.001287510947752457, step: 323, replay memory length: 398042\n",
      "episode: 1288, score: 0, global_step_num: 398365, avg loss: 0.0012440247944941127, step: 323, replay memory length: 398365\n",
      "episode: 1289, score: 0, global_step_num: 398688, avg loss: 0.001443255906317919, step: 323, replay memory length: 398688\n",
      "episode: 1290, score: 0, global_step_num: 399011, avg loss: 0.0015059242424798384, step: 323, replay memory length: 399011\n",
      "episode: 1291, score: 0, global_step_num: 399334, avg loss: 0.0013676937149836531, step: 323, replay memory length: 399334\n",
      "episode: 1292, score: 0, global_step_num: 399657, avg loss: 0.0014555256090079919, step: 323, replay memory length: 399657\n",
      "episode: 1293, score: 0, global_step_num: 399980, avg loss: 0.0012723631188118788, step: 323, replay memory length: 399980\n",
      "episode: 1294, score: 0, global_step_num: 400303, avg loss: 0.0012591148914648483, step: 323, replay memory length: 400000\n",
      "episode: 1295, score: 0, global_step_num: 400626, avg loss: 0.0009885722424065539, step: 323, replay memory length: 400000\n",
      "episode: 1296, score: 0, global_step_num: 400949, avg loss: 0.0013791466411981425, step: 323, replay memory length: 400000\n",
      "episode: 1297, score: 0, global_step_num: 401272, avg loss: 0.0018368177122294932, step: 323, replay memory length: 400000\n",
      "episode: 1298, score: 0, global_step_num: 401595, avg loss: 0.0010801022619289311, step: 323, replay memory length: 400000\n",
      "episode: 1299, score: 0, global_step_num: 401918, avg loss: 0.00137464342561408, step: 323, replay memory length: 400000\n",
      "episode: 1300, score: 0, global_step_num: 402241, avg loss: 0.0013526922435411065, step: 323, replay memory length: 400000\n",
      "episode: 1301, score: 0, global_step_num: 402564, avg loss: 0.0010248798465213708, step: 323, replay memory length: 400000\n",
      "episode: 1302, score: 0, global_step_num: 402887, avg loss: 0.0009684160065879058, step: 323, replay memory length: 400000\n",
      "episode: 1303, score: 0, global_step_num: 403210, avg loss: 0.0016797979871383856, step: 323, replay memory length: 400000\n",
      "episode: 1304, score: 0, global_step_num: 403533, avg loss: 0.0009816959198504168, step: 323, replay memory length: 400000\n",
      "episode: 1305, score: 0, global_step_num: 403856, avg loss: 0.0014676796778067649, step: 323, replay memory length: 400000\n",
      "episode: 1306, score: 0, global_step_num: 404179, avg loss: 0.001515520346224506, step: 323, replay memory length: 400000\n",
      "episode: 1307, score: 0, global_step_num: 404502, avg loss: 0.000888720033250397, step: 323, replay memory length: 400000\n",
      "episode: 1308, score: 1.0, global_step_num: 404547, avg loss: 0.0009756066572663257, step: 45, replay memory length: 400000\n",
      "episode: 1309, score: 0, global_step_num: 404870, avg loss: 0.0010737835572675436, step: 323, replay memory length: 400000\n",
      "episode: 1310, score: 0, global_step_num: 405193, avg loss: 0.001246045480596195, step: 323, replay memory length: 400000\n",
      "episode: 1311, score: 0, global_step_num: 405516, avg loss: 0.0013579794905357512, step: 323, replay memory length: 400000\n",
      "episode: 1312, score: 0, global_step_num: 405839, avg loss: 0.0008491542662862007, step: 323, replay memory length: 400000\n",
      "episode: 1313, score: 0, global_step_num: 406162, avg loss: 0.0013511183014857308, step: 323, replay memory length: 400000\n",
      "episode: 1314, score: 0, global_step_num: 406485, avg loss: 0.0014110933364044013, step: 323, replay memory length: 400000\n",
      "episode: 1315, score: 0, global_step_num: 406808, avg loss: 0.0011769235646820716, step: 323, replay memory length: 400000\n",
      "episode: 1316, score: 0, global_step_num: 407131, avg loss: 0.001244494493219874, step: 323, replay memory length: 400000\n",
      "episode: 1317, score: 0, global_step_num: 407454, avg loss: 0.0018854248337349091, step: 323, replay memory length: 400000\n",
      "episode: 1318, score: 0, global_step_num: 407777, avg loss: 0.0012486153815659262, step: 323, replay memory length: 400000\n",
      "episode: 1319, score: 0, global_step_num: 408100, avg loss: 0.0012557658259913082, step: 323, replay memory length: 400000\n",
      "episode: 1320, score: 0, global_step_num: 408423, avg loss: 0.0014544966045722738, step: 323, replay memory length: 400000\n",
      "episode: 1321, score: 0, global_step_num: 408746, avg loss: 0.0013230948876853206, step: 323, replay memory length: 400000\n",
      "episode: 1322, score: 0, global_step_num: 409069, avg loss: 0.0008467737143742266, step: 323, replay memory length: 400000\n",
      "episode: 1323, score: 0, global_step_num: 409392, avg loss: 0.0011815581403323944, step: 323, replay memory length: 400000\n",
      "episode: 1324, score: 1.0, global_step_num: 409608, avg loss: 0.0015312278276016717, step: 216, replay memory length: 400000\n",
      "episode: 1325, score: 0, global_step_num: 409931, avg loss: 0.0011918326254329401, step: 323, replay memory length: 400000\n",
      "episode: 1326, score: 0, global_step_num: 410254, avg loss: 0.00112405803875583, step: 323, replay memory length: 400000\n",
      "episode: 1327, score: 0, global_step_num: 410577, avg loss: 0.0013585042564879049, step: 323, replay memory length: 400000\n",
      "episode: 1328, score: 0, global_step_num: 410900, avg loss: 0.0010306092375891244, step: 323, replay memory length: 400000\n",
      "episode: 1329, score: 0, global_step_num: 411223, avg loss: 0.00142522165059669, step: 323, replay memory length: 400000\n",
      "episode: 1330, score: 0, global_step_num: 411546, avg loss: 0.0010944312127290636, step: 323, replay memory length: 400000\n",
      "episode: 1331, score: 0, global_step_num: 411869, avg loss: 0.0012595526516172195, step: 323, replay memory length: 400000\n",
      "episode: 1332, score: 0, global_step_num: 412192, avg loss: 0.001656579149697926, step: 323, replay memory length: 400000\n",
      "episode: 1333, score: 0, global_step_num: 412515, avg loss: 0.0007959428200730784, step: 323, replay memory length: 400000\n",
      "episode: 1334, score: 0, global_step_num: 412838, avg loss: 0.0016607726355850505, step: 323, replay memory length: 400000\n",
      "episode: 1335, score: 0, global_step_num: 413161, avg loss: 0.0014455855494899272, step: 323, replay memory length: 400000\n",
      "episode: 1336, score: 0, global_step_num: 413484, avg loss: 0.0015964344518370943, step: 323, replay memory length: 400000\n",
      "episode: 1337, score: 0, global_step_num: 413807, avg loss: 0.0012737766757650191, step: 323, replay memory length: 400000\n",
      "episode: 1338, score: 0, global_step_num: 414130, avg loss: 0.0010513955467160413, step: 323, replay memory length: 400000\n",
      "episode: 1339, score: 0, global_step_num: 414453, avg loss: 0.0013671649522422498, step: 323, replay memory length: 400000\n",
      "episode: 1340, score: 0, global_step_num: 414776, avg loss: 0.0013372165703195175, step: 323, replay memory length: 400000\n",
      "episode: 1341, score: 0, global_step_num: 415099, avg loss: 0.0010457204864190882, step: 323, replay memory length: 400000\n",
      "episode: 1342, score: 0, global_step_num: 415422, avg loss: 0.0012995457279075624, step: 323, replay memory length: 400000\n",
      "episode: 1343, score: 0, global_step_num: 415745, avg loss: 0.0011821260516122329, step: 323, replay memory length: 400000\n",
      "episode: 1344, score: 0, global_step_num: 416068, avg loss: 0.0011301121657881887, step: 323, replay memory length: 400000\n",
      "episode: 1345, score: 0, global_step_num: 416391, avg loss: 0.0011677227549575285, step: 323, replay memory length: 400000\n",
      "episode: 1346, score: 0, global_step_num: 416714, avg loss: 0.0012329406195120427, step: 323, replay memory length: 400000\n",
      "episode: 1347, score: 0, global_step_num: 417037, avg loss: 0.001539135756972453, step: 323, replay memory length: 400000\n",
      "episode: 1348, score: 0, global_step_num: 417360, avg loss: 0.0014390868288779986, step: 323, replay memory length: 400000\n",
      "episode: 1349, score: 0, global_step_num: 417683, avg loss: 0.00101559065360674, step: 323, replay memory length: 400000\n",
      "episode: 1350, score: 0, global_step_num: 418006, avg loss: 0.0012751049311706597, step: 323, replay memory length: 400000\n",
      "episode: 1351, score: 0, global_step_num: 418329, avg loss: 0.0013069652344114414, step: 323, replay memory length: 400000\n",
      "episode: 1352, score: 0, global_step_num: 418652, avg loss: 0.001007212597327475, step: 323, replay memory length: 400000\n",
      "episode: 1353, score: 0, global_step_num: 418975, avg loss: 0.001337825939765093, step: 323, replay memory length: 400000\n",
      "episode: 1354, score: 0, global_step_num: 419298, avg loss: 0.0010721214123948716, step: 323, replay memory length: 400000\n",
      "episode: 1355, score: 0, global_step_num: 419621, avg loss: 0.0014067866013154529, step: 323, replay memory length: 400000\n",
      "episode: 1356, score: 0, global_step_num: 419944, avg loss: 0.0011699012060399517, step: 323, replay memory length: 400000\n",
      "episode: 1357, score: 0, global_step_num: 420267, avg loss: 0.0013148430213180463, step: 323, replay memory length: 400000\n",
      "episode: 1358, score: 0, global_step_num: 420590, avg loss: 0.0013512066904946133, step: 323, replay memory length: 400000\n",
      "episode: 1359, score: 0, global_step_num: 420913, avg loss: 0.0012158607846883313, step: 323, replay memory length: 400000\n",
      "episode: 1360, score: 0, global_step_num: 421236, avg loss: 0.0013390301341380515, step: 323, replay memory length: 400000\n",
      "episode: 1361, score: 0, global_step_num: 421559, avg loss: 0.0010792118821955677, step: 323, replay memory length: 400000\n",
      "episode: 1362, score: 0, global_step_num: 421882, avg loss: 0.0012468016289540315, step: 323, replay memory length: 400000\n",
      "episode: 1363, score: 0, global_step_num: 422205, avg loss: 0.0014644163151424662, step: 323, replay memory length: 400000\n",
      "episode: 1364, score: 0, global_step_num: 422528, avg loss: 0.0009676608038947843, step: 323, replay memory length: 400000\n",
      "episode: 1365, score: 0, global_step_num: 422851, avg loss: 0.0009502123362968187, step: 323, replay memory length: 400000\n",
      "episode: 1366, score: 0, global_step_num: 423174, avg loss: 0.0014031955069236325, step: 323, replay memory length: 400000\n",
      "episode: 1367, score: 0, global_step_num: 423497, avg loss: 0.0012795212566613905, step: 323, replay memory length: 400000\n",
      "episode: 1368, score: 0, global_step_num: 423820, avg loss: 0.0012514731987758067, step: 323, replay memory length: 400000\n",
      "episode: 1369, score: 1.0, global_step_num: 423871, avg loss: 0.0005542926428907045, step: 51, replay memory length: 400000\n",
      "episode: 1370, score: 0, global_step_num: 424194, avg loss: 0.0009274437342983586, step: 323, replay memory length: 400000\n",
      "episode: 1371, score: 0, global_step_num: 424517, avg loss: 0.00122637340651191, step: 323, replay memory length: 400000\n",
      "episode: 1372, score: 0, global_step_num: 424840, avg loss: 0.001736828010850976, step: 323, replay memory length: 400000\n",
      "episode: 1373, score: 0, global_step_num: 425163, avg loss: 0.0014182395624581993, step: 323, replay memory length: 400000\n",
      "episode: 1374, score: 0, global_step_num: 425486, avg loss: 0.0014920163049949903, step: 323, replay memory length: 400000\n",
      "episode: 1375, score: 0, global_step_num: 425809, avg loss: 0.0011067085736404714, step: 323, replay memory length: 400000\n",
      "episode: 1376, score: 0, global_step_num: 426132, avg loss: 0.0008897289801081046, step: 323, replay memory length: 400000\n",
      "episode: 1377, score: 0, global_step_num: 426455, avg loss: 0.0008356298493970758, step: 323, replay memory length: 400000\n",
      "episode: 1378, score: 0, global_step_num: 426778, avg loss: 0.001359768767333071, step: 323, replay memory length: 400000\n",
      "episode: 1379, score: 0, global_step_num: 427101, avg loss: 0.001121644626822807, step: 323, replay memory length: 400000\n",
      "episode: 1380, score: 0, global_step_num: 427424, avg loss: 0.0014494508851151326, step: 323, replay memory length: 400000\n",
      "episode: 1381, score: 0, global_step_num: 427747, avg loss: 0.0010918393037727498, step: 323, replay memory length: 400000\n",
      "episode: 1382, score: 1.0, global_step_num: 428070, avg loss: 0.00130893974505782, step: 323, replay memory length: 400000\n",
      "episode: 1383, score: 0, global_step_num: 428393, avg loss: 0.0015067439138826892, step: 323, replay memory length: 400000\n",
      "episode: 1384, score: 0, global_step_num: 428716, avg loss: 0.0015743589894425519, step: 323, replay memory length: 400000\n",
      "episode: 1385, score: 1.0, global_step_num: 428816, avg loss: 0.0008128783117990679, step: 100, replay memory length: 400000\n",
      "episode: 1386, score: 0, global_step_num: 429139, avg loss: 0.0014840967142315965, step: 323, replay memory length: 400000\n",
      "episode: 1387, score: 0, global_step_num: 429462, avg loss: 0.000913284067176873, step: 323, replay memory length: 400000\n",
      "episode: 1388, score: 0, global_step_num: 429785, avg loss: 0.0013099098991197504, step: 323, replay memory length: 400000\n",
      "episode: 1389, score: 0, global_step_num: 430108, avg loss: 0.0009410384099460358, step: 323, replay memory length: 400000\n",
      "episode: 1390, score: 0, global_step_num: 430431, avg loss: 0.0015398332368329157, step: 323, replay memory length: 400000\n",
      "episode: 1391, score: 0, global_step_num: 430754, avg loss: 0.0009710301381025655, step: 323, replay memory length: 400000\n",
      "episode: 1392, score: 0, global_step_num: 431077, avg loss: 0.0010624112299765414, step: 323, replay memory length: 400000\n",
      "episode: 1393, score: 0, global_step_num: 431400, avg loss: 0.0012293602773411647, step: 323, replay memory length: 400000\n",
      "episode: 1394, score: 0, global_step_num: 431723, avg loss: 0.0015717553289023806, step: 323, replay memory length: 400000\n",
      "episode: 1395, score: 0, global_step_num: 432046, avg loss: 0.0011972690847858408, step: 323, replay memory length: 400000\n",
      "episode: 1396, score: 0, global_step_num: 432369, avg loss: 0.0013659770214373577, step: 323, replay memory length: 400000\n",
      "episode: 1397, score: 0, global_step_num: 432692, avg loss: 0.0011476468912504387, step: 323, replay memory length: 400000\n",
      "episode: 1398, score: 0, global_step_num: 433015, avg loss: 0.0012521803736357915, step: 323, replay memory length: 400000\n",
      "episode: 1399, score: 0, global_step_num: 433338, avg loss: 0.000968854434198165, step: 323, replay memory length: 400000\n",
      "episode: 1400, score: 1.0, global_step_num: 433606, avg loss: 0.0013205913711476908, step: 268, replay memory length: 400000\n",
      "episode: 1401, score: 0, global_step_num: 433929, avg loss: 0.0009506510775180272, step: 323, replay memory length: 400000\n",
      "episode: 1402, score: 0, global_step_num: 434252, avg loss: 0.0013220378874638618, step: 323, replay memory length: 400000\n",
      "episode: 1403, score: 0, global_step_num: 434575, avg loss: 0.001320038866799713, step: 323, replay memory length: 400000\n",
      "episode: 1404, score: 0, global_step_num: 434898, avg loss: 0.0011615671556759108, step: 323, replay memory length: 400000\n",
      "episode: 1405, score: 0, global_step_num: 435221, avg loss: 0.0009707918381379045, step: 323, replay memory length: 400000\n",
      "episode: 1406, score: 0, global_step_num: 435544, avg loss: 0.0011481661231033178, step: 323, replay memory length: 400000\n",
      "episode: 1407, score: 0, global_step_num: 435867, avg loss: 0.0009713902630072241, step: 323, replay memory length: 400000\n",
      "episode: 1408, score: 0, global_step_num: 436190, avg loss: 0.0013100451352560294, step: 323, replay memory length: 400000\n",
      "episode: 1409, score: 0, global_step_num: 436513, avg loss: 0.001260363127624572, step: 323, replay memory length: 400000\n",
      "episode: 1410, score: 0, global_step_num: 436836, avg loss: 0.001161112947699027, step: 323, replay memory length: 400000\n",
      "episode: 1411, score: 0, global_step_num: 437159, avg loss: 0.0015246999476279395, step: 323, replay memory length: 400000\n",
      "episode: 1412, score: 0, global_step_num: 437482, avg loss: 0.0012411501745991024, step: 323, replay memory length: 400000\n",
      "episode: 1413, score: 0, global_step_num: 437805, avg loss: 0.0015281574828847114, step: 323, replay memory length: 400000\n",
      "episode: 1414, score: 0, global_step_num: 438128, avg loss: 0.0010829698274134642, step: 323, replay memory length: 400000\n",
      "episode: 1415, score: 0, global_step_num: 438451, avg loss: 0.0013713363730551045, step: 323, replay memory length: 400000\n",
      "episode: 1416, score: 0, global_step_num: 438774, avg loss: 0.001313170658828515, step: 323, replay memory length: 400000\n",
      "episode: 1417, score: 0, global_step_num: 439097, avg loss: 0.0013462673339382145, step: 323, replay memory length: 400000\n",
      "episode: 1418, score: 0, global_step_num: 439420, avg loss: 0.001457785894610323, step: 323, replay memory length: 400000\n",
      "episode: 1419, score: 0, global_step_num: 439743, avg loss: 0.0015332228571502753, step: 323, replay memory length: 400000\n",
      "episode: 1420, score: 0, global_step_num: 440066, avg loss: 0.001197771687817722, step: 323, replay memory length: 400000\n",
      "episode: 1421, score: 0, global_step_num: 440389, avg loss: 0.0008624235778336559, step: 323, replay memory length: 400000\n",
      "episode: 1422, score: 0, global_step_num: 440712, avg loss: 0.0016180946152532611, step: 323, replay memory length: 400000\n",
      "episode: 1423, score: 1.0, global_step_num: 441013, avg loss: 0.0010770784991493134, step: 301, replay memory length: 400000\n",
      "episode: 1424, score: 0, global_step_num: 441336, avg loss: 0.0014355120121352218, step: 323, replay memory length: 400000\n",
      "episode: 1425, score: 0, global_step_num: 441659, avg loss: 0.0009893825176056422, step: 323, replay memory length: 400000\n",
      "episode: 1426, score: 0, global_step_num: 441982, avg loss: 0.0013735492053940567, step: 323, replay memory length: 400000\n",
      "episode: 1427, score: 1.0, global_step_num: 442021, avg loss: 0.0010187020763437315, step: 39, replay memory length: 400000\n",
      "episode: 1428, score: 0, global_step_num: 442344, avg loss: 0.000984696319765332, step: 323, replay memory length: 400000\n",
      "episode: 1429, score: 0, global_step_num: 442667, avg loss: 0.0011175855291624404, step: 323, replay memory length: 400000\n",
      "episode: 1430, score: 0, global_step_num: 442990, avg loss: 0.001344278261781861, step: 323, replay memory length: 400000\n",
      "episode: 1431, score: 0, global_step_num: 443313, avg loss: 0.0013242393931247446, step: 323, replay memory length: 400000\n",
      "episode: 1432, score: 0, global_step_num: 443636, avg loss: 0.0010863983818264118, step: 323, replay memory length: 400000\n",
      "episode: 1433, score: 0, global_step_num: 443959, avg loss: 0.0012038724144949585, step: 323, replay memory length: 400000\n",
      "episode: 1434, score: 0, global_step_num: 444282, avg loss: 0.0011982549514443696, step: 323, replay memory length: 400000\n",
      "episode: 1435, score: 0, global_step_num: 444605, avg loss: 0.0007215917888035744, step: 323, replay memory length: 400000\n",
      "episode: 1436, score: 0, global_step_num: 444928, avg loss: 0.001308650507468289, step: 323, replay memory length: 400000\n",
      "episode: 1437, score: 0, global_step_num: 445251, avg loss: 0.0015430747816302214, step: 323, replay memory length: 400000\n",
      "episode: 1438, score: 0, global_step_num: 445574, avg loss: 0.0010268623107749422, step: 323, replay memory length: 400000\n",
      "episode: 1439, score: 0, global_step_num: 445897, avg loss: 0.001377778295042194, step: 323, replay memory length: 400000\n",
      "episode: 1440, score: 0, global_step_num: 446220, avg loss: 0.0009743054885096089, step: 323, replay memory length: 400000\n",
      "episode: 1441, score: 0, global_step_num: 446543, avg loss: 0.0017089146918234763, step: 323, replay memory length: 400000\n",
      "episode: 1442, score: 1.0, global_step_num: 446779, avg loss: 0.0009907506223749282, step: 236, replay memory length: 400000\n",
      "episode: 1443, score: 0, global_step_num: 447102, avg loss: 0.0014098164695007017, step: 323, replay memory length: 400000\n",
      "episode: 1444, score: 0, global_step_num: 447425, avg loss: 0.000960783618640686, step: 323, replay memory length: 400000\n",
      "episode: 1445, score: 0, global_step_num: 447748, avg loss: 0.0013105957364892595, step: 323, replay memory length: 400000\n",
      "episode: 1446, score: 0, global_step_num: 448071, avg loss: 0.0009002087743666427, step: 323, replay memory length: 400000\n",
      "episode: 1447, score: 0, global_step_num: 448394, avg loss: 0.0011158813360675215, step: 323, replay memory length: 400000\n",
      "episode: 1448, score: 0, global_step_num: 448717, avg loss: 0.0010868554862271463, step: 323, replay memory length: 400000\n",
      "episode: 1449, score: 0, global_step_num: 449040, avg loss: 0.0011842337325804512, step: 323, replay memory length: 400000\n",
      "episode: 1450, score: 0, global_step_num: 449363, avg loss: 0.0013629715970611992, step: 323, replay memory length: 400000\n",
      "episode: 1451, score: 0, global_step_num: 449686, avg loss: 0.0011211286637896223, step: 323, replay memory length: 400000\n",
      "episode: 1452, score: 1.0, global_step_num: 449753, avg loss: 0.0008554877162603236, step: 67, replay memory length: 400000\n",
      "episode: 1453, score: 1.0, global_step_num: 449993, avg loss: 0.001228672875535608, step: 240, replay memory length: 400000\n",
      "episode: 1454, score: 1.0, global_step_num: 450234, avg loss: 0.0014992798979672527, step: 241, replay memory length: 400000\n",
      "episode: 1455, score: 0, global_step_num: 450557, avg loss: 0.0013431872306536214, step: 323, replay memory length: 400000\n",
      "episode: 1456, score: 0, global_step_num: 450880, avg loss: 0.0013505667205788788, step: 323, replay memory length: 400000\n",
      "episode: 1457, score: 0, global_step_num: 451203, avg loss: 0.0010732330977240143, step: 323, replay memory length: 400000\n",
      "episode: 1458, score: 0, global_step_num: 451526, avg loss: 0.00142637644332787, step: 323, replay memory length: 400000\n",
      "episode: 1459, score: 0, global_step_num: 451849, avg loss: 0.0010050747177280724, step: 323, replay memory length: 400000\n",
      "episode: 1460, score: 0, global_step_num: 452172, avg loss: 0.0012734363896781456, step: 323, replay memory length: 400000\n",
      "episode: 1461, score: 0, global_step_num: 452495, avg loss: 0.001347397743127703, step: 323, replay memory length: 400000\n",
      "episode: 1462, score: 0, global_step_num: 452818, avg loss: 0.0010129829669475229, step: 323, replay memory length: 400000\n",
      "episode: 1463, score: 0, global_step_num: 453141, avg loss: 0.0011080352722009574, step: 323, replay memory length: 400000\n",
      "episode: 1464, score: 0, global_step_num: 453464, avg loss: 0.001877773971931387, step: 323, replay memory length: 400000\n",
      "episode: 1465, score: 1.0, global_step_num: 453515, avg loss: 0.0007753670741686958, step: 51, replay memory length: 400000\n",
      "episode: 1466, score: 0, global_step_num: 453838, avg loss: 0.001119542444731358, step: 323, replay memory length: 400000\n",
      "episode: 1467, score: 0, global_step_num: 454161, avg loss: 0.0011141938542197254, step: 323, replay memory length: 400000\n",
      "episode: 1468, score: 0, global_step_num: 454484, avg loss: 0.001429582105691326, step: 323, replay memory length: 400000\n",
      "episode: 1469, score: 0, global_step_num: 454807, avg loss: 0.001422646731078839, step: 323, replay memory length: 400000\n",
      "episode: 1470, score: 0, global_step_num: 455130, avg loss: 0.0015253433557926579, step: 323, replay memory length: 400000\n",
      "episode: 1471, score: 0, global_step_num: 455453, avg loss: 0.0013209194644233904, step: 323, replay memory length: 400000\n",
      "episode: 1472, score: 0, global_step_num: 455776, avg loss: 0.000948478340271305, step: 323, replay memory length: 400000\n",
      "episode: 1473, score: 1.0, global_step_num: 456074, avg loss: 0.001074637827988965, step: 298, replay memory length: 400000\n",
      "episode: 1474, score: 0, global_step_num: 456397, avg loss: 0.0011959371350310243, step: 323, replay memory length: 400000\n",
      "episode: 1475, score: 0, global_step_num: 456720, avg loss: 0.001159296045927938, step: 323, replay memory length: 400000\n",
      "episode: 1476, score: 0, global_step_num: 457043, avg loss: 0.0015898332835477668, step: 323, replay memory length: 400000\n",
      "episode: 1477, score: 0, global_step_num: 457366, avg loss: 0.0012168634955026956, step: 323, replay memory length: 400000\n",
      "episode: 1478, score: 0, global_step_num: 457689, avg loss: 0.0010964278411504248, step: 323, replay memory length: 400000\n",
      "episode: 1479, score: 0, global_step_num: 458012, avg loss: 0.0013442143694904446, step: 323, replay memory length: 400000\n",
      "episode: 1480, score: 0, global_step_num: 458335, avg loss: 0.0015309260841058295, step: 323, replay memory length: 400000\n",
      "episode: 1481, score: 0, global_step_num: 458658, avg loss: 0.001154348103202334, step: 323, replay memory length: 400000\n",
      "episode: 1482, score: 0, global_step_num: 458981, avg loss: 0.001494406031403795, step: 323, replay memory length: 400000\n",
      "episode: 1483, score: 0, global_step_num: 459304, avg loss: 0.0013420269091492017, step: 323, replay memory length: 400000\n",
      "episode: 1484, score: 0, global_step_num: 459627, avg loss: 0.0009263325624141721, step: 323, replay memory length: 400000\n",
      "episode: 1485, score: 1.0, global_step_num: 459757, avg loss: 0.0014527713381155011, step: 130, replay memory length: 400000\n",
      "episode: 1486, score: 0, global_step_num: 460080, avg loss: 0.0010916993437702657, step: 323, replay memory length: 400000\n",
      "episode: 1487, score: 0, global_step_num: 460403, avg loss: 0.0013553052394741972, step: 323, replay memory length: 400000\n",
      "episode: 1488, score: 0, global_step_num: 460726, avg loss: 0.0010584910439415819, step: 323, replay memory length: 400000\n",
      "episode: 1489, score: 0, global_step_num: 461049, avg loss: 0.001448749184885295, step: 323, replay memory length: 400000\n",
      "episode: 1490, score: 0, global_step_num: 461372, avg loss: 0.0014703658480343183, step: 323, replay memory length: 400000\n",
      "episode: 1491, score: 0, global_step_num: 461695, avg loss: 0.0012989512805753481, step: 323, replay memory length: 400000\n",
      "episode: 1492, score: 0, global_step_num: 462018, avg loss: 0.0011725273504323546, step: 323, replay memory length: 400000\n",
      "episode: 1493, score: 1.0, global_step_num: 462246, avg loss: 0.0009997369124903344, step: 228, replay memory length: 400000\n",
      "episode: 1494, score: 0, global_step_num: 462569, avg loss: 0.0010990487381554225, step: 323, replay memory length: 400000\n",
      "episode: 1495, score: 0, global_step_num: 462892, avg loss: 0.0015545511768908875, step: 323, replay memory length: 400000\n",
      "episode: 1496, score: 0, global_step_num: 463215, avg loss: 0.0011263271932309825, step: 323, replay memory length: 400000\n",
      "episode: 1497, score: 0, global_step_num: 463538, avg loss: 0.0012160667244640448, step: 323, replay memory length: 400000\n",
      "episode: 1498, score: 0, global_step_num: 463861, avg loss: 0.0014326785889684584, step: 323, replay memory length: 400000\n",
      "episode: 1499, score: 0, global_step_num: 464184, avg loss: 0.001140442983517209, step: 323, replay memory length: 400000\n",
      "episode: 1500, score: 0, global_step_num: 464507, avg loss: 0.0009794912013671186, step: 323, replay memory length: 400000\n",
      "episode: 1501, score: 1.0, global_step_num: 464707, avg loss: 0.0013029535181021856, step: 200, replay memory length: 400000\n",
      "episode: 1502, score: 0, global_step_num: 465030, avg loss: 0.0013573297169401013, step: 323, replay memory length: 400000\n",
      "episode: 1503, score: 0, global_step_num: 465353, avg loss: 0.0011732946618739568, step: 323, replay memory length: 400000\n",
      "episode: 1504, score: 0, global_step_num: 465676, avg loss: 0.001327699396864176, step: 323, replay memory length: 400000\n",
      "episode: 1505, score: 0, global_step_num: 465999, avg loss: 0.0010627016068546066, step: 323, replay memory length: 400000\n",
      "episode: 1506, score: 0, global_step_num: 466322, avg loss: 0.0014048333670826163, step: 323, replay memory length: 400000\n",
      "episode: 1507, score: 0, global_step_num: 466645, avg loss: 0.0011099672427827435, step: 323, replay memory length: 400000\n",
      "episode: 1508, score: 0, global_step_num: 466968, avg loss: 0.001048418294661924, step: 323, replay memory length: 400000\n",
      "episode: 1509, score: 0, global_step_num: 467291, avg loss: 0.0010664255115202918, step: 323, replay memory length: 400000\n",
      "episode: 1510, score: 0, global_step_num: 467614, avg loss: 0.0013840040215899853, step: 323, replay memory length: 400000\n",
      "episode: 1511, score: 0, global_step_num: 467937, avg loss: 0.0012256988518915947, step: 323, replay memory length: 400000\n",
      "episode: 1512, score: 0, global_step_num: 468260, avg loss: 0.0016062725985056972, step: 323, replay memory length: 400000\n",
      "episode: 1513, score: 0, global_step_num: 468583, avg loss: 0.0013908925071749645, step: 323, replay memory length: 400000\n",
      "episode: 1514, score: 0, global_step_num: 468906, avg loss: 0.0010617804383772334, step: 323, replay memory length: 400000\n",
      "episode: 1515, score: 0, global_step_num: 469229, avg loss: 0.0010362319226964241, step: 323, replay memory length: 400000\n",
      "episode: 1516, score: 0, global_step_num: 469552, avg loss: 0.0013603902604443889, step: 323, replay memory length: 400000\n",
      "episode: 1517, score: 0, global_step_num: 469875, avg loss: 0.0013179411786440713, step: 323, replay memory length: 400000\n",
      "episode: 1518, score: 0, global_step_num: 470198, avg loss: 0.0011158136688197934, step: 323, replay memory length: 400000\n",
      "episode: 1519, score: 0, global_step_num: 470521, avg loss: 0.0011781502630787562, step: 323, replay memory length: 400000\n",
      "episode: 1520, score: 0, global_step_num: 470844, avg loss: 0.0016056962326926366, step: 323, replay memory length: 400000\n",
      "episode: 1521, score: 0, global_step_num: 471167, avg loss: 0.001067149437213649, step: 323, replay memory length: 400000\n",
      "episode: 1522, score: 0, global_step_num: 471490, avg loss: 0.0012841821288530238, step: 323, replay memory length: 400000\n",
      "episode: 1523, score: 0, global_step_num: 471813, avg loss: 0.0015770747298897267, step: 323, replay memory length: 400000\n",
      "episode: 1524, score: 0, global_step_num: 472136, avg loss: 0.0011698174737143365, step: 323, replay memory length: 400000\n",
      "episode: 1525, score: 0, global_step_num: 472459, avg loss: 0.0011739466382735177, step: 323, replay memory length: 400000\n",
      "episode: 1526, score: 0, global_step_num: 472782, avg loss: 0.0013274778566976053, step: 323, replay memory length: 400000\n",
      "episode: 1527, score: 0, global_step_num: 473105, avg loss: 0.001044708956428889, step: 323, replay memory length: 400000\n",
      "episode: 1528, score: 0, global_step_num: 473428, avg loss: 0.001368291957238826, step: 323, replay memory length: 400000\n",
      "episode: 1529, score: 0, global_step_num: 473751, avg loss: 0.0011782287756150619, step: 323, replay memory length: 400000\n",
      "episode: 1531, score: 0, global_step_num: 474397, avg loss: 0.0010782150732612697, step: 323, replay memory length: 400000\n",
      "episode: 1532, score: 0, global_step_num: 474720, avg loss: 0.0014525265143010392, step: 323, replay memory length: 400000\n",
      "episode: 1533, score: 0, global_step_num: 475043, avg loss: 0.0015500409903572696, step: 323, replay memory length: 400000\n",
      "episode: 1534, score: 0, global_step_num: 475366, avg loss: 0.0009165743524203484, step: 323, replay memory length: 400000\n",
      "episode: 1535, score: 0, global_step_num: 475689, avg loss: 0.001686767431530808, step: 323, replay memory length: 400000\n",
      "episode: 1536, score: 0, global_step_num: 476012, avg loss: 0.001010187330543055, step: 323, replay memory length: 400000\n",
      "episode: 1537, score: 0, global_step_num: 476335, avg loss: 0.0013261230433131643, step: 323, replay memory length: 400000\n",
      "episode: 1538, score: 0, global_step_num: 476658, avg loss: 0.0014958317157465378, step: 323, replay memory length: 400000\n",
      "episode: 1539, score: 0, global_step_num: 476981, avg loss: 0.0011220430876584305, step: 323, replay memory length: 400000\n",
      "episode: 1540, score: 0, global_step_num: 477304, avg loss: 0.001538462859282538, step: 323, replay memory length: 400000\n",
      "episode: 1541, score: 0, global_step_num: 477627, avg loss: 0.0009516464756866623, step: 323, replay memory length: 400000\n",
      "episode: 1542, score: 0, global_step_num: 477950, avg loss: 0.0012091810763884964, step: 323, replay memory length: 400000\n",
      "episode: 1543, score: 0, global_step_num: 478273, avg loss: 0.001390776549461314, step: 323, replay memory length: 400000\n",
      "episode: 1544, score: 0, global_step_num: 478596, avg loss: 0.0008066676602254398, step: 323, replay memory length: 400000\n",
      "episode: 1545, score: 0, global_step_num: 478919, avg loss: 0.001674165439371988, step: 323, replay memory length: 400000\n",
      "episode: 1546, score: 0, global_step_num: 479242, avg loss: 0.0011447100516113937, step: 323, replay memory length: 400000\n",
      "episode: 1547, score: 0, global_step_num: 479565, avg loss: 0.0009268162126422386, step: 323, replay memory length: 400000\n",
      "episode: 1548, score: 0, global_step_num: 479888, avg loss: 0.0011089766567857727, step: 323, replay memory length: 400000\n",
      "episode: 1549, score: 1.0, global_step_num: 480018, avg loss: 0.001751892461773143, step: 130, replay memory length: 400000\n",
      "episode: 1550, score: 0, global_step_num: 480341, avg loss: 0.0014131842519035625, step: 323, replay memory length: 400000\n",
      "episode: 1551, score: 0, global_step_num: 480664, avg loss: 0.001128014718426197, step: 323, replay memory length: 400000\n",
      "episode: 1552, score: 0, global_step_num: 480987, avg loss: 0.0013039385842676433, step: 323, replay memory length: 400000\n",
      "episode: 1553, score: 1.0, global_step_num: 481169, avg loss: 0.0017087952289110255, step: 182, replay memory length: 400000\n",
      "episode: 1554, score: 0, global_step_num: 481492, avg loss: 0.001281828803498416, step: 323, replay memory length: 400000\n",
      "episode: 1555, score: 0, global_step_num: 481815, avg loss: 0.0007221010612586558, step: 323, replay memory length: 400000\n",
      "episode: 1556, score: 1.0, global_step_num: 481924, avg loss: 0.0011628863256008268, step: 109, replay memory length: 400000\n",
      "episode: 1557, score: 1.0, global_step_num: 482232, avg loss: 0.000985605171851969, step: 308, replay memory length: 400000\n",
      "episode: 1558, score: 0, global_step_num: 482555, avg loss: 0.0012681483744420552, step: 323, replay memory length: 400000\n",
      "episode: 1559, score: 1.0, global_step_num: 482647, avg loss: 0.0010381820225120464, step: 92, replay memory length: 400000\n",
      "episode: 1560, score: 0, global_step_num: 482970, avg loss: 0.0013969011575011934, step: 323, replay memory length: 400000\n",
      "episode: 1561, score: 1.0, global_step_num: 483182, avg loss: 0.0009012242230560247, step: 212, replay memory length: 400000\n",
      "episode: 1562, score: 1.0, global_step_num: 483458, avg loss: 0.0011027957872955453, step: 276, replay memory length: 400000\n",
      "episode: 1563, score: 1.0, global_step_num: 483684, avg loss: 0.0013408801963594396, step: 226, replay memory length: 400000\n",
      "episode: 1564, score: 0, global_step_num: 484007, avg loss: 0.0012526805539286548, step: 323, replay memory length: 400000\n",
      "episode: 1565, score: 0, global_step_num: 484330, avg loss: 0.001498885250591733, step: 323, replay memory length: 400000\n",
      "episode: 1566, score: 0, global_step_num: 484653, avg loss: 0.0014059346255857765, step: 323, replay memory length: 400000\n",
      "episode: 1567, score: 0, global_step_num: 484976, avg loss: 0.0013283211714697357, step: 323, replay memory length: 400000\n",
      "episode: 1568, score: 1.0, global_step_num: 485214, avg loss: 0.0012468382688271163, step: 238, replay memory length: 400000\n",
      "episode: 1569, score: 1.0, global_step_num: 485426, avg loss: 0.0015142658709494771, step: 212, replay memory length: 400000\n",
      "episode: 1570, score: 1.0, global_step_num: 485626, avg loss: 0.0011621233671235132, step: 200, replay memory length: 400000\n",
      "episode: 1571, score: 0, global_step_num: 485949, avg loss: 0.0008892665300410374, step: 323, replay memory length: 400000\n",
      "episode: 1572, score: 0, global_step_num: 486272, avg loss: 0.0013965774387191235, step: 323, replay memory length: 400000\n",
      "episode: 1573, score: 0, global_step_num: 486595, avg loss: 0.0015301737046588403, step: 323, replay memory length: 400000\n",
      "episode: 1574, score: 0, global_step_num: 486918, avg loss: 0.0012635805467698024, step: 323, replay memory length: 400000\n",
      "episode: 1575, score: 0, global_step_num: 487241, avg loss: 0.0012303024316133251, step: 323, replay memory length: 400000\n",
      "episode: 1576, score: 1.0, global_step_num: 487461, avg loss: 0.0009259382081361103, step: 220, replay memory length: 400000\n",
      "episode: 1577, score: 1.0, global_step_num: 487708, avg loss: 0.0011784748356458367, step: 247, replay memory length: 400000\n",
      "episode: 1578, score: 1.0, global_step_num: 487987, avg loss: 0.0010973901015334322, step: 279, replay memory length: 400000\n",
      "episode: 1579, score: 0, global_step_num: 488310, avg loss: 0.0013347369670614186, step: 323, replay memory length: 400000\n",
      "episode: 1580, score: 0, global_step_num: 488633, avg loss: 0.0011823860852001804, step: 323, replay memory length: 400000\n",
      "episode: 1581, score: 0, global_step_num: 488956, avg loss: 0.000941920064834778, step: 323, replay memory length: 400000\n",
      "episode: 1582, score: 0, global_step_num: 489279, avg loss: 0.0013128949987559412, step: 323, replay memory length: 400000\n",
      "episode: 1583, score: 0, global_step_num: 489602, avg loss: 0.0014523274847590703, step: 323, replay memory length: 400000\n",
      "episode: 1584, score: 0, global_step_num: 489925, avg loss: 0.0012293525008362427, step: 323, replay memory length: 400000\n",
      "episode: 1585, score: 1.0, global_step_num: 490221, avg loss: 0.0011348330164697178, step: 296, replay memory length: 400000\n",
      "episode: 1586, score: 0, global_step_num: 490544, avg loss: 0.0010733046080922887, step: 323, replay memory length: 400000\n",
      "episode: 1587, score: 0, global_step_num: 490867, avg loss: 0.0014472243045867699, step: 323, replay memory length: 400000\n",
      "episode: 1588, score: 0, global_step_num: 491190, avg loss: 0.001142550167084042, step: 323, replay memory length: 400000\n",
      "episode: 1589, score: 0, global_step_num: 491513, avg loss: 0.0012526083460258123, step: 323, replay memory length: 400000\n",
      "episode: 1590, score: 0, global_step_num: 491836, avg loss: 0.0011496159066636585, step: 323, replay memory length: 400000\n",
      "episode: 1591, score: 1.0, global_step_num: 491858, avg loss: 0.0012184285338993175, step: 22, replay memory length: 400000\n",
      "episode: 1592, score: 1.0, global_step_num: 492164, avg loss: 0.0012996218960506073, step: 306, replay memory length: 400000\n",
      "episode: 1593, score: 1.0, global_step_num: 492422, avg loss: 0.0014972968837947667, step: 258, replay memory length: 400000\n",
      "episode: 1594, score: 0, global_step_num: 492745, avg loss: 0.0012571654777433082, step: 323, replay memory length: 400000\n",
      "episode: 1595, score: 0, global_step_num: 493068, avg loss: 0.000820591076927167, step: 323, replay memory length: 400000\n",
      "episode: 1596, score: 1.0, global_step_num: 493318, avg loss: 0.0010765155917324591, step: 250, replay memory length: 400000\n",
      "episode: 1597, score: 1.0, global_step_num: 493458, avg loss: 0.0007224527127618785, step: 140, replay memory length: 400000\n",
      "episode: 1598, score: 1.0, global_step_num: 493679, avg loss: 0.0009680589208112894, step: 221, replay memory length: 400000\n",
      "episode: 1599, score: 0, global_step_num: 494002, avg loss: 0.0013632167134711316, step: 323, replay memory length: 400000\n",
      "episode: 1600, score: 0, global_step_num: 494325, avg loss: 0.0009999408543117396, step: 323, replay memory length: 400000\n",
      "episode: 1601, score: 0, global_step_num: 494648, avg loss: 0.001543623848022156, step: 323, replay memory length: 400000\n",
      "episode: 1602, score: 0, global_step_num: 494971, avg loss: 0.0011438619970892824, step: 323, replay memory length: 400000\n",
      "episode: 1603, score: 1.0, global_step_num: 495145, avg loss: 0.0007717038129942074, step: 174, replay memory length: 400000\n",
      "episode: 1604, score: 0, global_step_num: 495468, avg loss: 0.001066125777622058, step: 323, replay memory length: 400000\n",
      "episode: 1605, score: 0, global_step_num: 495791, avg loss: 0.0016678865801570942, step: 323, replay memory length: 400000\n",
      "episode: 1606, score: 0, global_step_num: 496114, avg loss: 0.001083461501657833, step: 323, replay memory length: 400000\n",
      "episode: 1607, score: 0, global_step_num: 496437, avg loss: 0.0008904081569114278, step: 323, replay memory length: 400000\n",
      "episode: 1608, score: 0, global_step_num: 496760, avg loss: 0.0012416716427727434, step: 323, replay memory length: 400000\n",
      "episode: 1609, score: 1.0, global_step_num: 496917, avg loss: 0.001318323562723299, step: 157, replay memory length: 400000\n",
      "episode: 1610, score: 0, global_step_num: 497240, avg loss: 0.001297427145099484, step: 323, replay memory length: 400000\n",
      "episode: 1611, score: 0, global_step_num: 497563, avg loss: 0.0014873503864551096, step: 323, replay memory length: 400000\n",
      "episode: 1612, score: 0, global_step_num: 497886, avg loss: 0.0011213685229182267, step: 323, replay memory length: 400000\n",
      "episode: 1613, score: 0, global_step_num: 498209, avg loss: 0.0014580125326397095, step: 323, replay memory length: 400000\n",
      "episode: 1614, score: 1.0, global_step_num: 498418, avg loss: 0.0014723407115259882, step: 209, replay memory length: 400000\n",
      "episode: 1615, score: 1.0, global_step_num: 498640, avg loss: 0.001180775937886669, step: 222, replay memory length: 400000\n",
      "episode: 1616, score: 0, global_step_num: 498963, avg loss: 0.0012743725979372207, step: 323, replay memory length: 400000\n",
      "episode: 1617, score: 0, global_step_num: 499286, avg loss: 0.001316303931664726, step: 323, replay memory length: 400000\n",
      "episode: 1618, score: 0, global_step_num: 499609, avg loss: 0.0011556551842169301, step: 323, replay memory length: 400000\n",
      "episode: 1619, score: 1.0, global_step_num: 499679, avg loss: 0.00128085944248986, step: 70, replay memory length: 400000\n",
      "episode: 1620, score: 0, global_step_num: 500002, avg loss: 0.001109111218189614, step: 323, replay memory length: 400000\n",
      "episode: 1621, score: 0, global_step_num: 500325, avg loss: 0.0010955740378530922, step: 323, replay memory length: 400000\n",
      "episode: 1622, score: 0, global_step_num: 500648, avg loss: 0.0012244188935464173, step: 323, replay memory length: 400000\n",
      "episode: 1623, score: 0, global_step_num: 500971, avg loss: 0.001161739614359733, step: 323, replay memory length: 400000\n",
      "episode: 1624, score: 0, global_step_num: 501294, avg loss: 0.0016543229012060112, step: 323, replay memory length: 400000\n",
      "episode: 1625, score: 0, global_step_num: 501617, avg loss: 0.0008534710306365002, step: 323, replay memory length: 400000\n",
      "episode: 1626, score: 0, global_step_num: 501940, avg loss: 0.0010761069116574829, step: 323, replay memory length: 400000\n",
      "episode: 1627, score: 0, global_step_num: 502263, avg loss: 0.0010435152331866946, step: 323, replay memory length: 400000\n",
      "episode: 1628, score: 0, global_step_num: 502586, avg loss: 0.001090411812222502, step: 323, replay memory length: 400000\n",
      "episode: 1629, score: 0, global_step_num: 502909, avg loss: 0.001478216921385029, step: 323, replay memory length: 400000\n",
      "episode: 1630, score: 0, global_step_num: 503232, avg loss: 0.0009584347860843135, step: 323, replay memory length: 400000\n",
      "episode: 1631, score: 0, global_step_num: 503555, avg loss: 0.0016682882840318978, step: 323, replay memory length: 400000\n",
      "episode: 1632, score: 0, global_step_num: 503878, avg loss: 0.0011405635536902992, step: 323, replay memory length: 400000\n",
      "episode: 1633, score: 0, global_step_num: 504201, avg loss: 0.0010488366197502106, step: 323, replay memory length: 400000\n",
      "episode: 1634, score: 1.0, global_step_num: 504386, avg loss: 0.0014397300406607109, step: 185, replay memory length: 400000\n",
      "episode: 1635, score: 0, global_step_num: 504709, avg loss: 0.0015367783402728242, step: 323, replay memory length: 400000\n",
      "episode: 1636, score: 0, global_step_num: 505032, avg loss: 0.0013433839508069252, step: 323, replay memory length: 400000\n",
      "episode: 1637, score: 1.0, global_step_num: 505338, avg loss: 0.0013112606132981573, step: 306, replay memory length: 400000\n",
      "episode: 1638, score: 0, global_step_num: 505661, avg loss: 0.0010013448702170466, step: 323, replay memory length: 400000\n",
      "episode: 1639, score: 0, global_step_num: 505984, avg loss: 0.001127116028697467, step: 323, replay memory length: 400000\n",
      "episode: 1640, score: 0, global_step_num: 506307, avg loss: 0.001198857134618927, step: 323, replay memory length: 400000\n",
      "episode: 1641, score: 0, global_step_num: 506630, avg loss: 0.001428178488869056, step: 323, replay memory length: 400000\n",
      "episode: 1642, score: 0, global_step_num: 506953, avg loss: 0.0013943434184832714, step: 323, replay memory length: 400000\n",
      "episode: 1643, score: 0, global_step_num: 507276, avg loss: 0.0008356925828627165, step: 323, replay memory length: 400000\n",
      "episode: 1644, score: 0, global_step_num: 507599, avg loss: 0.0013201564431914866, step: 323, replay memory length: 400000\n",
      "episode: 1645, score: 0, global_step_num: 507922, avg loss: 0.0013849715460450896, step: 323, replay memory length: 400000\n",
      "episode: 1646, score: 0, global_step_num: 508245, avg loss: 0.001013914755366451, step: 323, replay memory length: 400000\n",
      "episode: 1647, score: 1.0, global_step_num: 508461, avg loss: 0.0008913522159677659, step: 216, replay memory length: 400000\n",
      "episode: 1648, score: 1.0, global_step_num: 508779, avg loss: 0.001080089170820612, step: 318, replay memory length: 400000\n",
      "episode: 1649, score: 0, global_step_num: 509102, avg loss: 0.0014369828973946088, step: 323, replay memory length: 400000\n",
      "episode: 1650, score: 1.0, global_step_num: 509354, avg loss: 0.0016751670564948047, step: 252, replay memory length: 400000\n",
      "episode: 1651, score: 0, global_step_num: 509677, avg loss: 0.0009431994229373862, step: 323, replay memory length: 400000\n",
      "episode: 1652, score: 0, global_step_num: 510000, avg loss: 0.001440278236352394, step: 323, replay memory length: 400000\n",
      "episode: 1653, score: 0, global_step_num: 510323, avg loss: 0.0009499270315890479, step: 323, replay memory length: 400000\n",
      "episode: 1654, score: 0, global_step_num: 510646, avg loss: 0.0011649136504781631, step: 323, replay memory length: 400000\n",
      "episode: 1655, score: 0, global_step_num: 510969, avg loss: 0.0012394654389846372, step: 323, replay memory length: 400000\n",
      "episode: 1656, score: 1.0, global_step_num: 511236, avg loss: 0.001443109572484103, step: 267, replay memory length: 400000\n",
      "episode: 1657, score: 0, global_step_num: 511559, avg loss: 0.0012546476848604052, step: 323, replay memory length: 400000\n",
      "episode: 1658, score: 0, global_step_num: 511882, avg loss: 0.0011348060722986318, step: 323, replay memory length: 400000\n",
      "episode: 1659, score: 0, global_step_num: 512205, avg loss: 0.0008410843313364076, step: 323, replay memory length: 400000\n",
      "episode: 1660, score: 0, global_step_num: 512528, avg loss: 0.001144018216437581, step: 323, replay memory length: 400000\n",
      "episode: 1661, score: 1.0, global_step_num: 512636, avg loss: 0.0010197285775988079, step: 108, replay memory length: 400000\n",
      "episode: 1662, score: 0, global_step_num: 512959, avg loss: 0.0012403083207133958, step: 323, replay memory length: 400000\n",
      "episode: 1663, score: 1.0, global_step_num: 513239, avg loss: 0.001151007337335841, step: 280, replay memory length: 400000\n",
      "episode: 1664, score: 0, global_step_num: 513562, avg loss: 0.0012130720837061062, step: 323, replay memory length: 400000\n",
      "episode: 1665, score: 0, global_step_num: 513885, avg loss: 0.0011524692680675223, step: 323, replay memory length: 400000\n",
      "episode: 1666, score: 0, global_step_num: 514208, avg loss: 0.0011322344215666863, step: 323, replay memory length: 400000\n",
      "episode: 1667, score: 0, global_step_num: 514531, avg loss: 0.0011238229197150992, step: 323, replay memory length: 400000\n",
      "episode: 1668, score: 0, global_step_num: 514854, avg loss: 0.0010767786937789362, step: 323, replay memory length: 400000\n",
      "episode: 1669, score: 0, global_step_num: 515177, avg loss: 0.0014955144179365232, step: 323, replay memory length: 400000\n",
      "episode: 1670, score: 0, global_step_num: 515500, avg loss: 0.0010134290287486052, step: 323, replay memory length: 400000\n",
      "episode: 1671, score: 1.0, global_step_num: 515745, avg loss: 0.00130924548336169, step: 245, replay memory length: 400000\n",
      "episode: 1672, score: 0, global_step_num: 516068, avg loss: 0.0007662800880057246, step: 323, replay memory length: 400000\n",
      "episode: 1673, score: 0, global_step_num: 516391, avg loss: 0.0012820165632887995, step: 323, replay memory length: 400000\n",
      "episode: 1674, score: 0, global_step_num: 516714, avg loss: 0.0015470310598572298, step: 323, replay memory length: 400000\n",
      "episode: 1675, score: 0, global_step_num: 517037, avg loss: 0.0011785272303139254, step: 323, replay memory length: 400000\n",
      "episode: 1676, score: 0, global_step_num: 517360, avg loss: 0.001184020448408351, step: 323, replay memory length: 400000\n",
      "episode: 1677, score: 0, global_step_num: 517683, avg loss: 0.0014172869049639092, step: 323, replay memory length: 400000\n",
      "episode: 1678, score: 0, global_step_num: 518006, avg loss: 0.0014312486914084043, step: 323, replay memory length: 400000\n",
      "episode: 1679, score: 0, global_step_num: 518329, avg loss: 0.0013785940214329346, step: 323, replay memory length: 400000\n",
      "episode: 1680, score: 0, global_step_num: 518652, avg loss: 0.0012397491787828796, step: 323, replay memory length: 400000\n",
      "episode: 1681, score: 0, global_step_num: 518975, avg loss: 0.0012103835312212003, step: 323, replay memory length: 400000\n",
      "episode: 1682, score: 0, global_step_num: 519298, avg loss: 0.0010242762023512785, step: 323, replay memory length: 400000\n",
      "episode: 1683, score: 0, global_step_num: 519621, avg loss: 0.001192910335944094, step: 323, replay memory length: 400000\n",
      "episode: 1684, score: 1.0, global_step_num: 519828, avg loss: 0.0010400546950995924, step: 207, replay memory length: 400000\n",
      "episode: 1685, score: 0, global_step_num: 520151, avg loss: 0.0010560713176332246, step: 323, replay memory length: 400000\n",
      "episode: 1686, score: 1.0, global_step_num: 520372, avg loss: 0.0012349796170403919, step: 221, replay memory length: 400000\n",
      "episode: 1687, score: 1.0, global_step_num: 520656, avg loss: 0.001450313284656556, step: 284, replay memory length: 400000\n",
      "episode: 1688, score: 0, global_step_num: 520979, avg loss: 0.0012407773849666427, step: 323, replay memory length: 400000\n",
      "episode: 1689, score: 1.0, global_step_num: 521000, avg loss: 0.002391509221936195, step: 21, replay memory length: 400000\n",
      "episode: 1690, score: 0, global_step_num: 521323, avg loss: 0.0010447148437675992, step: 323, replay memory length: 400000\n",
      "episode: 1691, score: 0, global_step_num: 521646, avg loss: 0.0013192127436230648, step: 323, replay memory length: 400000\n",
      "episode: 1692, score: 1.0, global_step_num: 521895, avg loss: 0.001317742718238589, step: 249, replay memory length: 400000\n",
      "episode: 1693, score: 1.0, global_step_num: 521965, avg loss: 0.001513670857528788, step: 70, replay memory length: 400000\n",
      "episode: 1694, score: 1.0, global_step_num: 522227, avg loss: 0.001268844416342172, step: 262, replay memory length: 400000\n",
      "episode: 1695, score: 1.0, global_step_num: 522314, avg loss: 0.001352530381379553, step: 87, replay memory length: 400000\n",
      "episode: 1696, score: 1.0, global_step_num: 522484, avg loss: 0.0012148575636729219, step: 170, replay memory length: 400000\n",
      "episode: 1697, score: 0, global_step_num: 522807, avg loss: 0.000796990272319198, step: 323, replay memory length: 400000\n",
      "episode: 1698, score: 1.0, global_step_num: 523047, avg loss: 0.001096886934376092, step: 240, replay memory length: 400000\n",
      "episode: 1699, score: 1.0, global_step_num: 523268, avg loss: 0.0019532864757964828, step: 221, replay memory length: 400000\n",
      "episode: 1700, score: 0, global_step_num: 523591, avg loss: 0.0009770646508356208, step: 323, replay memory length: 400000\n",
      "episode: 1701, score: 1.0, global_step_num: 523840, avg loss: 0.0011789348906665643, step: 249, replay memory length: 400000\n",
      "episode: 1702, score: 0, global_step_num: 524163, avg loss: 0.0009656680241325949, step: 323, replay memory length: 400000\n",
      "episode: 1703, score: 0, global_step_num: 524486, avg loss: 0.0012356738091036077, step: 323, replay memory length: 400000\n",
      "episode: 1704, score: 0, global_step_num: 524809, avg loss: 0.001175762151631958, step: 323, replay memory length: 400000\n",
      "episode: 1705, score: 0, global_step_num: 525132, avg loss: 0.0013918090154043015, step: 323, replay memory length: 400000\n",
      "episode: 1706, score: 0, global_step_num: 525455, avg loss: 0.0012387368518894807, step: 323, replay memory length: 400000\n",
      "episode: 1707, score: 0, global_step_num: 525778, avg loss: 0.0010490216949938117, step: 323, replay memory length: 400000\n",
      "episode: 1708, score: 0, global_step_num: 526101, avg loss: 0.001078371253406264, step: 323, replay memory length: 400000\n",
      "episode: 1709, score: 0, global_step_num: 526424, avg loss: 0.0012518381049602832, step: 323, replay memory length: 400000\n",
      "episode: 1710, score: 1.0, global_step_num: 526654, avg loss: 0.001037473920642578, step: 230, replay memory length: 400000\n",
      "episode: 1711, score: 1.0, global_step_num: 526690, avg loss: 0.0014621629207643612, step: 36, replay memory length: 400000\n",
      "episode: 1712, score: 1.0, global_step_num: 526806, avg loss: 0.0009297697085834254, step: 116, replay memory length: 400000\n",
      "episode: 1713, score: 0, global_step_num: 527129, avg loss: 0.0008523038619477185, step: 323, replay memory length: 400000\n",
      "episode: 1714, score: 0, global_step_num: 527452, avg loss: 0.001448252448530685, step: 323, replay memory length: 400000\n",
      "episode: 1715, score: 0, global_step_num: 527775, avg loss: 0.0011995018861847538, step: 323, replay memory length: 400000\n",
      "episode: 1716, score: 0, global_step_num: 528098, avg loss: 0.0009027091879834921, step: 323, replay memory length: 400000\n",
      "episode: 1717, score: 0, global_step_num: 528421, avg loss: 0.0009362733217454695, step: 323, replay memory length: 400000\n",
      "episode: 1718, score: 0, global_step_num: 528744, avg loss: 0.0013934638582044718, step: 323, replay memory length: 400000\n",
      "episode: 1719, score: 1.0, global_step_num: 528821, avg loss: 0.0005232212582251867, step: 77, replay memory length: 400000\n",
      "episode: 1720, score: 0, global_step_num: 529144, avg loss: 0.0013860553490571072, step: 323, replay memory length: 400000\n",
      "episode: 1721, score: 0, global_step_num: 529467, avg loss: 0.0014017698311633662, step: 323, replay memory length: 400000\n",
      "episode: 1722, score: 0, global_step_num: 529790, avg loss: 0.0012869018525490997, step: 323, replay memory length: 400000\n",
      "episode: 1723, score: 1.0, global_step_num: 530036, avg loss: 0.000916478239024008, step: 246, replay memory length: 400000\n",
      "episode: 1724, score: 1.0, global_step_num: 530335, avg loss: 0.0013695422300898342, step: 299, replay memory length: 400000\n",
      "episode: 1725, score: 1.0, global_step_num: 530415, avg loss: 0.000989647695973872, step: 80, replay memory length: 400000\n",
      "episode: 1726, score: 1.0, global_step_num: 530561, avg loss: 0.0011843147192207217, step: 146, replay memory length: 400000\n",
      "episode: 1727, score: 0, global_step_num: 530884, avg loss: 0.0010299627343590284, step: 323, replay memory length: 400000\n",
      "episode: 1728, score: 0, global_step_num: 531207, avg loss: 0.0008811144536767099, step: 323, replay memory length: 400000\n",
      "episode: 1729, score: 1.0, global_step_num: 531418, avg loss: 0.0013656184724193787, step: 211, replay memory length: 400000\n",
      "episode: 1730, score: 0, global_step_num: 531741, avg loss: 0.0011930703620500456, step: 323, replay memory length: 400000\n",
      "episode: 1731, score: 0, global_step_num: 532064, avg loss: 0.0011859236661739515, step: 323, replay memory length: 400000\n",
      "episode: 1732, score: 0, global_step_num: 532387, avg loss: 0.0011409313796639112, step: 323, replay memory length: 400000\n",
      "episode: 1733, score: 1.0, global_step_num: 532551, avg loss: 0.00178933520703872, step: 164, replay memory length: 400000\n",
      "episode: 1734, score: 1.0, global_step_num: 532852, avg loss: 0.0013440613500904609, step: 301, replay memory length: 400000\n",
      "episode: 1735, score: 0, global_step_num: 533175, avg loss: 0.0012276930015400536, step: 323, replay memory length: 400000\n",
      "episode: 1736, score: 0, global_step_num: 533498, avg loss: 0.0011067824169133395, step: 323, replay memory length: 400000\n",
      "episode: 1737, score: 1.0, global_step_num: 533704, avg loss: 0.00120105849069898, step: 206, replay memory length: 400000\n",
      "episode: 1738, score: 0, global_step_num: 534027, avg loss: 0.0011356909903135755, step: 323, replay memory length: 400000\n",
      "episode: 1739, score: 1.0, global_step_num: 534118, avg loss: 0.0013254016333691082, step: 91, replay memory length: 400000\n",
      "episode: 1740, score: 1.0, global_step_num: 534432, avg loss: 0.0013106908943355286, step: 314, replay memory length: 400000\n",
      "episode: 1741, score: 0, global_step_num: 534755, avg loss: 0.0012217537857772969, step: 323, replay memory length: 400000\n",
      "episode: 1742, score: 0, global_step_num: 535078, avg loss: 0.001024622301133534, step: 323, replay memory length: 400000\n",
      "episode: 1743, score: 1.0, global_step_num: 535192, avg loss: 0.0013842451601328975, step: 114, replay memory length: 400000\n",
      "episode: 1744, score: 1.0, global_step_num: 535406, avg loss: 0.0013804122363219725, step: 214, replay memory length: 400000\n",
      "episode: 1745, score: 1.0, global_step_num: 535720, avg loss: 0.0010449552155811254, step: 314, replay memory length: 400000\n",
      "episode: 1746, score: 0, global_step_num: 536043, avg loss: 0.0010237335669372489, step: 323, replay memory length: 400000\n",
      "episode: 1747, score: 0, global_step_num: 536366, avg loss: 0.0012497371951913827, step: 323, replay memory length: 400000\n",
      "episode: 1748, score: 1.0, global_step_num: 536615, avg loss: 0.0013873668622985437, step: 249, replay memory length: 400000\n",
      "episode: 1749, score: 1.0, global_step_num: 536778, avg loss: 0.0012430678646362218, step: 163, replay memory length: 400000\n",
      "episode: 1750, score: 0, global_step_num: 537101, avg loss: 0.0014721298955767286, step: 323, replay memory length: 400000\n",
      "episode: 1751, score: 1.0, global_step_num: 537212, avg loss: 0.0012045315901363014, step: 111, replay memory length: 400000\n",
      "episode: 1752, score: 0, global_step_num: 537535, avg loss: 0.0009064523001896462, step: 323, replay memory length: 400000\n",
      "episode: 1753, score: 0, global_step_num: 537858, avg loss: 0.0011738279919238784, step: 323, replay memory length: 400000\n",
      "episode: 1754, score: 0, global_step_num: 538181, avg loss: 0.0011352517911617846, step: 323, replay memory length: 400000\n",
      "episode: 1755, score: 1.0, global_step_num: 538384, avg loss: 0.0009939127623741746, step: 203, replay memory length: 400000\n",
      "episode: 1756, score: 1.0, global_step_num: 538610, avg loss: 0.0010132978989439135, step: 226, replay memory length: 400000\n",
      "episode: 1757, score: 1.0, global_step_num: 538834, avg loss: 0.0014926505388055083, step: 224, replay memory length: 400000\n",
      "episode: 1758, score: 0, global_step_num: 539157, avg loss: 0.001002645814532293, step: 323, replay memory length: 400000\n",
      "episode: 1759, score: 0, global_step_num: 539480, avg loss: 0.0014860342783564423, step: 323, replay memory length: 400000\n",
      "episode: 1760, score: 0, global_step_num: 539803, avg loss: 0.0008532429137152288, step: 323, replay memory length: 400000\n",
      "episode: 1761, score: 0, global_step_num: 540126, avg loss: 0.0008359195284005683, step: 323, replay memory length: 400000\n",
      "episode: 1762, score: 1.0, global_step_num: 540228, avg loss: 0.0012275737369022595, step: 102, replay memory length: 400000\n",
      "episode: 1763, score: 1.0, global_step_num: 540293, avg loss: 0.0008619845980809679, step: 65, replay memory length: 400000\n",
      "episode: 1764, score: 0, global_step_num: 540616, avg loss: 0.0015331095863212027, step: 323, replay memory length: 400000\n",
      "episode: 1765, score: 1.0, global_step_num: 540842, avg loss: 0.0013471668532305703, step: 226, replay memory length: 400000\n",
      "episode: 1766, score: 0, global_step_num: 541165, avg loss: 0.0016272241041645572, step: 323, replay memory length: 400000\n",
      "episode: 1767, score: 0, global_step_num: 541488, avg loss: 0.0011395294992218945, step: 323, replay memory length: 400000\n",
      "episode: 1768, score: 0, global_step_num: 541811, avg loss: 0.0010312959030803095, step: 323, replay memory length: 400000\n",
      "episode: 1769, score: 0, global_step_num: 542134, avg loss: 0.0013743128356199525, step: 323, replay memory length: 400000\n",
      "episode: 1770, score: 1.0, global_step_num: 542284, avg loss: 0.0018669260897089164, step: 150, replay memory length: 400000\n",
      "episode: 1771, score: 0, global_step_num: 542607, avg loss: 0.0013302644229831343, step: 323, replay memory length: 400000\n",
      "episode: 1772, score: 1.0, global_step_num: 542710, avg loss: 0.0017229350258682282, step: 103, replay memory length: 400000\n",
      "episode: 1773, score: 1.0, global_step_num: 542950, avg loss: 0.0009412131833755666, step: 240, replay memory length: 400000\n",
      "episode: 1774, score: 1.0, global_step_num: 543176, avg loss: 0.0014289406128742822, step: 226, replay memory length: 400000\n",
      "episode: 1775, score: 0, global_step_num: 543499, avg loss: 0.0013993431879887107, step: 323, replay memory length: 400000\n",
      "episode: 1776, score: 0, global_step_num: 543822, avg loss: 0.001129564797615743, step: 323, replay memory length: 400000\n",
      "episode: 1777, score: 1.0, global_step_num: 543988, avg loss: 0.0010018656156955375, step: 166, replay memory length: 400000\n",
      "episode: 1778, score: 0, global_step_num: 544311, avg loss: 0.0011025236298880848, step: 323, replay memory length: 400000\n",
      "episode: 1779, score: 0, global_step_num: 544634, avg loss: 0.0011929040789584386, step: 323, replay memory length: 400000\n",
      "episode: 1780, score: 0, global_step_num: 544957, avg loss: 0.001240229011125358, step: 323, replay memory length: 400000\n",
      "episode: 1781, score: 1.0, global_step_num: 545121, avg loss: 0.000994061500217335, step: 164, replay memory length: 400000\n",
      "episode: 1782, score: 0, global_step_num: 545444, avg loss: 0.0011087574186206864, step: 323, replay memory length: 400000\n",
      "episode: 1783, score: 0, global_step_num: 545767, avg loss: 0.0014315505137394787, step: 323, replay memory length: 400000\n",
      "episode: 1784, score: 0, global_step_num: 546090, avg loss: 0.001160412865743953, step: 323, replay memory length: 400000\n",
      "episode: 1785, score: 0, global_step_num: 546413, avg loss: 0.0016747814293392328, step: 323, replay memory length: 400000\n",
      "episode: 1786, score: 0, global_step_num: 546736, avg loss: 0.0012325226763608469, step: 323, replay memory length: 400000\n",
      "episode: 1787, score: 0, global_step_num: 547059, avg loss: 0.000835056823708939, step: 323, replay memory length: 400000\n",
      "episode: 1788, score: 1.0, global_step_num: 547249, avg loss: 0.0009393098467937402, step: 190, replay memory length: 400000\n",
      "episode: 1789, score: 0, global_step_num: 547572, avg loss: 0.0012739962713009842, step: 323, replay memory length: 400000\n",
      "episode: 1790, score: 0, global_step_num: 547895, avg loss: 0.001226607172679272, step: 323, replay memory length: 400000\n",
      "episode: 1791, score: 0, global_step_num: 548218, avg loss: 0.001085117571332567, step: 323, replay memory length: 400000\n",
      "episode: 1792, score: 0, global_step_num: 548541, avg loss: 0.0014236458637270479, step: 323, replay memory length: 400000\n",
      "episode: 1793, score: 0, global_step_num: 548864, avg loss: 0.001418974084178047, step: 323, replay memory length: 400000\n",
      "episode: 1794, score: 1.0, global_step_num: 549105, avg loss: 0.0009233402311337125, step: 241, replay memory length: 400000\n",
      "episode: 1795, score: 0, global_step_num: 549428, avg loss: 0.0008860156564467604, step: 323, replay memory length: 400000\n",
      "episode: 1796, score: 1.0, global_step_num: 549602, avg loss: 0.0013213136717057615, step: 174, replay memory length: 400000\n",
      "episode: 1797, score: 1.0, global_step_num: 549731, avg loss: 0.0008570172988005962, step: 129, replay memory length: 400000\n",
      "episode: 1798, score: 0, global_step_num: 550054, avg loss: 0.0009369540245147717, step: 323, replay memory length: 400000\n",
      "episode: 1799, score: 1.0, global_step_num: 550290, avg loss: 0.0014602628240196682, step: 236, replay memory length: 400000\n",
      "episode: 1800, score: 1.0, global_step_num: 550378, avg loss: 0.0012381263848314202, step: 88, replay memory length: 400000\n",
      "episode: 1801, score: 0, global_step_num: 550701, avg loss: 0.0017389396010357898, step: 323, replay memory length: 400000\n",
      "episode: 1802, score: 0, global_step_num: 551024, avg loss: 0.0011000933950815431, step: 323, replay memory length: 400000\n",
      "episode: 1803, score: 0, global_step_num: 551347, avg loss: 0.0010652046844750618, step: 323, replay memory length: 400000\n",
      "episode: 1804, score: 1.0, global_step_num: 551540, avg loss: 0.0011246629303019251, step: 193, replay memory length: 400000\n",
      "episode: 1805, score: 1.0, global_step_num: 551785, avg loss: 0.0011589780912688685, step: 245, replay memory length: 400000\n",
      "episode: 1806, score: 1.0, global_step_num: 551957, avg loss: 0.0012534311739183215, step: 172, replay memory length: 400000\n",
      "episode: 1807, score: 0, global_step_num: 552280, avg loss: 0.0011754095617402596, step: 323, replay memory length: 400000\n",
      "episode: 1808, score: 0, global_step_num: 552603, avg loss: 0.0010927829728379019, step: 323, replay memory length: 400000\n",
      "episode: 1809, score: 0, global_step_num: 552926, avg loss: 0.001005763440532878, step: 323, replay memory length: 400000\n",
      "episode: 1810, score: 0, global_step_num: 553249, avg loss: 0.001326279819042735, step: 323, replay memory length: 400000\n",
      "episode: 1811, score: 0, global_step_num: 553572, avg loss: 0.0011538654223872122, step: 323, replay memory length: 400000\n",
      "episode: 1812, score: 1.0, global_step_num: 553735, avg loss: 0.0014122348649215398, step: 163, replay memory length: 400000\n",
      "episode: 1813, score: 1.0, global_step_num: 553895, avg loss: 0.0011735211354618968, step: 160, replay memory length: 400000\n",
      "episode: 1814, score: 0, global_step_num: 554218, avg loss: 0.0010770564460405917, step: 323, replay memory length: 400000\n",
      "episode: 1815, score: 0, global_step_num: 554541, avg loss: 0.0016049815752705045, step: 323, replay memory length: 400000\n",
      "episode: 1816, score: 1.0, global_step_num: 554676, avg loss: 0.0011750835702346025, step: 135, replay memory length: 400000\n",
      "episode: 1817, score: 1.0, global_step_num: 554994, avg loss: 0.001328556575706715, step: 318, replay memory length: 400000\n",
      "episode: 1818, score: 1.0, global_step_num: 555146, avg loss: 0.0012244000409545582, step: 152, replay memory length: 400000\n",
      "episode: 1819, score: 1.0, global_step_num: 555384, avg loss: 0.0011642162664979917, step: 238, replay memory length: 400000\n",
      "episode: 1820, score: 1.0, global_step_num: 555462, avg loss: 0.0003470718683542938, step: 78, replay memory length: 400000\n",
      "episode: 1821, score: 1.0, global_step_num: 555601, avg loss: 0.0010894500782662833, step: 139, replay memory length: 400000\n",
      "episode: 1822, score: 1.0, global_step_num: 555676, avg loss: 0.0014434757174664507, step: 75, replay memory length: 400000\n",
      "episode: 1823, score: 1.0, global_step_num: 555941, avg loss: 0.0013540504609066049, step: 265, replay memory length: 400000\n",
      "episode: 1824, score: 0, global_step_num: 556264, avg loss: 0.0010036930696306534, step: 323, replay memory length: 400000\n",
      "episode: 1825, score: 0, global_step_num: 556587, avg loss: 0.0011481251162961488, step: 323, replay memory length: 400000\n",
      "episode: 1826, score: 1.0, global_step_num: 556791, avg loss: 0.0008694481136252958, step: 204, replay memory length: 400000\n",
      "episode: 1827, score: 1.0, global_step_num: 556944, avg loss: 0.0017863450575086794, step: 153, replay memory length: 400000\n",
      "episode: 1828, score: 0, global_step_num: 557267, avg loss: 0.001278339214315886, step: 323, replay memory length: 400000\n",
      "episode: 1829, score: 1.0, global_step_num: 557429, avg loss: 0.0012677819254125176, step: 162, replay memory length: 400000\n",
      "episode: 1830, score: 0, global_step_num: 557752, avg loss: 0.0012681422471987754, step: 323, replay memory length: 400000\n",
      "episode: 1831, score: 1.0, global_step_num: 557991, avg loss: 0.0010526191318084666, step: 239, replay memory length: 400000\n",
      "episode: 1832, score: 1.0, global_step_num: 558100, avg loss: 0.0006531354506645117, step: 109, replay memory length: 400000\n",
      "episode: 1833, score: 1.0, global_step_num: 558327, avg loss: 0.001210045602656384, step: 227, replay memory length: 400000\n",
      "episode: 1834, score: 0, global_step_num: 558650, avg loss: 0.0012919941718475187, step: 323, replay memory length: 400000\n",
      "episode: 1835, score: 1.0, global_step_num: 558699, avg loss: 0.0016096219540356418, step: 49, replay memory length: 400000\n",
      "episode: 1836, score: 1.0, global_step_num: 558820, avg loss: 0.0005512557164546112, step: 121, replay memory length: 400000\n",
      "episode: 1837, score: 0, global_step_num: 559143, avg loss: 0.0009231920207034241, step: 323, replay memory length: 400000\n",
      "episode: 1838, score: 0, global_step_num: 559466, avg loss: 0.0018174101526882492, step: 323, replay memory length: 400000\n",
      "episode: 1839, score: 0, global_step_num: 559789, avg loss: 0.001073179744834596, step: 323, replay memory length: 400000\n",
      "episode: 1840, score: 1.0, global_step_num: 559915, avg loss: 0.001129779449774293, step: 126, replay memory length: 400000\n",
      "episode: 1841, score: 0, global_step_num: 560238, avg loss: 0.0013165864183721499, step: 323, replay memory length: 400000\n",
      "episode: 1842, score: 0, global_step_num: 560561, avg loss: 0.0007585836730675443, step: 323, replay memory length: 400000\n",
      "episode: 1843, score: 1.0, global_step_num: 560740, avg loss: 0.0012260627724912684, step: 179, replay memory length: 400000\n",
      "episode: 1844, score: 0, global_step_num: 561063, avg loss: 0.0014636949508909963, step: 323, replay memory length: 400000\n",
      "episode: 1845, score: 1.0, global_step_num: 561264, avg loss: 0.0010173058296766894, step: 201, replay memory length: 400000\n",
      "episode: 1846, score: 0, global_step_num: 561587, avg loss: 0.0015628167352644523, step: 323, replay memory length: 400000\n",
      "episode: 1847, score: 1.0, global_step_num: 561641, avg loss: 0.0018887332211626792, step: 54, replay memory length: 400000\n",
      "episode: 1848, score: 0, global_step_num: 561964, avg loss: 0.0011377879450532526, step: 323, replay memory length: 400000\n",
      "episode: 1849, score: 0, global_step_num: 562287, avg loss: 0.0012060810600679718, step: 323, replay memory length: 400000\n",
      "episode: 1850, score: 0, global_step_num: 562610, avg loss: 0.0013467132546092309, step: 323, replay memory length: 400000\n",
      "episode: 1851, score: 0, global_step_num: 562933, avg loss: 0.000939622076143664, step: 323, replay memory length: 400000\n",
      "episode: 1852, score: 1.0, global_step_num: 563147, avg loss: 0.001238862650221121, step: 214, replay memory length: 400000\n",
      "episode: 1853, score: 0, global_step_num: 563470, avg loss: 0.0013459822583696088, step: 323, replay memory length: 400000\n",
      "episode: 1854, score: 1.0, global_step_num: 563768, avg loss: 0.000904575222080747, step: 298, replay memory length: 400000\n",
      "episode: 1855, score: 0, global_step_num: 564091, avg loss: 0.0012906573301058385, step: 323, replay memory length: 400000\n",
      "episode: 1856, score: 1.0, global_step_num: 564154, avg loss: 0.0010737869154740659, step: 63, replay memory length: 400000\n",
      "episode: 1857, score: 1.0, global_step_num: 564402, avg loss: 0.0010904248577191774, step: 248, replay memory length: 400000\n",
      "episode: 1858, score: 0, global_step_num: 564725, avg loss: 0.0011577270950555918, step: 323, replay memory length: 400000\n",
      "episode: 1859, score: 0, global_step_num: 565048, avg loss: 0.0012995477346104778, step: 323, replay memory length: 400000\n",
      "episode: 1860, score: 0, global_step_num: 565371, avg loss: 0.0014155174988870834, step: 323, replay memory length: 400000\n",
      "episode: 1861, score: 1.0, global_step_num: 565662, avg loss: 0.001100701566949433, step: 291, replay memory length: 400000\n",
      "episode: 1862, score: 0, global_step_num: 565985, avg loss: 0.0010897691200863493, step: 323, replay memory length: 400000\n",
      "episode: 1863, score: 1.0, global_step_num: 566264, avg loss: 0.0010085558292115735, step: 279, replay memory length: 400000\n",
      "episode: 1864, score: 1.0, global_step_num: 566550, avg loss: 0.00103197571987554, step: 286, replay memory length: 400000\n",
      "episode: 1865, score: 1.0, global_step_num: 566645, avg loss: 0.0009974466452580314, step: 95, replay memory length: 400000\n",
      "episode: 1866, score: 0, global_step_num: 566968, avg loss: 0.0013296568555450348, step: 323, replay memory length: 400000\n",
      "episode: 1867, score: 1.0, global_step_num: 567078, avg loss: 0.0015221671416673582, step: 110, replay memory length: 400000\n",
      "episode: 1868, score: 0, global_step_num: 567401, avg loss: 0.0013429683928802027, step: 323, replay memory length: 400000\n",
      "episode: 1869, score: 1.0, global_step_num: 567639, avg loss: 0.0009007528093281446, step: 238, replay memory length: 400000\n",
      "episode: 1870, score: 1.0, global_step_num: 567873, avg loss: 0.0015331765514921655, step: 234, replay memory length: 400000\n",
      "episode: 1871, score: 0, global_step_num: 568196, avg loss: 0.0012737305422249132, step: 323, replay memory length: 400000\n",
      "episode: 1872, score: 1.0, global_step_num: 568432, avg loss: 0.0013948746802908564, step: 236, replay memory length: 400000\n",
      "episode: 1873, score: 1.0, global_step_num: 568682, avg loss: 0.0014428516473562923, step: 250, replay memory length: 400000\n",
      "episode: 1874, score: 1.0, global_step_num: 568780, avg loss: 0.0009239486536703875, step: 98, replay memory length: 400000\n",
      "episode: 1875, score: 1.0, global_step_num: 568931, avg loss: 0.0010571789843549975, step: 151, replay memory length: 400000\n",
      "episode: 1876, score: 0, global_step_num: 569254, avg loss: 0.0010936160939610336, step: 323, replay memory length: 400000\n",
      "episode: 1877, score: 0, global_step_num: 569577, avg loss: 0.0010216508851872473, step: 323, replay memory length: 400000\n",
      "episode: 1878, score: 0, global_step_num: 569900, avg loss: 0.001269180488723144, step: 323, replay memory length: 400000\n",
      "episode: 1879, score: 0, global_step_num: 570223, avg loss: 0.0009217487969137449, step: 323, replay memory length: 400000\n",
      "episode: 1880, score: 1.0, global_step_num: 570455, avg loss: 0.0013086776379235086, step: 232, replay memory length: 400000\n",
      "episode: 1881, score: 1.0, global_step_num: 570502, avg loss: 0.0005692806899652227, step: 47, replay memory length: 400000\n",
      "episode: 1882, score: 0, global_step_num: 570825, avg loss: 0.001088211296606437, step: 323, replay memory length: 400000\n",
      "episode: 1883, score: 0, global_step_num: 571148, avg loss: 0.0009574501217988986, step: 323, replay memory length: 400000\n",
      "episode: 1884, score: 1.0, global_step_num: 571350, avg loss: 0.0008988274732883378, step: 202, replay memory length: 400000\n",
      "episode: 1885, score: 0, global_step_num: 571673, avg loss: 0.0010087934773005721, step: 323, replay memory length: 400000\n",
      "episode: 1886, score: 0, global_step_num: 571996, avg loss: 0.0011615622534206266, step: 323, replay memory length: 400000\n",
      "episode: 1887, score: 0, global_step_num: 572319, avg loss: 0.001317271172671442, step: 323, replay memory length: 400000\n",
      "episode: 1888, score: 0, global_step_num: 572642, avg loss: 0.0012823285345867777, step: 323, replay memory length: 400000\n",
      "episode: 1889, score: 0, global_step_num: 572965, avg loss: 0.0009130709002972081, step: 323, replay memory length: 400000\n",
      "episode: 1890, score: 0, global_step_num: 573288, avg loss: 0.0011247717307437048, step: 323, replay memory length: 400000\n",
      "episode: 1891, score: 0, global_step_num: 573611, avg loss: 0.0012724473962662328, step: 323, replay memory length: 400000\n",
      "episode: 1892, score: 0, global_step_num: 573934, avg loss: 0.0016673266180038497, step: 323, replay memory length: 400000\n",
      "episode: 1893, score: 1.0, global_step_num: 574038, avg loss: 0.0010764419307109235, step: 104, replay memory length: 400000\n",
      "episode: 1894, score: 0, global_step_num: 574361, avg loss: 0.0013037726260113612, step: 323, replay memory length: 400000\n",
      "episode: 1895, score: 1.0, global_step_num: 574544, avg loss: 0.0009798410835690726, step: 183, replay memory length: 400000\n",
      "episode: 1896, score: 1.0, global_step_num: 574609, avg loss: 0.0010149513314760183, step: 65, replay memory length: 400000\n",
      "episode: 1897, score: 0, global_step_num: 574932, avg loss: 0.0006753579322484772, step: 323, replay memory length: 400000\n",
      "episode: 1898, score: 0, global_step_num: 575255, avg loss: 0.001155266722527261, step: 323, replay memory length: 400000\n",
      "episode: 1899, score: 0, global_step_num: 575578, avg loss: 0.0010970596871807217, step: 323, replay memory length: 400000\n",
      "episode: 1900, score: 0, global_step_num: 575901, avg loss: 0.001077682636597012, step: 323, replay memory length: 400000\n",
      "episode: 1901, score: 0, global_step_num: 576224, avg loss: 0.001191771869312261, step: 323, replay memory length: 400000\n",
      "episode: 1902, score: 0, global_step_num: 576547, avg loss: 0.0010706269714965426, step: 323, replay memory length: 400000\n",
      "episode: 1903, score: 0, global_step_num: 576870, avg loss: 0.0007643738847012795, step: 323, replay memory length: 400000\n",
      "episode: 1904, score: 1.0, global_step_num: 577061, avg loss: 0.001819842819249542, step: 191, replay memory length: 400000\n",
      "episode: 1905, score: 0, global_step_num: 577384, avg loss: 0.0012149603711151698, step: 323, replay memory length: 400000\n",
      "episode: 1906, score: 0, global_step_num: 577707, avg loss: 0.001364172415064603, step: 323, replay memory length: 400000\n",
      "episode: 1907, score: 0, global_step_num: 578030, avg loss: 0.0011293207960266847, step: 323, replay memory length: 400000\n",
      "episode: 1908, score: 0, global_step_num: 578353, avg loss: 0.0015219846770811983, step: 323, replay memory length: 400000\n",
      "episode: 1909, score: 0, global_step_num: 578676, avg loss: 0.0010946712045551976, step: 323, replay memory length: 400000\n",
      "episode: 1910, score: 0, global_step_num: 578999, avg loss: 0.000974178145475191, step: 323, replay memory length: 400000\n",
      "episode: 1911, score: 0, global_step_num: 579322, avg loss: 0.0009927832813992263, step: 323, replay memory length: 400000\n",
      "episode: 1912, score: 0, global_step_num: 579645, avg loss: 0.0008806477857082928, step: 323, replay memory length: 400000\n",
      "episode: 1913, score: 1.0, global_step_num: 579844, avg loss: 0.0007422600504528715, step: 199, replay memory length: 400000\n",
      "episode: 1914, score: 0, global_step_num: 580167, avg loss: 0.0009617627515398237, step: 323, replay memory length: 400000\n",
      "episode: 1915, score: 0, global_step_num: 580490, avg loss: 0.0015801003586104355, step: 323, replay memory length: 400000\n",
      "episode: 1916, score: 0, global_step_num: 580813, avg loss: 0.0010000971916226274, step: 323, replay memory length: 400000\n",
      "episode: 1917, score: 0, global_step_num: 581136, avg loss: 0.0007831671810621932, step: 323, replay memory length: 400000\n",
      "episode: 1918, score: 0, global_step_num: 581459, avg loss: 0.0010146479559206463, step: 323, replay memory length: 400000\n",
      "episode: 1919, score: 0, global_step_num: 581782, avg loss: 0.000823124367863063, step: 323, replay memory length: 400000\n",
      "episode: 1920, score: 0, global_step_num: 582105, avg loss: 0.0011434489202127186, step: 323, replay memory length: 400000\n",
      "episode: 1921, score: 0, global_step_num: 582428, avg loss: 0.0011902817589680267, step: 323, replay memory length: 400000\n",
      "episode: 1922, score: 0, global_step_num: 582751, avg loss: 0.0010361390099531114, step: 323, replay memory length: 400000\n",
      "episode: 1923, score: 0, global_step_num: 583074, avg loss: 0.0018936485875991295, step: 323, replay memory length: 400000\n",
      "episode: 1924, score: 0, global_step_num: 583397, avg loss: 0.0008556115013849002, step: 323, replay memory length: 400000\n",
      "episode: 1925, score: 0, global_step_num: 583720, avg loss: 0.0016008612212934183, step: 323, replay memory length: 400000\n",
      "episode: 1926, score: 0, global_step_num: 584043, avg loss: 0.0009823048399000183, step: 323, replay memory length: 400000\n",
      "episode: 1927, score: 0, global_step_num: 584366, avg loss: 0.0015218758574867346, step: 323, replay memory length: 400000\n",
      "episode: 1928, score: 0, global_step_num: 584689, avg loss: 0.0009231639531675621, step: 323, replay memory length: 400000\n",
      "episode: 1929, score: 0, global_step_num: 585012, avg loss: 0.0009639537855884453, step: 323, replay memory length: 400000\n",
      "episode: 1930, score: 0, global_step_num: 585335, avg loss: 0.0015769226159758737, step: 323, replay memory length: 400000\n",
      "episode: 1931, score: 0, global_step_num: 585658, avg loss: 0.001106814102398007, step: 323, replay memory length: 400000\n",
      "episode: 1932, score: 0, global_step_num: 585981, avg loss: 0.0008952743363090189, step: 323, replay memory length: 400000\n",
      "episode: 1933, score: 0, global_step_num: 586304, avg loss: 0.0015020901876711774, step: 323, replay memory length: 400000\n",
      "episode: 1934, score: 0, global_step_num: 586627, avg loss: 0.0012210468956764427, step: 323, replay memory length: 400000\n",
      "episode: 1935, score: 0, global_step_num: 586950, avg loss: 0.0009810300061667968, step: 323, replay memory length: 400000\n",
      "episode: 1936, score: 0, global_step_num: 587273, avg loss: 0.0011546963948769792, step: 323, replay memory length: 400000\n",
      "episode: 1937, score: 0, global_step_num: 587596, avg loss: 0.0010084952071833769, step: 323, replay memory length: 400000\n",
      "episode: 1938, score: 0, global_step_num: 587919, avg loss: 0.0007654377993836623, step: 323, replay memory length: 400000\n",
      "episode: 1939, score: 0, global_step_num: 588242, avg loss: 0.0014735645393355878, step: 323, replay memory length: 400000\n",
      "episode: 1940, score: 0, global_step_num: 588565, avg loss: 0.0009198764591260175, step: 323, replay memory length: 400000\n",
      "episode: 1941, score: 0, global_step_num: 588888, avg loss: 0.000777145828948366, step: 323, replay memory length: 400000\n",
      "episode: 1942, score: 0, global_step_num: 589211, avg loss: 0.0010343871645745652, step: 323, replay memory length: 400000\n",
      "episode: 1943, score: 0, global_step_num: 589534, avg loss: 0.001075949114280265, step: 323, replay memory length: 400000\n",
      "episode: 1944, score: 0, global_step_num: 589857, avg loss: 0.0011104435026779015, step: 323, replay memory length: 400000\n",
      "episode: 1945, score: 0, global_step_num: 590180, avg loss: 0.0012071755040708558, step: 323, replay memory length: 400000\n",
      "episode: 1946, score: 0, global_step_num: 590503, avg loss: 0.0011848573647669923, step: 323, replay memory length: 400000\n",
      "episode: 1947, score: 0, global_step_num: 590826, avg loss: 0.0010904063633306324, step: 323, replay memory length: 400000\n",
      "episode: 1948, score: 0, global_step_num: 591149, avg loss: 0.0012386039802958217, step: 323, replay memory length: 400000\n",
      "episode: 1949, score: 0, global_step_num: 591472, avg loss: 0.0013057811837756297, step: 323, replay memory length: 400000\n",
      "episode: 1950, score: 0, global_step_num: 591795, avg loss: 0.0009719226321323489, step: 323, replay memory length: 400000\n",
      "episode: 1951, score: 0, global_step_num: 592118, avg loss: 0.0009379606176100464, step: 323, replay memory length: 400000\n",
      "episode: 1952, score: 0, global_step_num: 592441, avg loss: 0.0013923003003870498, step: 323, replay memory length: 400000\n",
      "episode: 1953, score: 0, global_step_num: 592764, avg loss: 0.001342153692607853, step: 323, replay memory length: 400000\n",
      "episode: 1954, score: 0, global_step_num: 593087, avg loss: 0.0011901471741946768, step: 323, replay memory length: 400000\n",
      "episode: 1955, score: 0, global_step_num: 593410, avg loss: 0.0015731295264375053, step: 323, replay memory length: 400000\n",
      "episode: 1956, score: 0, global_step_num: 593733, avg loss: 0.0009772456955534912, step: 323, replay memory length: 400000\n",
      "episode: 1957, score: 0, global_step_num: 594056, avg loss: 0.0013701920621722245, step: 323, replay memory length: 400000\n",
      "episode: 1958, score: 0, global_step_num: 594379, avg loss: 0.0011134384450213267, step: 323, replay memory length: 400000\n",
      "episode: 1959, score: 0, global_step_num: 594702, avg loss: 0.0011228636190166797, step: 323, replay memory length: 400000\n",
      "episode: 1960, score: 0, global_step_num: 595025, avg loss: 0.0014990436234946641, step: 323, replay memory length: 400000\n",
      "episode: 1961, score: 0, global_step_num: 595348, avg loss: 0.0008018007805000338, step: 323, replay memory length: 400000\n",
      "episode: 1962, score: 0, global_step_num: 595671, avg loss: 0.0010832112735061396, step: 323, replay memory length: 400000\n",
      "episode: 1963, score: 0, global_step_num: 595994, avg loss: 0.0010303660246368603, step: 323, replay memory length: 400000\n",
      "episode: 1964, score: 0, global_step_num: 596317, avg loss: 0.001142573612450271, step: 323, replay memory length: 400000\n",
      "episode: 1965, score: 0, global_step_num: 596640, avg loss: 0.0010439894755170927, step: 323, replay memory length: 400000\n",
      "episode: 1966, score: 0, global_step_num: 596963, avg loss: 0.0011984934340851243, step: 323, replay memory length: 400000\n",
      "episode: 1967, score: 0, global_step_num: 597286, avg loss: 0.0013765505741510187, step: 323, replay memory length: 400000\n",
      "episode: 1968, score: 0, global_step_num: 597609, avg loss: 0.0009934360246823264, step: 323, replay memory length: 400000\n",
      "episode: 1969, score: 0, global_step_num: 597932, avg loss: 0.0008952217810844668, step: 323, replay memory length: 400000\n",
      "episode: 1970, score: 0, global_step_num: 598255, avg loss: 0.001200936559015062, step: 323, replay memory length: 400000\n",
      "episode: 1971, score: 0, global_step_num: 598578, avg loss: 0.0011599497975407827, step: 323, replay memory length: 400000\n",
      "episode: 1972, score: 0, global_step_num: 598901, avg loss: 0.0010665344246237633, step: 323, replay memory length: 400000\n",
      "episode: 1973, score: 0, global_step_num: 599224, avg loss: 0.0008163426621406141, step: 323, replay memory length: 400000\n",
      "episode: 1974, score: 0, global_step_num: 599547, avg loss: 0.0010562977851950057, step: 323, replay memory length: 400000\n",
      "episode: 1975, score: 0, global_step_num: 599870, avg loss: 0.0011138611375461117, step: 323, replay memory length: 400000\n",
      "episode: 1976, score: 1.0, global_step_num: 600056, avg loss: 0.0013375403225369662, step: 186, replay memory length: 400000\n",
      "episode: 1977, score: 0, global_step_num: 600379, avg loss: 0.0009490390191120061, step: 323, replay memory length: 400000\n",
      "episode: 1978, score: 1.0, global_step_num: 600690, avg loss: 0.0015009847992312414, step: 311, replay memory length: 400000\n",
      "episode: 1979, score: 0, global_step_num: 601013, avg loss: 0.0010270931197216891, step: 323, replay memory length: 400000\n",
      "episode: 1980, score: 1.0, global_step_num: 601144, avg loss: 0.0010059399425841992, step: 131, replay memory length: 400000\n",
      "episode: 1981, score: 0, global_step_num: 601467, avg loss: 0.001432580092409174, step: 323, replay memory length: 400000\n",
      "episode: 1982, score: 1.0, global_step_num: 601634, avg loss: 0.0008861889638380549, step: 167, replay memory length: 400000\n",
      "episode: 1983, score: 1.0, global_step_num: 601891, avg loss: 0.0012771860738681029, step: 257, replay memory length: 400000\n",
      "episode: 1984, score: 1.0, global_step_num: 602175, avg loss: 0.0013841105045265733, step: 284, replay memory length: 400000\n",
      "episode: 1985, score: 1.0, global_step_num: 602378, avg loss: 0.0010202817420890667, step: 203, replay memory length: 400000\n",
      "episode: 1986, score: 1.0, global_step_num: 602577, avg loss: 0.0009115284942366193, step: 199, replay memory length: 400000\n",
      "episode: 1987, score: 1.0, global_step_num: 602763, avg loss: 0.001178266278915182, step: 186, replay memory length: 400000\n",
      "episode: 1988, score: 0, global_step_num: 603086, avg loss: 0.0012467901289651294, step: 323, replay memory length: 400000\n",
      "episode: 1989, score: 1.0, global_step_num: 603192, avg loss: 0.0009653756660940897, step: 106, replay memory length: 400000\n",
      "episode: 1990, score: 1.0, global_step_num: 603376, avg loss: 0.0014594824096100776, step: 184, replay memory length: 400000\n",
      "episode: 1991, score: 1.0, global_step_num: 603555, avg loss: 0.001015557563079822, step: 179, replay memory length: 400000\n",
      "episode: 1992, score: 1.0, global_step_num: 603723, avg loss: 0.0014640082363812433, step: 168, replay memory length: 400000\n",
      "episode: 1993, score: 1.0, global_step_num: 604033, avg loss: 0.001021921201556559, step: 310, replay memory length: 400000\n",
      "episode: 1994, score: 1.0, global_step_num: 604274, avg loss: 0.000940204002248101, step: 241, replay memory length: 400000\n",
      "episode: 1995, score: 0, global_step_num: 604597, avg loss: 0.0012250591243083298, step: 323, replay memory length: 400000\n",
      "episode: 1996, score: 0, global_step_num: 604920, avg loss: 0.000811406270089939, step: 323, replay memory length: 400000\n",
      "episode: 1997, score: 1.0, global_step_num: 605095, avg loss: 0.0012210117209763536, step: 175, replay memory length: 400000\n",
      "episode: 1998, score: 1.0, global_step_num: 605324, avg loss: 0.000989173632107778, step: 229, replay memory length: 400000\n",
      "episode: 1999, score: 0, global_step_num: 605647, avg loss: 0.0012460255498004788, step: 323, replay memory length: 400000\n",
      "episode: 2000, score: 0, global_step_num: 605970, avg loss: 0.0007731139530050519, step: 323, replay memory length: 400000\n",
      "episode: 2001, score: 0, global_step_num: 606293, avg loss: 0.0007639850572286096, step: 323, replay memory length: 400000\n",
      "episode: 2002, score: 1.0, global_step_num: 606553, avg loss: 0.0009351096517399617, step: 260, replay memory length: 400000\n",
      "episode: 2003, score: 1.0, global_step_num: 606744, avg loss: 0.001189560387568507, step: 191, replay memory length: 400000\n",
      "episode: 2004, score: 0, global_step_num: 607067, avg loss: 0.0011022745836645291, step: 323, replay memory length: 400000\n",
      "episode: 2005, score: 0, global_step_num: 607390, avg loss: 0.0013420443463849835, step: 323, replay memory length: 400000\n",
      "episode: 2006, score: 0, global_step_num: 607713, avg loss: 0.0011547224223254166, step: 323, replay memory length: 400000\n",
      "episode: 2007, score: 0, global_step_num: 608036, avg loss: 0.0012371260382811225, step: 323, replay memory length: 400000\n",
      "episode: 2008, score: 1.0, global_step_num: 608317, avg loss: 0.0013564688559448788, step: 281, replay memory length: 400000\n",
      "episode: 2009, score: 1.0, global_step_num: 608501, avg loss: 0.001288986738603873, step: 184, replay memory length: 400000\n",
      "episode: 2010, score: 0, global_step_num: 608824, avg loss: 0.001220010342219997, step: 323, replay memory length: 400000\n",
      "episode: 2011, score: 0, global_step_num: 609147, avg loss: 0.001308914237727017, step: 323, replay memory length: 400000\n",
      "episode: 2012, score: 0, global_step_num: 609470, avg loss: 0.00123195050494799, step: 323, replay memory length: 400000\n",
      "episode: 2013, score: 1.0, global_step_num: 609671, avg loss: 0.0013235909627023355, step: 201, replay memory length: 400000\n",
      "episode: 2014, score: 1.0, global_step_num: 609962, avg loss: 0.0009428619752562832, step: 291, replay memory length: 400000\n",
      "episode: 2015, score: 0, global_step_num: 610285, avg loss: 0.0008773957207773244, step: 323, replay memory length: 400000\n",
      "episode: 2016, score: 1.0, global_step_num: 610516, avg loss: 0.0009939710245553176, step: 231, replay memory length: 400000\n",
      "episode: 2017, score: 0, global_step_num: 610839, avg loss: 0.0013478547057767898, step: 323, replay memory length: 400000\n",
      "episode: 2018, score: 0, global_step_num: 611162, avg loss: 0.0009805284400391252, step: 323, replay memory length: 400000\n",
      "episode: 2019, score: 1.0, global_step_num: 611305, avg loss: 0.0016901482996405587, step: 143, replay memory length: 400000\n",
      "episode: 2020, score: 1.0, global_step_num: 611531, avg loss: 0.0012417651231584612, step: 226, replay memory length: 400000\n",
      "episode: 2021, score: 1.0, global_step_num: 611775, avg loss: 0.0010120620618777809, step: 244, replay memory length: 400000\n",
      "episode: 2022, score: 1.0, global_step_num: 611963, avg loss: 0.0010503163373765017, step: 188, replay memory length: 400000\n",
      "episode: 2023, score: 0, global_step_num: 612286, avg loss: 0.0011322657338023307, step: 323, replay memory length: 400000\n",
      "episode: 2024, score: 0, global_step_num: 612609, avg loss: 0.0013163472375865082, step: 323, replay memory length: 400000\n",
      "episode: 2025, score: 1.0, global_step_num: 612729, avg loss: 0.0010973825657022947, step: 120, replay memory length: 400000\n",
      "episode: 2026, score: 1.0, global_step_num: 612946, avg loss: 0.0009056670211508549, step: 217, replay memory length: 400000\n",
      "episode: 2027, score: 0, global_step_num: 613269, avg loss: 0.0014574441982385794, step: 323, replay memory length: 400000\n",
      "episode: 2028, score: 1.0, global_step_num: 613444, avg loss: 0.0014360020589317304, step: 175, replay memory length: 400000\n",
      "episode: 2029, score: 0, global_step_num: 613767, avg loss: 0.0011321941889323888, step: 323, replay memory length: 400000\n",
      "episode: 2030, score: 1.0, global_step_num: 614080, avg loss: 0.0011212911895497632, step: 313, replay memory length: 400000\n",
      "episode: 2031, score: 0, global_step_num: 614403, avg loss: 0.0010886617077815377, step: 323, replay memory length: 400000\n",
      "episode: 2032, score: 0, global_step_num: 614726, avg loss: 0.0014510561420332689, step: 323, replay memory length: 400000\n",
      "episode: 2033, score: 1.0, global_step_num: 614983, avg loss: 0.0012128658150095538, step: 257, replay memory length: 400000\n",
      "episode: 2034, score: 0, global_step_num: 615306, avg loss: 0.001125596571684875, step: 323, replay memory length: 400000\n",
      "episode: 2035, score: 1.0, global_step_num: 615495, avg loss: 0.0011096524704910173, step: 189, replay memory length: 400000\n",
      "episode: 2036, score: 1.0, global_step_num: 615752, avg loss: 0.0010229377381205946, step: 257, replay memory length: 400000\n",
      "episode: 2037, score: 0, global_step_num: 616075, avg loss: 0.0008651121407270671, step: 323, replay memory length: 400000\n",
      "episode: 2038, score: 1.0, global_step_num: 616096, avg loss: 0.0006298531072518797, step: 21, replay memory length: 400000\n",
      "episode: 2039, score: 1.0, global_step_num: 616246, avg loss: 0.0014083591606701398, step: 150, replay memory length: 400000\n",
      "episode: 2040, score: 0, global_step_num: 616569, avg loss: 0.0012535511337765195, step: 323, replay memory length: 400000\n",
      "episode: 2041, score: 1.0, global_step_num: 616798, avg loss: 0.0014076627746549312, step: 229, replay memory length: 400000\n",
      "episode: 2042, score: 1.0, global_step_num: 616942, avg loss: 0.0011892560013046073, step: 144, replay memory length: 400000\n",
      "episode: 2043, score: 1.0, global_step_num: 617172, avg loss: 0.001110502291202386, step: 230, replay memory length: 400000\n",
      "episode: 2044, score: 0, global_step_num: 617495, avg loss: 0.0013361473202540052, step: 323, replay memory length: 400000\n",
      "episode: 2045, score: 1.0, global_step_num: 617664, avg loss: 0.0010970208425011183, step: 169, replay memory length: 400000\n",
      "episode: 2046, score: 0, global_step_num: 617987, avg loss: 0.0010018667720225563, step: 323, replay memory length: 400000\n",
      "episode: 2047, score: 0, global_step_num: 618310, avg loss: 0.0011066629524795514, step: 323, replay memory length: 400000\n",
      "episode: 2048, score: 0, global_step_num: 618633, avg loss: 0.0011717164579531584, step: 323, replay memory length: 400000\n",
      "episode: 2049, score: 1.0, global_step_num: 618709, avg loss: 0.001371219965434241, step: 76, replay memory length: 400000\n",
      "episode: 2050, score: 1.0, global_step_num: 618795, avg loss: 0.0009192663890691915, step: 86, replay memory length: 400000\n",
      "episode: 2051, score: 0, global_step_num: 619118, avg loss: 0.0011758164545399802, step: 323, replay memory length: 400000\n",
      "episode: 2052, score: 0, global_step_num: 619441, avg loss: 0.0009430311038771265, step: 323, replay memory length: 400000\n",
      "episode: 2053, score: 1.0, global_step_num: 619584, avg loss: 0.0013111864260723462, step: 143, replay memory length: 400000\n",
      "episode: 2054, score: 1.0, global_step_num: 619884, avg loss: 0.0009650833997155436, step: 300, replay memory length: 400000\n",
      "episode: 2055, score: 1.0, global_step_num: 620068, avg loss: 0.0013412913692533216, step: 184, replay memory length: 400000\n",
      "episode: 2056, score: 0, global_step_num: 620391, avg loss: 0.0012435114386534964, step: 323, replay memory length: 400000\n",
      "episode: 2057, score: 0, global_step_num: 620714, avg loss: 0.001103631210648632, step: 323, replay memory length: 400000\n",
      "episode: 2058, score: 0, global_step_num: 621037, avg loss: 0.0012487272190630262, step: 323, replay memory length: 400000\n",
      "episode: 2059, score: 0, global_step_num: 621360, avg loss: 0.0013713960210839035, step: 323, replay memory length: 400000\n",
      "episode: 2060, score: 0, global_step_num: 621683, avg loss: 0.0010309139825032854, step: 323, replay memory length: 400000\n",
      "episode: 2061, score: 0, global_step_num: 622006, avg loss: 0.0010280893123086042, step: 323, replay memory length: 400000\n",
      "episode: 2062, score: 0, global_step_num: 622329, avg loss: 0.0009747363136508402, step: 323, replay memory length: 400000\n",
      "episode: 2063, score: 0, global_step_num: 622652, avg loss: 0.0007707753593196978, step: 323, replay memory length: 400000\n",
      "episode: 2064, score: 0, global_step_num: 622975, avg loss: 0.0008312114238119803, step: 323, replay memory length: 400000\n",
      "episode: 2065, score: 0, global_step_num: 623298, avg loss: 0.0011786414614011608, step: 323, replay memory length: 400000\n",
      "episode: 2066, score: 0, global_step_num: 623621, avg loss: 0.0013947754714367184, step: 323, replay memory length: 400000\n",
      "episode: 2067, score: 0, global_step_num: 623944, avg loss: 0.0010242385869329977, step: 323, replay memory length: 400000\n",
      "episode: 2068, score: 0, global_step_num: 624267, avg loss: 0.0014708800053164566, step: 323, replay memory length: 400000\n",
      "episode: 2069, score: 0, global_step_num: 624590, avg loss: 0.0013116491507448715, step: 323, replay memory length: 400000\n",
      "episode: 2070, score: 0, global_step_num: 624913, avg loss: 0.0010473997950005303, step: 323, replay memory length: 400000\n",
      "episode: 2071, score: 0, global_step_num: 625236, avg loss: 0.0012170553736631864, step: 323, replay memory length: 400000\n",
      "episode: 2072, score: 0, global_step_num: 625559, avg loss: 0.0010725612025971403, step: 323, replay memory length: 400000\n",
      "episode: 2073, score: 0, global_step_num: 625882, avg loss: 0.000884048163843742, step: 323, replay memory length: 400000\n",
      "episode: 2074, score: 0, global_step_num: 626205, avg loss: 0.0010704689870569605, step: 323, replay memory length: 400000\n",
      "episode: 2075, score: 0, global_step_num: 626528, avg loss: 0.0010319837376058555, step: 323, replay memory length: 400000\n",
      "episode: 2076, score: 0, global_step_num: 626851, avg loss: 0.0012934545959756558, step: 323, replay memory length: 400000\n",
      "episode: 2077, score: 0, global_step_num: 627174, avg loss: 0.0010817678501950042, step: 323, replay memory length: 400000\n",
      "episode: 2078, score: 0, global_step_num: 627497, avg loss: 0.0009715482944441706, step: 323, replay memory length: 400000\n",
      "episode: 2079, score: 0, global_step_num: 627820, avg loss: 0.0008583279684169741, step: 323, replay memory length: 400000\n",
      "episode: 2080, score: 0, global_step_num: 628143, avg loss: 0.0010141762192235136, step: 323, replay memory length: 400000\n",
      "episode: 2081, score: 0, global_step_num: 628466, avg loss: 0.0010189049509196366, step: 323, replay memory length: 400000\n",
      "episode: 2082, score: 0, global_step_num: 628789, avg loss: 0.0012369415789470518, step: 323, replay memory length: 400000\n",
      "episode: 2083, score: 0, global_step_num: 629112, avg loss: 0.0012843556555701308, step: 323, replay memory length: 400000\n",
      "episode: 2084, score: 0, global_step_num: 629435, avg loss: 0.0010584320885338272, step: 323, replay memory length: 400000\n",
      "episode: 2085, score: 0, global_step_num: 629758, avg loss: 0.0011523089813455824, step: 323, replay memory length: 400000\n",
      "episode: 2086, score: 0, global_step_num: 630081, avg loss: 0.00113810559261396, step: 323, replay memory length: 400000\n",
      "episode: 2087, score: 0, global_step_num: 630404, avg loss: 0.0014283509111160705, step: 323, replay memory length: 400000\n",
      "episode: 2088, score: 0, global_step_num: 630727, avg loss: 0.0010941051394855448, step: 323, replay memory length: 400000\n",
      "episode: 2089, score: 0, global_step_num: 631050, avg loss: 0.0013746007628528802, step: 323, replay memory length: 400000\n",
      "episode: 2090, score: 0, global_step_num: 631373, avg loss: 0.0008752062649297359, step: 323, replay memory length: 400000\n",
      "episode: 2091, score: 0, global_step_num: 631696, avg loss: 0.00127465367575499, step: 323, replay memory length: 400000\n",
      "episode: 2092, score: 0, global_step_num: 632019, avg loss: 0.0010592987678763944, step: 323, replay memory length: 400000\n",
      "episode: 2093, score: 0, global_step_num: 632342, avg loss: 0.0009772422866181128, step: 323, replay memory length: 400000\n",
      "episode: 2094, score: 0, global_step_num: 632665, avg loss: 0.0012819687057212367, step: 323, replay memory length: 400000\n",
      "episode: 2095, score: 0, global_step_num: 632988, avg loss: 0.001027634309902881, step: 323, replay memory length: 400000\n",
      "episode: 2096, score: 0, global_step_num: 633311, avg loss: 0.0010309509295161703, step: 323, replay memory length: 400000\n",
      "episode: 2097, score: 0, global_step_num: 633634, avg loss: 0.001178206843743049, step: 323, replay memory length: 400000\n",
      "episode: 2098, score: 0, global_step_num: 633957, avg loss: 0.0013912453107437141, step: 323, replay memory length: 400000\n",
      "episode: 2099, score: 0, global_step_num: 634280, avg loss: 0.0013138620846980345, step: 323, replay memory length: 400000\n",
      "episode: 2100, score: 0, global_step_num: 634603, avg loss: 0.0009440490512893951, step: 323, replay memory length: 400000\n",
      "episode: 2101, score: 0, global_step_num: 634926, avg loss: 0.0012401943331018341, step: 323, replay memory length: 400000\n",
      "episode: 2102, score: 0, global_step_num: 635249, avg loss: 0.0010379458708442654, step: 323, replay memory length: 400000\n",
      "episode: 2103, score: 0, global_step_num: 635572, avg loss: 0.0011772945250391087, step: 323, replay memory length: 400000\n",
      "episode: 2104, score: 0, global_step_num: 635895, avg loss: 0.001032605043284887, step: 323, replay memory length: 400000\n",
      "episode: 2105, score: 0, global_step_num: 636218, avg loss: 0.0012047046876072012, step: 323, replay memory length: 400000\n",
      "episode: 2106, score: 0, global_step_num: 636541, avg loss: 0.0009752947978836417, step: 323, replay memory length: 400000\n",
      "episode: 2107, score: 0, global_step_num: 636864, avg loss: 0.0012797631614223808, step: 323, replay memory length: 400000\n",
      "episode: 2108, score: 0, global_step_num: 637187, avg loss: 0.0010359335322147852, step: 323, replay memory length: 400000\n",
      "episode: 2109, score: 0, global_step_num: 637510, avg loss: 0.0009431004291231366, step: 323, replay memory length: 400000\n",
      "episode: 2110, score: 0, global_step_num: 637833, avg loss: 0.0012753557010017698, step: 323, replay memory length: 400000\n",
      "episode: 2111, score: 0, global_step_num: 638156, avg loss: 0.0015324568413338558, step: 323, replay memory length: 400000\n",
      "episode: 2112, score: 0, global_step_num: 638479, avg loss: 0.0012189565569679806, step: 323, replay memory length: 400000\n",
      "episode: 2113, score: 0, global_step_num: 638802, avg loss: 0.0009222997199905408, step: 323, replay memory length: 400000\n",
      "episode: 2114, score: 0, global_step_num: 639125, avg loss: 0.001039720177355978, step: 323, replay memory length: 400000\n",
      "episode: 2115, score: 0, global_step_num: 639448, avg loss: 0.0011611854396373464, step: 323, replay memory length: 400000\n",
      "episode: 2116, score: 0, global_step_num: 639771, avg loss: 0.0009488675586239612, step: 323, replay memory length: 400000\n",
      "episode: 2117, score: 1.0, global_step_num: 640057, avg loss: 0.0010609462085635546, step: 286, replay memory length: 400000\n",
      "episode: 2118, score: 0, global_step_num: 640380, avg loss: 0.0009330774080565059, step: 323, replay memory length: 400000\n",
      "episode: 2119, score: 0, global_step_num: 640703, avg loss: 0.0011928886808062584, step: 323, replay memory length: 400000\n",
      "episode: 2120, score: 0, global_step_num: 641026, avg loss: 0.0010071752805564215, step: 323, replay memory length: 400000\n",
      "episode: 2121, score: 1.0, global_step_num: 641121, avg loss: 0.0013637736134593356, step: 95, replay memory length: 400000\n",
      "episode: 2122, score: 0, global_step_num: 641444, avg loss: 0.0013649630896782586, step: 323, replay memory length: 400000\n",
      "episode: 2123, score: 1.0, global_step_num: 641607, avg loss: 0.0012828908118904026, step: 163, replay memory length: 400000\n",
      "episode: 2124, score: 0, global_step_num: 641930, avg loss: 0.0011680639537885059, step: 323, replay memory length: 400000\n",
      "episode: 2125, score: 0, global_step_num: 642253, avg loss: 0.0012326261340271844, step: 323, replay memory length: 400000\n",
      "episode: 2126, score: 0, global_step_num: 642576, avg loss: 0.0013975864040736443, step: 323, replay memory length: 400000\n",
      "episode: 2127, score: 0, global_step_num: 642899, avg loss: 0.0009564606385980431, step: 323, replay memory length: 400000\n",
      "episode: 2128, score: 0, global_step_num: 643222, avg loss: 0.001386355053013818, step: 323, replay memory length: 400000\n",
      "episode: 2129, score: 0, global_step_num: 643545, avg loss: 0.0007788893577370048, step: 323, replay memory length: 400000\n",
      "episode: 2130, score: 0, global_step_num: 643868, avg loss: 0.0014560952394109144, step: 323, replay memory length: 400000\n",
      "episode: 2131, score: 1.0, global_step_num: 644172, avg loss: 0.0011076724008070844, step: 304, replay memory length: 400000\n",
      "episode: 2132, score: 1.0, global_step_num: 644329, avg loss: 0.001402001998723014, step: 157, replay memory length: 400000\n",
      "episode: 2133, score: 1.0, global_step_num: 644467, avg loss: 0.0012510517283630363, step: 138, replay memory length: 400000\n",
      "episode: 2134, score: 0, global_step_num: 644790, avg loss: 0.001224965892813874, step: 323, replay memory length: 400000\n",
      "episode: 2135, score: 1.0, global_step_num: 645022, avg loss: 0.0009034527857107245, step: 232, replay memory length: 400000\n",
      "episode: 2136, score: 0, global_step_num: 645345, avg loss: 0.001156335668718767, step: 323, replay memory length: 400000\n",
      "episode: 2137, score: 0, global_step_num: 645668, avg loss: 0.0012213228880081268, step: 323, replay memory length: 400000\n",
      "episode: 2138, score: 1.0, global_step_num: 645948, avg loss: 0.0009156071257612958, step: 280, replay memory length: 400000\n",
      "episode: 2139, score: 0, global_step_num: 646271, avg loss: 0.0010350233280430861, step: 323, replay memory length: 400000\n",
      "episode: 2140, score: 0, global_step_num: 646594, avg loss: 0.0012763963924401823, step: 323, replay memory length: 400000\n",
      "episode: 2141, score: 0, global_step_num: 646917, avg loss: 0.0009403849222548972, step: 323, replay memory length: 400000\n",
      "episode: 2142, score: 0, global_step_num: 647240, avg loss: 0.0013335533605413027, step: 323, replay memory length: 400000\n",
      "episode: 2143, score: 1.0, global_step_num: 647432, avg loss: 0.001383428896687633, step: 192, replay memory length: 400000\n",
      "episode: 2144, score: 0, global_step_num: 647755, avg loss: 0.0009010346400253567, step: 323, replay memory length: 400000\n",
      "episode: 2145, score: 1.0, global_step_num: 647860, avg loss: 0.001133193373943002, step: 105, replay memory length: 400000\n",
      "episode: 2146, score: 0, global_step_num: 648183, avg loss: 0.0013734185863280455, step: 323, replay memory length: 400000\n",
      "episode: 2147, score: 1.0, global_step_num: 648313, avg loss: 0.0008831104983423407, step: 130, replay memory length: 400000\n",
      "episode: 2148, score: 0, global_step_num: 648636, avg loss: 0.001011539351812551, step: 323, replay memory length: 400000\n",
      "episode: 2149, score: 1.0, global_step_num: 648753, avg loss: 0.0009061464056782677, step: 117, replay memory length: 400000\n",
      "episode: 2150, score: 0, global_step_num: 649076, avg loss: 0.0012423804864393553, step: 323, replay memory length: 400000\n",
      "episode: 2151, score: 1.0, global_step_num: 649351, avg loss: 0.0009334133909256211, step: 275, replay memory length: 400000\n",
      "episode: 2152, score: 0, global_step_num: 649674, avg loss: 0.0011585846341003, step: 323, replay memory length: 400000\n",
      "episode: 2153, score: 0, global_step_num: 649997, avg loss: 0.0007199678802883881, step: 323, replay memory length: 400000\n",
      "episode: 2154, score: 1.0, global_step_num: 650186, avg loss: 0.0012763272822171553, step: 189, replay memory length: 400000\n",
      "episode: 2155, score: 1.0, global_step_num: 650249, avg loss: 0.00043376762695992337, step: 63, replay memory length: 400000\n",
      "episode: 2156, score: 0, global_step_num: 650572, avg loss: 0.0011200024684826714, step: 323, replay memory length: 400000\n",
      "episode: 2157, score: 1.0, global_step_num: 650814, avg loss: 0.0009747445982384306, step: 242, replay memory length: 400000\n",
      "episode: 2158, score: 1.0, global_step_num: 651054, avg loss: 0.0014721457051554883, step: 240, replay memory length: 400000\n",
      "episode: 2159, score: 0, global_step_num: 651377, avg loss: 0.0009763856149441412, step: 323, replay memory length: 400000\n",
      "episode: 2160, score: 1.0, global_step_num: 651536, avg loss: 0.0011512698758720577, step: 159, replay memory length: 400000\n",
      "episode: 2162, score: 1.0, global_step_num: 652019, avg loss: 0.0012532585399270602, step: 160, replay memory length: 400000\n",
      "episode: 2163, score: 1.0, global_step_num: 652206, avg loss: 0.0011738900352976152, step: 187, replay memory length: 400000\n",
      "episode: 2164, score: 1.0, global_step_num: 652459, avg loss: 0.0008298613900716073, step: 253, replay memory length: 400000\n",
      "episode: 2165, score: 1.0, global_step_num: 652586, avg loss: 0.0011645005834284312, step: 127, replay memory length: 400000\n",
      "episode: 2166, score: 0, global_step_num: 652909, avg loss: 0.0013575477735047355, step: 323, replay memory length: 400000\n",
      "episode: 2167, score: 0, global_step_num: 653232, avg loss: 0.0012191186137292212, step: 323, replay memory length: 400000\n",
      "episode: 2168, score: 1.0, global_step_num: 653443, avg loss: 0.0008499939472551055, step: 211, replay memory length: 400000\n",
      "episode: 2169, score: 0, global_step_num: 653766, avg loss: 0.0011042110501869532, step: 323, replay memory length: 400000\n",
      "episode: 2170, score: 0, global_step_num: 654089, avg loss: 0.0011806771728280624, step: 323, replay memory length: 400000\n",
      "episode: 2171, score: 0, global_step_num: 654412, avg loss: 0.0011893709527460322, step: 323, replay memory length: 400000\n",
      "episode: 2172, score: 0, global_step_num: 654735, avg loss: 0.0011043216091903862, step: 323, replay memory length: 400000\n",
      "episode: 2173, score: 0, global_step_num: 655058, avg loss: 0.0007378434437149547, step: 323, replay memory length: 400000\n",
      "episode: 2174, score: 1.0, global_step_num: 655121, avg loss: 0.0015064503242561004, step: 63, replay memory length: 400000\n",
      "episode: 2175, score: 1.0, global_step_num: 655343, avg loss: 0.0009883116313990532, step: 222, replay memory length: 400000\n",
      "episode: 2176, score: 1.0, global_step_num: 655511, avg loss: 0.0009791402857677852, step: 168, replay memory length: 400000\n",
      "episode: 2177, score: 0, global_step_num: 655834, avg loss: 0.0013398744289012823, step: 323, replay memory length: 400000\n",
      "episode: 2178, score: 0, global_step_num: 656157, avg loss: 0.0010499471869971101, step: 323, replay memory length: 400000\n",
      "episode: 2179, score: 1.0, global_step_num: 656357, avg loss: 0.0009341627136427633, step: 200, replay memory length: 400000\n",
      "episode: 2180, score: 1.0, global_step_num: 656512, avg loss: 0.0012628602695566506, step: 155, replay memory length: 400000\n",
      "episode: 2181, score: 1.0, global_step_num: 656801, avg loss: 0.0012012779984391692, step: 289, replay memory length: 400000\n",
      "episode: 2182, score: 0, global_step_num: 657124, avg loss: 0.0011903168603409199, step: 323, replay memory length: 400000\n",
      "episode: 2183, score: 0, global_step_num: 657447, avg loss: 0.0010486417170569938, step: 323, replay memory length: 400000\n",
      "episode: 2184, score: 0, global_step_num: 657770, avg loss: 0.0011236791633479808, step: 323, replay memory length: 400000\n",
      "episode: 2185, score: 1.0, global_step_num: 657895, avg loss: 0.001305809853307437, step: 125, replay memory length: 400000\n",
      "episode: 2186, score: 1.0, global_step_num: 658104, avg loss: 0.0009249353467836636, step: 209, replay memory length: 400000\n",
      "episode: 2187, score: 1.0, global_step_num: 658294, avg loss: 0.0011147490386131148, step: 190, replay memory length: 400000\n",
      "episode: 2188, score: 0, global_step_num: 658617, avg loss: 0.0012897886688194487, step: 323, replay memory length: 400000\n",
      "episode: 2189, score: 1.0, global_step_num: 658782, avg loss: 0.0010334307075716039, step: 165, replay memory length: 400000\n",
      "episode: 2190, score: 1.0, global_step_num: 659001, avg loss: 0.001310104491352474, step: 219, replay memory length: 400000\n",
      "episode: 2191, score: 1.0, global_step_num: 659189, avg loss: 0.0016111676892913895, step: 188, replay memory length: 400000\n",
      "episode: 2192, score: 1.0, global_step_num: 659249, avg loss: 0.0006455420747594568, step: 60, replay memory length: 400000\n",
      "episode: 2193, score: 1.0, global_step_num: 659512, avg loss: 0.001100301619667317, step: 263, replay memory length: 400000\n",
      "episode: 2194, score: 0, global_step_num: 659835, avg loss: 0.0011426349745682558, step: 323, replay memory length: 400000\n",
      "episode: 2195, score: 1.0, global_step_num: 660099, avg loss: 0.0012209098796424976, step: 264, replay memory length: 400000\n",
      "episode: 2196, score: 0, global_step_num: 660422, avg loss: 0.0010455857169993075, step: 323, replay memory length: 400000\n",
      "episode: 2197, score: 1.0, global_step_num: 660523, avg loss: 0.0009366425088429234, step: 101, replay memory length: 400000\n",
      "episode: 2198, score: 0, global_step_num: 660846, avg loss: 0.0009932619341390435, step: 323, replay memory length: 400000\n",
      "episode: 2199, score: 1.0, global_step_num: 661138, avg loss: 0.0011673314862952655, step: 292, replay memory length: 400000\n",
      "episode: 2200, score: 0, global_step_num: 661461, avg loss: 0.0009939982063109705, step: 323, replay memory length: 400000\n",
      "episode: 2201, score: 1.0, global_step_num: 661524, avg loss: 0.001209721572043539, step: 63, replay memory length: 400000\n",
      "episode: 2202, score: 1.0, global_step_num: 661781, avg loss: 0.0011701460971610613, step: 257, replay memory length: 400000\n",
      "episode: 2203, score: 1.0, global_step_num: 662060, avg loss: 0.0010930655183589177, step: 279, replay memory length: 400000\n",
      "episode: 2204, score: 1.0, global_step_num: 662107, avg loss: 0.0002724807372120035, step: 47, replay memory length: 400000\n",
      "episode: 2205, score: 0, global_step_num: 662430, avg loss: 0.0010991328070356098, step: 323, replay memory length: 400000\n",
      "episode: 2206, score: 0, global_step_num: 662753, avg loss: 0.0013193993374018198, step: 323, replay memory length: 400000\n",
      "episode: 2207, score: 0, global_step_num: 663076, avg loss: 0.0011111640033557046, step: 323, replay memory length: 400000\n",
      "episode: 2208, score: 1.0, global_step_num: 663270, avg loss: 0.001179619803424758, step: 194, replay memory length: 400000\n",
      "episode: 2209, score: 1.0, global_step_num: 663350, avg loss: 0.0004855160929423619, step: 80, replay memory length: 400000\n",
      "episode: 2210, score: 1.0, global_step_num: 663611, avg loss: 0.0010603488601097116, step: 261, replay memory length: 400000\n",
      "episode: 2211, score: 1.0, global_step_num: 663730, avg loss: 0.0008967779029228209, step: 119, replay memory length: 400000\n",
      "episode: 2212, score: 1.0, global_step_num: 663953, avg loss: 0.001258952692727885, step: 223, replay memory length: 400000\n",
      "episode: 2213, score: 1.0, global_step_num: 664110, avg loss: 0.001253150363376115, step: 157, replay memory length: 400000\n",
      "episode: 2214, score: 1.0, global_step_num: 664179, avg loss: 0.0017930287787248085, step: 69, replay memory length: 400000\n",
      "episode: 2215, score: 1.0, global_step_num: 664419, avg loss: 0.0010489078516902359, step: 240, replay memory length: 400000\n",
      "episode: 2216, score: 1.0, global_step_num: 664531, avg loss: 0.001327519691796754, step: 112, replay memory length: 400000\n",
      "episode: 2217, score: 1.0, global_step_num: 664738, avg loss: 0.0009926248245822925, step: 207, replay memory length: 400000\n",
      "episode: 2218, score: 0, global_step_num: 665061, avg loss: 0.001164320363295842, step: 323, replay memory length: 400000\n",
      "episode: 2219, score: 1.0, global_step_num: 665121, avg loss: 0.0006341263404616863, step: 60, replay memory length: 400000\n",
      "episode: 2220, score: 1.0, global_step_num: 665335, avg loss: 0.000929269422025729, step: 214, replay memory length: 400000\n",
      "episode: 2221, score: 1.0, global_step_num: 665510, avg loss: 0.001051677506332323, step: 175, replay memory length: 400000\n",
      "episode: 2222, score: 0, global_step_num: 665833, avg loss: 0.0011056706046160614, step: 323, replay memory length: 400000\n",
      "episode: 2223, score: 1.0, global_step_num: 666037, avg loss: 0.0011142046191574028, step: 204, replay memory length: 400000\n",
      "episode: 2224, score: 1.0, global_step_num: 666096, avg loss: 0.0006691721595285282, step: 59, replay memory length: 400000\n",
      "episode: 2225, score: 0, global_step_num: 666419, avg loss: 0.0013551702178963064, step: 323, replay memory length: 400000\n",
      "episode: 2226, score: 1.0, global_step_num: 666540, avg loss: 0.0013434980427563994, step: 121, replay memory length: 400000\n",
      "episode: 2227, score: 1.0, global_step_num: 666580, avg loss: 0.0012335716619304548, step: 40, replay memory length: 400000\n",
      "episode: 2228, score: 0, global_step_num: 666903, avg loss: 0.0009482545957577795, step: 323, replay memory length: 400000\n",
      "episode: 2229, score: 1.0, global_step_num: 667044, avg loss: 0.0008505221259567522, step: 141, replay memory length: 400000\n",
      "episode: 2230, score: 1.0, global_step_num: 667245, avg loss: 0.0010957126276444067, step: 201, replay memory length: 400000\n",
      "episode: 2231, score: 0, global_step_num: 667568, avg loss: 0.0007667371512785737, step: 323, replay memory length: 400000\n",
      "episode: 2232, score: 1.0, global_step_num: 667622, avg loss: 0.0007845244557655759, step: 54, replay memory length: 400000\n",
      "episode: 2233, score: 0, global_step_num: 667945, avg loss: 0.0011569971311332849, step: 323, replay memory length: 400000\n",
      "episode: 2234, score: 1.0, global_step_num: 667975, avg loss: 0.0017314003982240441, step: 30, replay memory length: 400000\n",
      "episode: 2235, score: 1.0, global_step_num: 668026, avg loss: 0.0014838828829343744, step: 51, replay memory length: 400000\n",
      "episode: 2236, score: 0, global_step_num: 668349, avg loss: 0.0010026532638056675, step: 323, replay memory length: 400000\n",
      "episode: 2237, score: 1.0, global_step_num: 668515, avg loss: 0.0012096345542637122, step: 166, replay memory length: 400000\n",
      "episode: 2238, score: 0, global_step_num: 668838, avg loss: 0.0012546979498597396, step: 323, replay memory length: 400000\n",
      "episode: 2239, score: 1.0, global_step_num: 668974, avg loss: 0.0012249708532077446, step: 136, replay memory length: 400000\n",
      "episode: 2240, score: 1.0, global_step_num: 669165, avg loss: 0.0010703282331566426, step: 191, replay memory length: 400000\n",
      "episode: 2241, score: 0, global_step_num: 669488, avg loss: 0.0008468623166645444, step: 323, replay memory length: 400000\n",
      "episode: 2242, score: 1.0, global_step_num: 669752, avg loss: 0.0013349309147759993, step: 264, replay memory length: 400000\n",
      "episode: 2243, score: 1.0, global_step_num: 670068, avg loss: 0.0012879114552191236, step: 316, replay memory length: 400000\n",
      "episode: 2244, score: 1.0, global_step_num: 670239, avg loss: 0.0013721045979631346, step: 171, replay memory length: 400000\n",
      "episode: 2245, score: 1.0, global_step_num: 670400, avg loss: 0.0005700008236265191, step: 161, replay memory length: 400000\n",
      "episode: 2246, score: 1.0, global_step_num: 670648, avg loss: 0.001163961506882339, step: 248, replay memory length: 400000\n",
      "episode: 2247, score: 1.0, global_step_num: 670825, avg loss: 0.0014531305228175592, step: 177, replay memory length: 400000\n",
      "episode: 2248, score: 1.0, global_step_num: 670912, avg loss: 0.0010438122283254604, step: 87, replay memory length: 400000\n",
      "episode: 2249, score: 1.0, global_step_num: 671036, avg loss: 0.0007653865507970823, step: 124, replay memory length: 400000\n",
      "episode: 2250, score: 1.0, global_step_num: 671211, avg loss: 0.0009100276578750968, step: 175, replay memory length: 400000\n",
      "episode: 2251, score: 0, global_step_num: 671534, avg loss: 0.0012191666119488725, step: 323, replay memory length: 400000\n",
      "episode: 2252, score: 1.0, global_step_num: 671665, avg loss: 0.0012813525588921428, step: 131, replay memory length: 400000\n",
      "episode: 2253, score: 1.0, global_step_num: 671875, avg loss: 0.0015167853680135783, step: 210, replay memory length: 400000\n",
      "episode: 2254, score: 1.0, global_step_num: 672025, avg loss: 0.0010848501213922646, step: 150, replay memory length: 400000\n",
      "episode: 2255, score: 1.0, global_step_num: 672147, avg loss: 0.0010511096638448761, step: 122, replay memory length: 400000\n",
      "episode: 2256, score: 0, global_step_num: 672470, avg loss: 0.001352578625443445, step: 323, replay memory length: 400000\n",
      "episode: 2257, score: 0, global_step_num: 672793, avg loss: 0.001102410238404544, step: 323, replay memory length: 400000\n",
      "episode: 2258, score: 0, global_step_num: 673116, avg loss: 0.0010748386144591635, step: 323, replay memory length: 400000\n",
      "episode: 2259, score: 1.0, global_step_num: 673226, avg loss: 0.0008310436752625802, step: 110, replay memory length: 400000\n",
      "episode: 2260, score: 1.0, global_step_num: 673404, avg loss: 0.0013003130091935797, step: 178, replay memory length: 400000\n",
      "episode: 2261, score: 1.0, global_step_num: 673641, avg loss: 0.0009827154897515595, step: 237, replay memory length: 400000\n",
      "episode: 2262, score: 1.0, global_step_num: 673727, avg loss: 0.0007812944177309218, step: 86, replay memory length: 400000\n",
      "episode: 2263, score: 1.0, global_step_num: 673935, avg loss: 0.0017576194360913178, step: 208, replay memory length: 400000\n",
      "episode: 2264, score: 0, global_step_num: 674258, avg loss: 0.0010079035146592266, step: 323, replay memory length: 400000\n",
      "episode: 2265, score: 1.0, global_step_num: 674354, avg loss: 0.0019176816969093124, step: 96, replay memory length: 400000\n",
      "episode: 2266, score: 1.0, global_step_num: 674441, avg loss: 0.0012714827701989404, step: 87, replay memory length: 400000\n",
      "episode: 2267, score: 1.0, global_step_num: 674485, avg loss: 0.00027901408567872335, step: 44, replay memory length: 400000\n",
      "episode: 2268, score: 1.0, global_step_num: 674618, avg loss: 0.0006726040342278397, step: 133, replay memory length: 400000\n",
      "episode: 2269, score: 1.0, global_step_num: 674866, avg loss: 0.0014516194887518499, step: 248, replay memory length: 400000\n",
      "episode: 2270, score: 0, global_step_num: 675189, avg loss: 0.0008740826904806521, step: 323, replay memory length: 400000\n",
      "episode: 2271, score: 1.0, global_step_num: 675346, avg loss: 0.0010634046338066346, step: 157, replay memory length: 400000\n",
      "episode: 2272, score: 1.0, global_step_num: 675387, avg loss: 0.0018700525180597985, step: 41, replay memory length: 400000\n",
      "episode: 2273, score: 0, global_step_num: 675710, avg loss: 0.0008909133311136928, step: 323, replay memory length: 400000\n",
      "episode: 2274, score: 1.0, global_step_num: 675920, avg loss: 0.0011704668037044116, step: 210, replay memory length: 400000\n",
      "episode: 2275, score: 0, global_step_num: 676243, avg loss: 0.0009168788999558564, step: 323, replay memory length: 400000\n",
      "episode: 2276, score: 1.0, global_step_num: 676510, avg loss: 0.0011038474966751598, step: 267, replay memory length: 400000\n",
      "episode: 2277, score: 0, global_step_num: 676833, avg loss: 0.001478593213259843, step: 323, replay memory length: 400000\n",
      "episode: 2278, score: 0, global_step_num: 677156, avg loss: 0.0013063928666547284, step: 323, replay memory length: 400000\n",
      "episode: 2279, score: 1.0, global_step_num: 677209, avg loss: 0.000956829497775992, step: 53, replay memory length: 400000\n",
      "episode: 2280, score: 0, global_step_num: 677532, avg loss: 0.001291556702551131, step: 323, replay memory length: 400000\n",
      "episode: 2281, score: 1.0, global_step_num: 677704, avg loss: 0.0008167458067331672, step: 172, replay memory length: 400000\n",
      "episode: 2282, score: 0, global_step_num: 678027, avg loss: 0.0010964606290904987, step: 323, replay memory length: 400000\n",
      "episode: 2283, score: 1.0, global_step_num: 678192, avg loss: 0.0010315605620579652, step: 165, replay memory length: 400000\n",
      "episode: 2284, score: 0, global_step_num: 678515, avg loss: 0.0009713619737320486, step: 323, replay memory length: 400000\n",
      "episode: 2285, score: 0, global_step_num: 678838, avg loss: 0.0007930253304568436, step: 323, replay memory length: 400000\n",
      "episode: 2286, score: 1.0, global_step_num: 678912, avg loss: 0.0011114002003849335, step: 74, replay memory length: 400000\n",
      "episode: 2287, score: 1.0, global_step_num: 679079, avg loss: 0.000582090854405867, step: 167, replay memory length: 400000\n",
      "episode: 2288, score: 0, global_step_num: 679402, avg loss: 0.0008982806604802448, step: 323, replay memory length: 400000\n",
      "episode: 2289, score: 1.0, global_step_num: 679442, avg loss: 0.0010169190954229634, step: 40, replay memory length: 400000\n",
      "episode: 2290, score: 1.0, global_step_num: 679658, avg loss: 0.0009456820815301028, step: 216, replay memory length: 400000\n",
      "episode: 2291, score: 1.0, global_step_num: 679837, avg loss: 0.0010592034281478582, step: 179, replay memory length: 400000\n",
      "episode: 2292, score: 1.0, global_step_num: 679901, avg loss: 0.0010538428867548078, step: 64, replay memory length: 400000\n",
      "episode: 2293, score: 0, global_step_num: 680224, avg loss: 0.0013608784343069255, step: 323, replay memory length: 400000\n",
      "episode: 2294, score: 0, global_step_num: 680547, avg loss: 0.000926618537670142, step: 323, replay memory length: 400000\n",
      "episode: 2295, score: 0, global_step_num: 680870, avg loss: 0.0011697261701466167, step: 323, replay memory length: 400000\n",
      "episode: 2296, score: 0, global_step_num: 681193, avg loss: 0.0012400405953288357, step: 323, replay memory length: 400000\n",
      "episode: 2297, score: 0, global_step_num: 681516, avg loss: 0.0012997343157865363, step: 323, replay memory length: 400000\n",
      "episode: 2298, score: 1.0, global_step_num: 681576, avg loss: 0.00044536748813091737, step: 60, replay memory length: 400000\n",
      "episode: 2299, score: 0, global_step_num: 681899, avg loss: 0.0009462920511832522, step: 323, replay memory length: 400000\n",
      "episode: 2300, score: 0, global_step_num: 682222, avg loss: 0.0011485483172200249, step: 323, replay memory length: 400000\n",
      "episode: 2301, score: 0, global_step_num: 682545, avg loss: 0.0009191985629827469, step: 323, replay memory length: 400000\n",
      "episode: 2302, score: 0, global_step_num: 682868, avg loss: 0.0010408278028683107, step: 323, replay memory length: 400000\n",
      "episode: 2303, score: 0, global_step_num: 683191, avg loss: 0.0013073107940157424, step: 323, replay memory length: 400000\n",
      "episode: 2304, score: 0, global_step_num: 683514, avg loss: 0.001295041220573877, step: 323, replay memory length: 400000\n",
      "episode: 2305, score: 0, global_step_num: 683837, avg loss: 0.0007093424396686824, step: 323, replay memory length: 400000\n",
      "episode: 2306, score: 0, global_step_num: 684160, avg loss: 0.0009098513757315784, step: 323, replay memory length: 400000\n",
      "episode: 2307, score: 0, global_step_num: 684483, avg loss: 0.0009910481941159315, step: 323, replay memory length: 400000\n",
      "episode: 2308, score: 0, global_step_num: 684806, avg loss: 0.0008916664361333105, step: 323, replay memory length: 400000\n",
      "episode: 2309, score: 0, global_step_num: 685129, avg loss: 0.001210778478501749, step: 323, replay memory length: 400000\n",
      "episode: 2310, score: 0, global_step_num: 685452, avg loss: 0.001296269396424642, step: 323, replay memory length: 400000\n",
      "episode: 2311, score: 0, global_step_num: 685775, avg loss: 0.0008791300644466287, step: 323, replay memory length: 400000\n",
      "episode: 2312, score: 0, global_step_num: 686098, avg loss: 0.0012854788770427018, step: 323, replay memory length: 400000\n",
      "episode: 2313, score: 0, global_step_num: 686421, avg loss: 0.0009930115203265369, step: 323, replay memory length: 400000\n",
      "episode: 2314, score: 0, global_step_num: 686744, avg loss: 0.0008674075993538608, step: 323, replay memory length: 400000\n",
      "episode: 2315, score: 0, global_step_num: 687067, avg loss: 0.0009326122846585844, step: 323, replay memory length: 400000\n",
      "episode: 2316, score: 0, global_step_num: 687390, avg loss: 0.0010200959699243476, step: 323, replay memory length: 400000\n",
      "episode: 2317, score: 0, global_step_num: 687713, avg loss: 0.0011088868825643674, step: 323, replay memory length: 400000\n",
      "episode: 2318, score: 0, global_step_num: 688036, avg loss: 0.0009833949807061546, step: 323, replay memory length: 400000\n",
      "episode: 2319, score: 0, global_step_num: 688359, avg loss: 0.001258438151870097, step: 323, replay memory length: 400000\n",
      "episode: 2320, score: 0, global_step_num: 688682, avg loss: 0.0010227249131494261, step: 323, replay memory length: 400000\n",
      "episode: 2321, score: 0, global_step_num: 689005, avg loss: 0.0008783993765602037, step: 323, replay memory length: 400000\n",
      "episode: 2322, score: 0, global_step_num: 689328, avg loss: 0.0011063644619119628, step: 323, replay memory length: 400000\n",
      "episode: 2323, score: 1.0, global_step_num: 689651, avg loss: 0.0008398182672601319, step: 323, replay memory length: 400000\n",
      "episode: 2324, score: 0, global_step_num: 689974, avg loss: 0.0008012059554976809, step: 323, replay memory length: 400000\n",
      "episode: 2325, score: 0, global_step_num: 690297, avg loss: 0.0008026121602121548, step: 323, replay memory length: 400000\n",
      "episode: 2326, score: 0, global_step_num: 690620, avg loss: 0.0008468229574710865, step: 323, replay memory length: 400000\n",
      "episode: 2327, score: 1.0, global_step_num: 690848, avg loss: 0.001080953006191577, step: 228, replay memory length: 400000\n",
      "episode: 2328, score: 0, global_step_num: 691171, avg loss: 0.0013953101086881699, step: 323, replay memory length: 400000\n",
      "episode: 2329, score: 0, global_step_num: 691494, avg loss: 0.0012452071921521654, step: 323, replay memory length: 400000\n",
      "episode: 2330, score: 0, global_step_num: 691817, avg loss: 0.0011961793118893179, step: 323, replay memory length: 400000\n",
      "episode: 2331, score: 0, global_step_num: 692140, avg loss: 0.0010370704815264706, step: 323, replay memory length: 400000\n",
      "episode: 2332, score: 0, global_step_num: 692463, avg loss: 0.0012954762494943, step: 323, replay memory length: 400000\n",
      "episode: 2333, score: 0, global_step_num: 692786, avg loss: 0.001042580778736804, step: 323, replay memory length: 400000\n",
      "episode: 2334, score: 0, global_step_num: 693109, avg loss: 0.0007908303068600845, step: 323, replay memory length: 400000\n",
      "episode: 2335, score: 0, global_step_num: 693432, avg loss: 0.0010063140382210497, step: 323, replay memory length: 400000\n",
      "episode: 2336, score: 0, global_step_num: 693755, avg loss: 0.0009336022886268142, step: 323, replay memory length: 400000\n",
      "episode: 2337, score: 0, global_step_num: 694078, avg loss: 0.0010931096935008595, step: 323, replay memory length: 400000\n",
      "episode: 2338, score: 0, global_step_num: 694401, avg loss: 0.0009835206899347086, step: 323, replay memory length: 400000\n",
      "episode: 2339, score: 0, global_step_num: 694724, avg loss: 0.0009934746118485317, step: 323, replay memory length: 400000\n",
      "episode: 2340, score: 0, global_step_num: 695047, avg loss: 0.0012638024466672217, step: 323, replay memory length: 400000\n",
      "episode: 2341, score: 0, global_step_num: 695370, avg loss: 0.001327593986349399, step: 323, replay memory length: 400000\n",
      "episode: 2342, score: 0, global_step_num: 695693, avg loss: 0.000836396456515985, step: 323, replay memory length: 400000\n",
      "episode: 2343, score: 1.0, global_step_num: 696014, avg loss: 0.0008558207799818763, step: 321, replay memory length: 400000\n",
      "episode: 2344, score: 0, global_step_num: 696337, avg loss: 0.00108442962155039, step: 323, replay memory length: 400000\n",
      "episode: 2345, score: 0, global_step_num: 696660, avg loss: 0.001010671197859482, step: 323, replay memory length: 400000\n",
      "episode: 2346, score: 0, global_step_num: 696983, avg loss: 0.0006653036996903388, step: 323, replay memory length: 400000\n",
      "episode: 2347, score: 0, global_step_num: 697306, avg loss: 0.0014143518868350885, step: 323, replay memory length: 400000\n",
      "episode: 2348, score: 0, global_step_num: 697629, avg loss: 0.0009176421218534762, step: 323, replay memory length: 400000\n",
      "episode: 2349, score: 0, global_step_num: 697952, avg loss: 0.0011461929909390603, step: 323, replay memory length: 400000\n",
      "episode: 2350, score: 0, global_step_num: 698275, avg loss: 0.0008502786798324918, step: 323, replay memory length: 400000\n",
      "episode: 2351, score: 0, global_step_num: 698598, avg loss: 0.0006902678195343335, step: 323, replay memory length: 400000\n",
      "episode: 2352, score: 0, global_step_num: 698921, avg loss: 0.0008808789309956134, step: 323, replay memory length: 400000\n",
      "episode: 2353, score: 0, global_step_num: 699244, avg loss: 0.0012926077012648406, step: 323, replay memory length: 400000\n",
      "episode: 2354, score: 0, global_step_num: 699567, avg loss: 0.0012135748427972825, step: 323, replay memory length: 400000\n",
      "episode: 2355, score: 0, global_step_num: 699890, avg loss: 0.0010315102683016053, step: 323, replay memory length: 400000\n",
      "episode: 2356, score: 1.0, global_step_num: 700070, avg loss: 0.001512096958749175, step: 180, replay memory length: 400000\n",
      "episode: 2359, score: 0, global_step_num: 701039, avg loss: 0.0011870749528269905, step: 323, replay memory length: 400000\n",
      "episode: 2360, score: 0, global_step_num: 701362, avg loss: 0.0005392266745762393, step: 323, replay memory length: 400000\n",
      "episode: 2361, score: 0, global_step_num: 701685, avg loss: 0.000999050644434959, step: 323, replay memory length: 400000\n",
      "episode: 2362, score: 0, global_step_num: 702008, avg loss: 0.0013658953770504148, step: 323, replay memory length: 400000\n",
      "episode: 2363, score: 0, global_step_num: 702331, avg loss: 0.0007668261458381097, step: 323, replay memory length: 400000\n",
      "episode: 2364, score: 0, global_step_num: 702654, avg loss: 0.0010873984922778652, step: 323, replay memory length: 400000\n",
      "episode: 2365, score: 0, global_step_num: 702977, avg loss: 0.0011190127281806162, step: 323, replay memory length: 400000\n",
      "episode: 2366, score: 1.0, global_step_num: 703284, avg loss: 0.0012069715289163567, step: 307, replay memory length: 400000\n",
      "episode: 2367, score: 0, global_step_num: 703607, avg loss: 0.000983162785678219, step: 323, replay memory length: 400000\n",
      "episode: 2368, score: 0, global_step_num: 703930, avg loss: 0.000786372768383185, step: 323, replay memory length: 400000\n",
      "episode: 2369, score: 1.0, global_step_num: 704202, avg loss: 0.0007969732563223635, step: 272, replay memory length: 400000\n",
      "episode: 2370, score: 0, global_step_num: 704525, avg loss: 0.0012847912035561452, step: 323, replay memory length: 400000\n",
      "episode: 2371, score: 0, global_step_num: 704848, avg loss: 0.0009707082177223742, step: 323, replay memory length: 400000\n",
      "episode: 2372, score: 0, global_step_num: 705171, avg loss: 0.001177312904418481, step: 323, replay memory length: 400000\n",
      "episode: 2373, score: 0, global_step_num: 705494, avg loss: 0.001070644994130138, step: 323, replay memory length: 400000\n",
      "episode: 2374, score: 0, global_step_num: 705817, avg loss: 0.0013399527000695205, step: 323, replay memory length: 400000\n",
      "episode: 2375, score: 0, global_step_num: 706140, avg loss: 0.0011977387538305384, step: 323, replay memory length: 400000\n",
      "episode: 2376, score: 0, global_step_num: 706463, avg loss: 0.0014743779574724195, step: 323, replay memory length: 400000\n",
      "episode: 2377, score: 0, global_step_num: 706786, avg loss: 0.0010036654351128214, step: 323, replay memory length: 400000\n",
      "episode: 2378, score: 0, global_step_num: 707109, avg loss: 0.0012352873852790143, step: 323, replay memory length: 400000\n",
      "episode: 2379, score: 0, global_step_num: 707432, avg loss: 0.001153408260011822, step: 323, replay memory length: 400000\n",
      "episode: 2380, score: 0, global_step_num: 707755, avg loss: 0.0008654913062580948, step: 323, replay memory length: 400000\n",
      "episode: 2381, score: 0, global_step_num: 708078, avg loss: 0.0009691063366123979, step: 323, replay memory length: 400000\n",
      "episode: 2382, score: 0, global_step_num: 708401, avg loss: 0.001155086822865332, step: 323, replay memory length: 400000\n",
      "episode: 2383, score: 0, global_step_num: 708724, avg loss: 0.0011909171021729904, step: 323, replay memory length: 400000\n",
      "episode: 2384, score: 0, global_step_num: 709047, avg loss: 0.0010658767969528669, step: 323, replay memory length: 400000\n",
      "episode: 2385, score: 0, global_step_num: 709370, avg loss: 0.0008592204612528696, step: 323, replay memory length: 400000\n",
      "episode: 2386, score: 0, global_step_num: 709693, avg loss: 0.0011062497255201712, step: 323, replay memory length: 400000\n",
      "episode: 2387, score: 0, global_step_num: 710016, avg loss: 0.0012287357712597406, step: 323, replay memory length: 400000\n",
      "episode: 2388, score: 0, global_step_num: 710339, avg loss: 0.0010144930125378026, step: 323, replay memory length: 400000\n",
      "episode: 2389, score: 0, global_step_num: 710662, avg loss: 0.000778426262355289, step: 323, replay memory length: 400000\n",
      "episode: 2390, score: 0, global_step_num: 710985, avg loss: 0.0010785550950160384, step: 323, replay memory length: 400000\n",
      "episode: 2391, score: 0, global_step_num: 711308, avg loss: 0.0016556777476539636, step: 323, replay memory length: 400000\n",
      "episode: 2392, score: 0, global_step_num: 711631, avg loss: 0.0010996102258170827, step: 323, replay memory length: 400000\n",
      "episode: 2393, score: 0, global_step_num: 711954, avg loss: 0.0012066392392279517, step: 323, replay memory length: 400000\n",
      "episode: 2394, score: 0, global_step_num: 712277, avg loss: 0.0010746675950169178, step: 323, replay memory length: 400000\n",
      "episode: 2395, score: 0, global_step_num: 712600, avg loss: 0.0008537715700387128, step: 323, replay memory length: 400000\n",
      "episode: 2396, score: 0, global_step_num: 712923, avg loss: 0.0008649634547705473, step: 323, replay memory length: 400000\n",
      "episode: 2397, score: 0, global_step_num: 713246, avg loss: 0.0014669584889913322, step: 323, replay memory length: 400000\n",
      "episode: 2398, score: 0, global_step_num: 713569, avg loss: 0.0007659848981668748, step: 323, replay memory length: 400000\n",
      "episode: 2399, score: 0, global_step_num: 713892, avg loss: 0.0011238278179719857, step: 323, replay memory length: 400000\n",
      "episode: 2400, score: 0, global_step_num: 714215, avg loss: 0.0009264282641638166, step: 323, replay memory length: 400000\n",
      "episode: 2402, score: 0, global_step_num: 714861, avg loss: 0.0012974290617652395, step: 323, replay memory length: 400000\n",
      "episode: 2403, score: 0, global_step_num: 715184, avg loss: 0.001172001024774221, step: 323, replay memory length: 400000\n",
      "episode: 2404, score: 0, global_step_num: 715507, avg loss: 0.0011372692941021012, step: 323, replay memory length: 400000\n",
      "episode: 2405, score: 0, global_step_num: 715830, avg loss: 0.0009538423553132799, step: 323, replay memory length: 400000\n",
      "episode: 2406, score: 0, global_step_num: 716153, avg loss: 0.0011945136327146033, step: 323, replay memory length: 400000\n",
      "episode: 2407, score: 0, global_step_num: 716476, avg loss: 0.0008584820940085093, step: 323, replay memory length: 400000\n",
      "episode: 2408, score: 0, global_step_num: 716799, avg loss: 0.0015449888809149516, step: 323, replay memory length: 400000\n",
      "episode: 2409, score: 0, global_step_num: 717122, avg loss: 0.0011019743177122466, step: 323, replay memory length: 400000\n",
      "episode: 2410, score: 0, global_step_num: 717445, avg loss: 0.0012371405966930434, step: 323, replay memory length: 400000\n",
      "episode: 2411, score: 0, global_step_num: 717768, avg loss: 0.0013152806522954198, step: 323, replay memory length: 400000\n",
      "episode: 2412, score: 0, global_step_num: 718091, avg loss: 0.000514012210605194, step: 323, replay memory length: 400000\n",
      "episode: 2413, score: 0, global_step_num: 718414, avg loss: 0.0007792007285576489, step: 323, replay memory length: 400000\n",
      "episode: 2414, score: 0, global_step_num: 718737, avg loss: 0.0011410581892670156, step: 323, replay memory length: 400000\n",
      "episode: 2415, score: 0, global_step_num: 719060, avg loss: 0.001036134270061638, step: 323, replay memory length: 400000\n",
      "episode: 2416, score: 0, global_step_num: 719383, avg loss: 0.0011329410980837615, step: 323, replay memory length: 400000\n",
      "episode: 2417, score: 0, global_step_num: 719706, avg loss: 0.0009558011557557632, step: 323, replay memory length: 400000\n",
      "episode: 2418, score: 0, global_step_num: 720029, avg loss: 0.001157128879427777, step: 323, replay memory length: 400000\n",
      "episode: 2419, score: 0, global_step_num: 720352, avg loss: 0.0010250248486343638, step: 323, replay memory length: 400000\n",
      "episode: 2420, score: 0, global_step_num: 720675, avg loss: 0.0013288900360809352, step: 323, replay memory length: 400000\n",
      "episode: 2421, score: 0, global_step_num: 720998, avg loss: 0.0014014387309321517, step: 323, replay memory length: 400000\n"
     ]
    }
   ],
   "source": [
    "dqn_algo_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ek1AH8QBbY5R"
   },
   "source": [
    "### Training results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T08:59:51.564423Z",
     "start_time": "2020-09-02T08:59:51.546204Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "9-PBPuP7bZAZ"
   },
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "def dqn_algo_test(test_epi=1):\n",
    "    # create the simple crossing environment \n",
    "    random_seed = 0 # np.random.randint(1000) ## uncomment this to create stochastic enviroments\n",
    "    env = gym.make('MiniGrid-SimpleCrossingS9N1-v0')\n",
    "    env = ReseedWrapper(env,seeds=[random_seed])\n",
    "    env = RGBImgObsWrapper(env) # Get pixel observations\n",
    "    env = ImgObsWrapper(env) # Get rid of the 'mission' field\n",
    "\n",
    "    test_episodes = test_epi # number of episodes to run test\n",
    "\n",
    "    # store the results \n",
    "    env = wrappers.Monitor(env, \"/results/\", force=True)\n",
    "\n",
    "    episode_number = 0 # initialize episode count\n",
    "    epsilon = 0.001 # initialize epsilon - keep to minimum because no need to explore\n",
    "    obs_step_num = 0 # no need to observe any data\n",
    "\n",
    "    # to use the trained network\n",
    "    global_step = 1000001  # \n",
    "    model = load_model(configs['restore_model_path'])\n",
    "\n",
    "    # run the test game loop\n",
    "    while episode_number < test_episodes:\n",
    "\n",
    "        # flags to identify if an episode/game has terminated\n",
    "        terminated = False\n",
    "\n",
    "        # variables to information per episode (a game)\n",
    "        score = 0         # store game score (per episode/game)   \n",
    "        \n",
    "        # reset the environment\n",
    "        env.reset()\n",
    "        #observe = env.reset()\n",
    "\n",
    "        # get the first observation and preprocess it\n",
    "        first_obs, _, _, _ = env.step(1)\n",
    "        first_state = pre_process(first_obs)\n",
    "\n",
    "        # duplicate the first observations 4 times to create history\n",
    "        history = np.stack((first_state, first_state, first_state, first_state), axis=2)\n",
    "        history = np.reshape([history], (1, 84, 84, 3*3))\n",
    "\n",
    "        # initialize a loop within an episode/game\n",
    "        while not terminated:\n",
    "\n",
    "            frames.append(np.moveaxis(env.render(\"rgb_array\"), 2, 0))\n",
    "\n",
    "            # get action for the current history and go one step in environment\n",
    "            action = select_action(history, epsilon, global_step, model, obs_step_num)\n",
    "\n",
    "            # record environment's response for the action\n",
    "            observation, reward, terminated, info = env.step(action)\n",
    "\n",
    "            # preprocess the observation and store as next state to new history\n",
    "            next_state = pre_process(observation)\n",
    "            next_state = np.reshape([next_state], (1, 84, 84, 1*3))\n",
    "            next_history = np.append(next_state, history[:, :, :, :2*3], axis=3)\n",
    "\n",
    "            # update the in game/episode score\n",
    "            score += reward\n",
    "\n",
    "            # assign new state to current state\n",
    "            history = next_history\n",
    "\n",
    "            # increment the global step number\n",
    "            global_step += 1\n",
    "            \n",
    "            # store information at the episode termination\n",
    "            if terminated:\n",
    "                write_gif(np.array(frames), f'test_epi_{episode_number}'+\".gif\", fps=1/0.1)\n",
    "                episode_number += 1\n",
    "                print(f\"episode: {episode_number}, score: {score}\")\n",
    "                env.close()\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T09:50:18.222191Z",
     "start_time": "2020-09-02T08:59:58.126015Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "DB-xZUmg3e4m",
    "outputId": "7431671a-aa06-43b2-8527-5eaf7fa73af1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1, score: 0\n",
      "episode: 2, score: 0\n",
      "episode: 3, score: 0\n",
      "episode: 4, score: 0\n",
      "episode: 5, score: 0\n",
      "episode: 6, score: 0\n",
      "episode: 7, score: 0\n",
      "episode: 8, score: 0\n",
      "episode: 9, score: 0\n"
     ]
    }
   ],
   "source": [
    "dqn_algo_test(9)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "RL4NLP_PandulaP.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
