{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mplfinance as mpf\n",
    "from PIL import Image\n",
    "import os, shutil\n",
    "import multiprocessing as mp\n",
    "import tqdm\n",
    "from datetime import datetime\n",
    "import create_chart\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(curr_pair, candle_hist = 40, nb_pool_wrks = 5, chunk_size=1, overwrite=False):\n",
    "    \n",
    "    \n",
    "    # delete exsisting content of the training-data folder\n",
    "    if overwrite:\n",
    "        folder = f'./data/fx_data/{curr_pair[:3]}_{curr_pair[4:]}/train_imgs/'\n",
    "        for filename in os.listdir(folder):\n",
    "            file_path = os.path.join(folder, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.unlink(file_path)\n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)\n",
    "            except Exception as e:\n",
    "                print('Failed to delete %s. Reason: %s' % (file_path, e))    \n",
    "    \n",
    "    \n",
    "    # extract saved signal and price data | merge \n",
    "    folder_path    = f'./data/fx_data/{curr_pair[:3]}_{curr_pair[4:]}/'\n",
    "    fx_signal_data = pd.read_parquet(folder_path+f'fx_data_{curr_pair[:3]}_{curr_pair[4:]}_w_sig.parquet')\n",
    "    fx_data        = pd.read_parquet(folder_path+f'fx_data_{curr_pair[:3]}_{curr_pair[4:]}.parquet')\n",
    "    fx_data.set_index('date',inplace = True)\n",
    "    fx_final = fx_data.merge(right = fx_signal_data\n",
    "                             , left_index=True\n",
    "                             , right_index=True\n",
    "                             , how = 'inner')\n",
    "\n",
    "    # print status\n",
    "    print('\\n------------------------------------\\n'\\\n",
    "          f'Curr. Pair: {curr_pair[:3]}-{curr_pair[4:]}\\n\\n' \\\n",
    "          f'Start-time: {fx_final.index.min()},\\nEnd-time: {fx_final.index.max()},\\n\\n' \\\n",
    "          f'Signal-Breakdown\\n{pd.DataFrame(fx_final.signal.value_counts())}\\n\\n' \\\n",
    "          f'Dataset-size:{fx_final.shape}\\n'\\\n",
    "           '--------------------------')\n",
    "    \n",
    "    # create a single `open', `close', `high', `low' metrics with bid/ask prices \n",
    "    fx_final.loc[:,'open']  = (fx_final.loc[:,'bidopen']  + fx_final.loc[:,'askopen'])/2 \n",
    "    fx_final.loc[:,'close'] = (fx_final.loc[:,'bidclose'] + fx_final.loc[:,'askclose'])/2 \n",
    "    fx_final.loc[:,'high']  = (fx_final.loc[:,'bidhigh']  + fx_final.loc[:,'askhigh'])/2 \n",
    "    fx_final.loc[:,'low']   = (fx_final.loc[:,'bidlow']   + fx_final.loc[:,'asklow'])/2 \n",
    "    fx_final.sort_index(inplace=True)\n",
    "        \n",
    "    # filter out only the required metrics / structure the dataframe\n",
    "    fx_final = fx_final.loc[:,['open','close','high','low','tickqty', 'signal', 'signal_count']]\n",
    "    fx_final.columns = ['open','close','high','low','volume', 'signal', 'signal_count']    \n",
    "        \n",
    "    # create basic moving-average indicators (50 EMA 200 EMA)\n",
    "    fx_final['ewm_50_m'] = fx_final['close'].ewm(span=50\n",
    "                                               , min_periods=0\n",
    "                                               , adjust=False\n",
    "                                               , ignore_na=False).mean()\n",
    "\n",
    "    fx_final['ewm_50_h'] = fx_final['high'].ewm(span=50\n",
    "                                               , min_periods=0\n",
    "                                               , adjust=False\n",
    "                                               , ignore_na=False).mean()\n",
    "\n",
    "    fx_final['ewm_50_l'] = fx_final['low'].ewm(span=50\n",
    "                                               , min_periods=0\n",
    "                                               , adjust=False\n",
    "                                               , ignore_na=False).mean()\n",
    "\n",
    "    fx_final['ewm_200'] = fx_final['close'].ewm(span=200\n",
    "                                               , min_periods=0\n",
    "                                               , adjust=False\n",
    "                                               , ignore_na=False).mean()    \n",
    "        \n",
    "    # number of candle-stick history to consider for each prediction\n",
    "    look_back_time = candle_hist\n",
    "\n",
    "    try:\n",
    "        # get the image labels in the target folder\n",
    "        file_name_li = os.listdir(folder_path+'train_imgs/')\n",
    "\n",
    "        # extract the time labels from files\n",
    "        file_time_li = [datetime.strptime(file_name[8:24], '%Y-%m-%d_%H-%M') for file_name in file_name_li]\n",
    "\n",
    "        # get the most recent time\n",
    "        max_time_existing = max(file_time_li)\n",
    "\n",
    "        # filter time index for new data (excluding already existing data)\n",
    "        fx_final_date_filtered = fx_final.index[fx_final.index>max_time_existing]\n",
    "\n",
    "        # create incremental image chunks with 30 images (each chunk include 30 candles)\n",
    "        data_idx_chuncks = [i for i in zip(fx_final_date_filtered.to_list(), fx_final_date_filtered.to_list()[look_back_time:])]\n",
    "\n",
    "    except:\n",
    "        # create incremental image chunks with 30 images (each chunk include 30 candles)\n",
    "        data_idx_chuncks = [i for i in zip(fx_final.index.to_list(), fx_final.index.to_list()[look_back_time:])]    \n",
    "        \n",
    "        \n",
    "    ### structure the data for parallel-processing ###\n",
    "    \n",
    "    # add curr. pair information to dataframe\n",
    "    fx_final.loc[:,\"curr_1\"] = curr_pair[:3]\n",
    "    fx_final.loc[:,\"curr_2\"] = curr_pair[4:]\n",
    "\n",
    "    # add folder_path to dataframe\n",
    "    fx_final.loc[:,\"f_path\"] = folder_path\n",
    "\n",
    "    # create dataframe chunks based on time indexes\n",
    "    df_chuncks = []\n",
    "\n",
    "    print(\"\\n Partitioning dataset... \", end='\\r')\n",
    "        \n",
    "    for data_chunk in tqdm.tqdm(data_idx_chuncks):\n",
    "        df_chuncks.append(fx_final.loc[data_chunk[0]:data_chunk[1]])\n",
    "        \n",
    "                \n",
    "    # create folder to store images\n",
    "    if not os.path.exists(folder_path+'train_imgs'):\n",
    "         os.makedirs(folder_path+'train_imgs')\n",
    "            \n",
    "    # list to store predicted date time period\n",
    "    predicted_dates = []\n",
    "\n",
    "    # initialize workers\n",
    "    Pool = mp.Pool(processes=nb_pool_wrks)\n",
    "    \n",
    "    print(\"\\n Genarating charts... \", end='\\r')\n",
    "    # generate candle-stick charts (parallelized)\n",
    "    for _ in tqdm.tqdm(Pool.imap(create_chart.create_chart_parellel, df_chuncks, chunksize=chunk_size), total=len(df_chuncks)):\n",
    "        predicted_dates.append(_)\n",
    "    \n",
    "    # release workers\n",
    "    Pool.close()\n",
    "    Pool.join()\n",
    "    \n",
    " \n",
    "    ## update the chart image creation log ##\n",
    "    # read old log datafile\n",
    "    try:\n",
    "        with open(folder_path+curr_pair[:3]+'_'+curr_pair[4:]+\"_chart_log.txt\") as json_file:\n",
    "            log_data = json.load(json_file)\n",
    "    except:\n",
    "        log_data = {}\n",
    "\n",
    "    # add new log data\n",
    "    log_data[datetime.now().strftime('%Y-%m-%d %H:%M:%S')] = predicted_dates\n",
    "\n",
    "    # overwite the log datafile\n",
    "    with open(folder_path+curr_pair[:3]+'_'+curr_pair[4:]+\"_chart_log.txt\", 'w') as outfile:\n",
    "        json.dump(log_data, outfile)\n",
    "        \n",
    "    print(f\"\\nExecution complete for {curr_pair[:3]}-{curr_pair[4:]} Pair!\\n\" \\\n",
    "           '------------------------------------', end='\\r')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_pairs = ['EUR/USD',\n",
    "             'GBP/USD',\n",
    "             'USD/CHF',\n",
    "             'AUD/USD',\n",
    "             'USD/CAD',\n",
    "             'NZD/USD',\n",
    "             'EUR/CHF',\n",
    "             'EUR/GBP',\n",
    "             'EUR/AUD',\n",
    "             'EUR/CAD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------\n",
      "Curr. Pair: EUR-USD\n",
      "\n",
      "Start-time: 2020-06-25 07:15:00,\n",
      "End-time: 2020-11-20 18:15:00,\n",
      "\n",
      "Signal-Breakdown\n",
      "      signal\n",
      "HOLD   10326\n",
      "SELL      17\n",
      "BUY       15\n",
      "\n",
      "Dataset-size:(10358, 11)\n",
      "--------------------------\n",
      "\n",
      " Partitioning dataset... \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10318/10318 [00:04<00:00, 2514.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Genarating charts... \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████████████████████████████████████████████████████████▏                 | 7925/10318 [24:49<06:50,  5.83it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    732\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 733\u001b[1;33m                 \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    734\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-8b3100198104>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                            \u001b[1;33m,\u001b[0m \u001b[0mnb_pool_wrks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                            \u001b[1;33m,\u001b[0m \u001b[0mchunk_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                            , overwrite=True)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-158871e6f084>\u001b[0m in \u001b[0;36mgenerate_training_data\u001b[1;34m(curr_pair, candle_hist, nb_pool_wrks, chunk_size, overwrite)\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n Genarating charts... \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;31m# generate candle-stick charts (parallelized)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_chart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_chart_parellel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_chuncks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_chuncks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m         \u001b[0mpredicted_dates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1079\u001b[0m             \"\"\"), fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1081\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m             \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    323\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m                 ))\n\u001b[1;32m--> 325\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mimap_unordered\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    735\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 737\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    738\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# generate training data for every curr. pair\n",
    "for curr_pair in curr_pairs:\n",
    "    generate_training_data(curr_pair\n",
    "                           , candle_hist = 40\n",
    "                           , nb_pool_wrks = 6\n",
    "                           , chunk_size = 2\n",
    "                           , overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
