{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import mplfinance as mpf\n",
    "#from PIL import Image\n",
    "import os, shutil\n",
    "import multiprocessing as mp\n",
    "import tqdm\n",
    "from datetime import datetime\n",
    "import create_chart\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(curr_pair, candle_hist = 40, nb_pool_wrks = 5, chunk_size=1, overwrite=False):\n",
    "    \n",
    "    \n",
    "    # delete exsisting content of the training-data folder\n",
    "    if overwrite:\n",
    "        folder = f'./data/fx_data/{curr_pair[:3]}_{curr_pair[4:]}/train_imgs/'\n",
    "        for filename in os.listdir(folder):\n",
    "            file_path = os.path.join(folder, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.unlink(file_path)\n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)\n",
    "            except Exception as e:\n",
    "                print('Failed to delete %s. Reason: %s' % (file_path, e))    \n",
    "    \n",
    "    \n",
    "    # extract saved signal and price data | merge \n",
    "    folder_path    = f'./data/fx_data/{curr_pair[:3]}_{curr_pair[4:]}/'\n",
    "    fx_signal_data = pd.read_parquet(folder_path+f'fx_data_{curr_pair[:3]}_{curr_pair[4:]}_w_sig.parquet')\n",
    "    fx_data        = pd.read_parquet(folder_path+f'fx_data_{curr_pair[:3]}_{curr_pair[4:]}.parquet')\n",
    "    fx_data.set_index('date',inplace = True)\n",
    "    fx_final = fx_data.merge(right = fx_signal_data\n",
    "                             , left_index=True\n",
    "                             , right_index=True\n",
    "                             , how = 'inner')\n",
    "\n",
    "    # print status\n",
    "    print('\\n------------------------------------\\n'\\\n",
    "          f'Curr. Pair: {curr_pair[:3]}-{curr_pair[4:]}\\n\\n' \\\n",
    "          f'Start-time: {fx_final.index.min()},\\nEnd-time: {fx_final.index.max()},\\n\\n' \\\n",
    "          f'Signal-Breakdown\\n{pd.DataFrame(fx_final.signal.value_counts())}\\n\\n' \\\n",
    "          f'Dataset-size:{fx_final.shape}\\n'\\\n",
    "           '--------------------------')\n",
    "    \n",
    "    # create a single `open', `close', `high', `low' metrics with bid/ask prices \n",
    "    fx_final.loc[:,'open']  = (fx_final.loc[:,'bidopen']  + fx_final.loc[:,'askopen'])/2 \n",
    "    fx_final.loc[:,'close'] = (fx_final.loc[:,'bidclose'] + fx_final.loc[:,'askclose'])/2 \n",
    "    fx_final.loc[:,'high']  = (fx_final.loc[:,'bidhigh']  + fx_final.loc[:,'askhigh'])/2 \n",
    "    fx_final.loc[:,'low']   = (fx_final.loc[:,'bidlow']   + fx_final.loc[:,'asklow'])/2 \n",
    "    fx_final.sort_index(inplace=True)\n",
    "        \n",
    "    # filter out only the required metrics / structure the dataframe\n",
    "    fx_final = fx_final.loc[:,['open','close','high','low','tickqty', 'signal', 'signal_count']]\n",
    "    fx_final.columns = ['open','close','high','low','volume', 'signal', 'signal_count']    \n",
    "        \n",
    "    # create basic moving-average indicators (50 EMA 200 EMA)\n",
    "    fx_final['ewm_50_m'] = fx_final['close'].ewm(span=50\n",
    "                                               , min_periods=0\n",
    "                                               , adjust=False\n",
    "                                               , ignore_na=False).mean()\n",
    "\n",
    "    fx_final['ewm_50_h'] = fx_final['high'].ewm(span=50\n",
    "                                               , min_periods=0\n",
    "                                               , adjust=False\n",
    "                                               , ignore_na=False).mean()\n",
    "\n",
    "    fx_final['ewm_50_l'] = fx_final['low'].ewm(span=50\n",
    "                                               , min_periods=0\n",
    "                                               , adjust=False\n",
    "                                               , ignore_na=False).mean()\n",
    "\n",
    "    fx_final['ewm_200'] = fx_final['close'].ewm(span=200\n",
    "                                               , min_periods=0\n",
    "                                               , adjust=False\n",
    "                                               , ignore_na=False).mean()    \n",
    "        \n",
    "    # number of candle-stick history to consider for each prediction\n",
    "    look_back_time = candle_hist\n",
    "\n",
    "    try:\n",
    "        # get the image labels in the target folder\n",
    "        file_name_li = os.listdir(folder_path+'train_imgs/')\n",
    "\n",
    "        # extract the time labels from files\n",
    "        file_time_li = [datetime.strptime(file_name[8:24], '%Y-%m-%d_%H-%M') for file_name in file_name_li]\n",
    "\n",
    "        # get the most recent time\n",
    "        max_time_existing = max(file_time_li)\n",
    "\n",
    "        # filter time index for new data (excluding already existing data)\n",
    "        fx_final_date_filtered = fx_final.index[fx_final.index>max_time_existing]\n",
    "\n",
    "        # create incremental image chunks with 30 images (each chunk include 30 candles)\n",
    "        data_idx_chuncks = [i for i in zip(fx_final_date_filtered.to_list(), fx_final_date_filtered.to_list()[look_back_time:])]\n",
    "\n",
    "    except:\n",
    "        # create incremental image chunks with 30 images (each chunk include 30 candles)\n",
    "        data_idx_chuncks = [i for i in zip(fx_final.index.to_list(), fx_final.index.to_list()[look_back_time:])]    \n",
    "        \n",
    "        \n",
    "    ### structure the data for parallel-processing ###\n",
    "    \n",
    "    # add curr. pair information to dataframe\n",
    "    fx_final.loc[:,\"curr_1\"] = curr_pair[:3]\n",
    "    fx_final.loc[:,\"curr_2\"] = curr_pair[4:]\n",
    "\n",
    "    # add folder_path to dataframe\n",
    "    fx_final.loc[:,\"f_path\"] = folder_path\n",
    "\n",
    "    # create dataframe chunks based on time indexes\n",
    "    df_chuncks = []\n",
    "\n",
    "    print(\"\\n Partitioning dataset... \", end='\\r')\n",
    "        \n",
    "    for data_chunk in tqdm.tqdm(data_idx_chuncks):\n",
    "        df_chuncks.append(fx_final.loc[data_chunk[0]:data_chunk[1]])\n",
    "        \n",
    "                \n",
    "    # create folder to store images\n",
    "    if not os.path.exists(folder_path+'train_imgs'):\n",
    "         os.makedirs(folder_path+'train_imgs')\n",
    "            \n",
    "    # list to store predicted date time period\n",
    "    predicted_dates = []\n",
    "\n",
    "    # initialize workers\n",
    "    Pool = mp.Pool(processes=nb_pool_wrks)\n",
    "    \n",
    "    print(\"\\n Genarating charts... \", end='\\r')\n",
    "    # generate candle-stick charts (parallelized)\n",
    "    for _ in tqdm.tqdm(Pool.imap(create_chart.create_chart_parellel, df_chuncks, chunksize=chunk_size), total=len(df_chuncks)):\n",
    "        predicted_dates.append(_)\n",
    "    \n",
    "    # release workers\n",
    "    Pool.close()\n",
    "    Pool.join()\n",
    "    \n",
    " \n",
    "    ## update the chart image creation log ##\n",
    "    # read old log datafile\n",
    "    try:\n",
    "        with open(folder_path+curr_pair[:3]+'_'+curr_pair[4:]+\"_chart_log.txt\") as json_file:\n",
    "            log_data = json.load(json_file)\n",
    "    except:\n",
    "        log_data = {}\n",
    "\n",
    "    # add new log data\n",
    "    log_data[datetime.now().strftime('%Y-%m-%d %H:%M:%S')] = predicted_dates\n",
    "\n",
    "    # overwite the log datafile\n",
    "    with open(folder_path+curr_pair[:3]+'_'+curr_pair[4:]+\"_chart_log.txt\", 'w') as outfile:\n",
    "        json.dump(log_data, outfile)\n",
    "        \n",
    "    print(f\"\\nExecution complete for {curr_pair[:3]}-{curr_pair[4:]} Pair!\\n\" \\\n",
    "           '------------------------------------', end='\\r')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of instruments need to generate training data\n",
    "curr_pairs = ['EUR/USD',\n",
    "             'GBP/USD',\n",
    "             #'USD/CHF',\n",
    "             #'AUD/USD',\n",
    "             'USD/CAD',\n",
    "             #'NZD/USD',\n",
    "             #'EUR/CHF',\n",
    "             'EUR/GBP',\n",
    "             'EUR/AUD',\n",
    "             'EUR/CAD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------\n",
      "Curr. Pair: EUR-USD\n",
      "\n",
      "Start-time: 2020-08-04 06:00:00,\n",
      "End-time: 2020-12-29 21:15:00,\n",
      "\n",
      "Signal-Breakdown\n",
      "      signal\n",
      "HOLD   10108\n",
      "BUY       42\n",
      "SELL      36\n",
      "\n",
      "Dataset-size:(10186, 11)\n",
      "--------------------------\n",
      "\n",
      " Partitioning dataset... \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 192/192 [00:00<00:00, 2672.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Genarating charts... \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 192/192 [00:30<00:00,  6.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution complete for EUR-USD Pair!\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Curr. Pair: GBP-USD\n",
      "\n",
      "Start-time: 2020-08-04 00:30:00,\n",
      "End-time: 2020-12-29 21:15:00,\n",
      "\n",
      "Signal-Breakdown\n",
      "      signal\n",
      "HOLD    9918\n",
      "SELL     137\n",
      "BUY      136\n",
      "\n",
      "Dataset-size:(10191, 11)\n",
      "--------------------------\n",
      "\n",
      " Partitioning dataset... \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 197/197 [00:00<00:00, 2123.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Genarating charts... \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 197/197 [00:33<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution complete for GBP-USD Pair!\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Curr. Pair: USD-CAD\n",
      "\n",
      "Start-time: 2020-08-03 13:00:00,\n",
      "End-time: 2020-12-29 21:30:00,\n",
      "\n",
      "Signal-Breakdown\n",
      "      signal\n",
      "HOLD   10105\n",
      "BUY       42\n",
      "SELL      41\n",
      "\n",
      "Dataset-size:(10188, 11)\n",
      "--------------------------\n",
      "\n",
      " Partitioning dataset... \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 194/194 [00:00<00:00, 1451.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Genarating charts... \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 194/194 [00:35<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution complete for USD-CAD Pair!\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Curr. Pair: EUR-GBP\n",
      "\n",
      "Start-time: 2020-08-04 01:45:00,\n",
      "End-time: 2020-12-29 21:30:00,\n",
      "\n",
      "Signal-Breakdown\n",
      "      signal\n",
      "HOLD   10103\n",
      "BUY       46\n",
      "SELL      42\n",
      "\n",
      "Dataset-size:(10191, 11)\n",
      "--------------------------\n",
      "\n",
      " Partitioning dataset... \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 197/197 [00:00<00:00, 2218.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Genarating charts... \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 197/197 [00:31<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution complete for EUR-GBP Pair!\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Curr. Pair: EUR-AUD\n",
      "\n",
      "Start-time: 2020-08-04 04:15:00,\n",
      "End-time: 2020-12-29 21:30:00,\n",
      "\n",
      "Signal-Breakdown\n",
      "      signal\n",
      "HOLD    9959\n",
      "BUY      124\n",
      "SELL     113\n",
      "\n",
      "Dataset-size:(10196, 11)\n",
      "--------------------------\n",
      "\n",
      " Partitioning dataset... \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 202/202 [00:00<00:00, 1620.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Genarating charts... \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 202/202 [00:30<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution complete for EUR-AUD Pair!\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Curr. Pair: EUR-CAD\n",
      "\n",
      "Start-time: 2020-08-03 20:15:00,\n",
      "End-time: 2020-12-29 21:30:00,\n",
      "\n",
      "Signal-Breakdown\n",
      "      signal\n",
      "HOLD   10074\n",
      "BUY       61\n",
      "SELL      54\n",
      "\n",
      "Dataset-size:(10189, 11)\n",
      "--------------------------\n",
      "\n",
      " Partitioning dataset... \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 195/195 [00:00<00:00, 1761.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Genarating charts... \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 195/195 [00:31<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution complete for EUR-CAD Pair!\n",
      "------------------------------------\r"
     ]
    }
   ],
   "source": [
    "# generate training data for every curr. pair\n",
    "for curr_pair in curr_pairs:\n",
    "    generate_training_data(curr_pair\n",
    "                           , candle_hist = 50\n",
    "                           , nb_pool_wrks = 6\n",
    "                           , chunk_size = 2\n",
    "                           , overwrite=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
